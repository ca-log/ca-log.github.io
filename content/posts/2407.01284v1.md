---
author: 'TechScribe'
title: 'GPT-4o 引领 LMM 迈向知识泛化阶段，WE-MATH 基准评估揭示视觉数学推理新进展'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01284v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01284v1)

## 摘要

本文提出了 WE-MATH，这是第一个用于深入分析 LMM 在视觉数学推理中的基准。WE-MATH 包含 6.5K 个视觉数学问题，涵盖 5 个层次和 67 个知识概念。此外，我们开创性地根据所需知识概念将复合问题分解为子问题，并引入了一种新颖的四维指标，用于精细推理评估。通过 WE-MATH，我们对现有的 LMM 在视觉数学推理方面进行了全面评估，并揭示了解题步骤与问题特定性能之间的负相关关系。我们还发现 IK 问题是 LMM 的最大漏洞，但 GPT-4o 的主要挑战已经从 IK 转移到 IG，这使其成为第一个迈向知识泛化阶段的 LMM。最后，对 KCA 策略和错误案例的分析进一步启发了现有的 LMM 向类人视觉数学推理发展。<!--more-->

## 原理

WE-MATH 的工作原理主要包括以下几个方面：
1. **数据集构建**：作者从公开权威的数学网站上收集了 6524 个问题，根据数学教材知识结构进行分类，构建了一个包含 5 个层次、99 个节点和 67 个叶节点的层次化知识结构。
2. **问题分解**：对于每个问题，作者根据其所需的知识概念将其分解为子问题。具体来说，对于一个包含 k 个知识概念的问题，作者将其分解为 k 个一步问题。
3. **推理评估**：作者引入了一种新颖的四维指标，用于评估 LMM 在解决问题过程中的推理能力。具体来说，该指标包括 Insufficient Knowledge (IK)、Inadequate Generalization (IG)、Complete Mastery (CM)和 Rote Memorization (RM)四个维度。
4. **知识概念扩充**：为了缓解 LMM 在解决问题过程中的知识不足问题，作者引入了知识概念扩充策略，为 LMM 提供了必要的知识支持。

## 流程

WE-MATH 的工作流程主要包括以下几个步骤：
1. **数据收集**：从公开权威的数学网站上收集 6524 个问题，并根据数学教材知识结构进行分类。
2. **问题分解**：对于每个问题，根据其所需的知识概念将其分解为子问题。
3. **推理评估**：使用引入的四维指标对 LMM 在解决问题过程中的推理能力进行评估。
4. **知识概念扩充**：使用知识概念扩充策略为 LMM 提供必要的知识支持。
5. **结果分析**：对评估结果进行分析，揭示 LMM 在视觉数学推理方面的问题和挑战，并提出改进建议。

## 应用

WE-MATH 可以应用于以下几个方面：
1. **LMM 评估**：WE-MATH 可以作为一个基准，用于评估 LMM 在视觉数学推理方面的性能。
2. **教育领域**：WE-MATH 可以为教育工作者提供一个工具，用于评估学生在视觉数学推理方面的能力，并为教学提供指导。
3. **研究领域**：WE-MATH 可以为研究人员提供一个数据集，用于研究 LMM 在视觉数学推理方面的问题和挑战，并提出改进建议。