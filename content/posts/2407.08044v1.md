---
author: 'TechScribe'
title: 'RoLoRA：通过旋转技术实现大型语言模型的高效权重-激活量化'
date: '2024-07-10'
Lastmod: '2024-07-12'
description: 'RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.08044v1.pdf_0.jpg)](https://arxiv.org/abs/2407.08044v1)

## 摘要

本文介绍了一种名为RoLoRA的新型低秩适应（LoRA）方法，旨在有效实现大型语言模型（LLMs）的权重-激活量化。RoLoRA通过旋转技术消除激活异常值，并提出旋转感知微调以保持旋转后LLMs的无异常值特性。实验结果表明，RoLoRA在低比特LoRA收敛和后训练量化鲁棒性方面持续改进，尤其在4比特权重-激活量化设置下，相比LoRA基线在常识推理任务上实现了高达29.5%的绝对准确度提升。此外，RoLoRA还展示了其在大规模多模态模型（如LLaVA-1.5-7B）上的有效性。<!--more-->

## 原理

RoLoRA的核心创新在于结合了旋转技术和LoRA方法，以解决权重-激活量化中的性能下降问题。旋转技术通过将权重矩阵与旋转矩阵相乘，有效地混合了大小不同的权重，从而产生更接近高斯分布的激活，减少了异常值。旋转感知微调则确保在微调过程中保持这种无异常值的特性。这种结合不仅减少了量化误差，还提高了模型的量化鲁棒性。

## 流程

RoLoRA的工作流程包括两个主要步骤：首先，对预训练的LLMs应用块内和块间旋转，以消除激活中的异常值；其次，进行旋转感知微调，以保持微调后LLMs的无异常值特性。具体来说，旋转操作在微调之前应用于权重矩阵，而旋转感知微调则通过优化目标的奇异值分解（SVD）来初始化LoRA权重。整个流程确保了在微调和量化过程中，模型的性能得到优化。

## 应用

RoLoRA不仅适用于纯文本的大型语言模型，还扩展到了多模态模型，显示出在视觉指令调整等任务上的潜力。其高效的量化方法和鲁棒性使得RoLoRA在资源受限的环境中部署大型模型成为可能，特别是在需要低比特操作的场景中，如移动设备和边缘计算。