---
author: 'TechScribe'
title: '"陌生环境下的安全导航：基于强化学习的社会机器人导航策略改进"'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06056v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06056v1)

## 摘要

本文探讨了基于强化学习（RL）的社会机器人导航方法在处理特别具有挑战性或不熟悉情况时的性能下降问题。为了确保人类的安全和舒适，算法需要适当处理罕见情况，但这些情况由于其低频和多样性，对数据驱动方法提出了重大挑战。为此，本文提出了一种改进的学习过程，旨在鼓励RL策略在陌生情况下保持额外警惕。具体来说，本文通过修改行人模型训练过程、更新价值网络以估计和利用行人不可预测性特征，以及实施奖励函数来学习对行人不可预测性的有效响应，从而改进了社会注意力强化学习（SARL）策略。与原始SARL策略相比，改进后的策略在保持相似导航时间和路径长度的同时，将碰撞次数减少了82%，并在最困难情况下将行人个人空间内的停留时间减少了高达19个百分点。此外，本文还描述了如何将这些修改应用于其他RL策略，并在物理机器人上展示了这些策略的有效性。<!--more-->

## 原理

本文的核心在于通过引入不确定性意识来改进现有的RL导航策略。具体来说，通过以下三个关键步骤实现：
1. **修改训练过程**：在行人模型中系统性地引入偏差，通过增加高斯噪声来模拟行人的不可预测行为，从而使RL策略在训练过程中接触到更多样化的行为模式。
2. **更新模型架构**：通过增加一个多层感知机（MLP1）来估计每个行人的不可预测性值（ρ），并将这些估计值作为输入传递给主价值网络，使得策略能够根据行人的不可预测性调整其行为。
3. **修改奖励函数**：在奖励函数中引入基于行人不可预测性值的调整项，鼓励机器人在接近不可预测行人时保持更大的安全距离，同时在可预测行人周围正常导航。

这些改进使得RL策略能够在面对不熟悉或挑战性情况时，更好地识别和适应行人的不可预测性，从而提高导航的安全性和效率。

## 流程

本文提出的改进RL策略的工作流程如下：
1. **训练阶段**：在模拟环境中，通过向行人模型添加高斯噪声来生成具有不同不可预测性的行人行为。使用这些数据训练RL策略，使其能够在面对不可预测行人时采取更为谨慎的行为。
2. **部署阶段**：在实际应用中，机器人使用预训练的YOLOv3神经网络来检测行人，并通过算法获取行人的状态信息并跟踪他们。机器人根据行人的不可预测性值调整其导航策略，保持与不可预测行人更大的距离，同时正常导航于可预测行人周围。

例如，在一个实际场景中，机器人可能会遇到突然停下的行人（这在训练数据中未出现），通过其不确定性意识策略，机器人能够识别这种情况并保持安全距离，避免潜在的碰撞。

## 应用

本文提出的不确定性意识RL导航策略具有广泛的应用前景，特别是在需要高度安全性和适应性的社会机器人导航领域。这些策略可以应用于各种类型的移动机器人，如服务机器人、导览机器人等，以提高它们在复杂和动态环境中的导航能力。此外，这些策略还可以扩展到其他需要考虑人类行为的自动化系统中，如自动驾驶车辆等。