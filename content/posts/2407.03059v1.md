---
author: 'Mariia Vladimirova,Federico Pavone,Eustache Diemert'
title: '探索在线广告公平性：FairJob数据集及其在职位推荐中的应用'
date: '2024-07-03'
Lastmod: '2024-07-05'
description: 'FairJob: A Real-World Dataset for Fairness in Online Systems'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![FairJob: A Real-World Dataset for Fairness in Online Systems](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03059v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03059v1)

## 摘要

本文介绍了一种名为FairJob的数据集，该数据集专门设计用于在线广告系统中的职位推荐公平性研究。该数据集从真实的广告场景中收集，遵循隐私标准和商业保密协议，特别关注了在缺乏敏感用户属性（如性别）访问权限的情况下如何评估和提升算法的公平性。尽管数据集中的用户信息已被匿名化，并且包含一个性别的代理估计，但该数据集保持了预测能力和现实挑战性。FairJob数据集填补了高影响力领域（如广告）中公平性资源可用性的重要空白，特别是在平衡公平性和实用性方面，这是工业界常见的挑战。此外，本文还探讨了广告过程中可能出现不公平性的各个阶段，并提出了一种计算在线系统中职位推荐公平效用指标的方法。实验评估显示，通过在发布的数据集上应用偏差缓解技术，可以潜在地改善公平性，并了解与实用性的权衡关系。<!--more-->

## 原理

FairJob数据集的核心在于提供一个公平性意识的基准，用于评估和改进在线广告系统中的职位推荐算法。该数据集通过匿名化和随机投影技术处理用户和发布者特征，确保了数据的隐私安全同时保持了预测能力。数据集中的“性别代理”是通过用户与产品的交互行为来估计的，这种方法虽然不直接访问敏感的性别信息，但通过统计分析和行为模式识别，能够为模型提供一个关于用户性别的近似估计。此外，数据集还包含了一系列的实验评估，展示了如何在不同的训练模型中平衡公平性和预测准确性，特别是在没有直接访问保护属性时，如何通过算法调整来减少偏差。

## 流程

FairJob数据集的工作流程始于用户访问包含广告位的网页，广告技术公司参与实时竞价（RTB）拍卖，选择基于发布者和用户属性的广告活动。在赢得展示拍卖后，选择要展示的产品（如高级职位或助理职位）。整个过程中，确保了广告选择的公平性，防止了现有不平等的强化。具体到数据集的使用，研究者可以利用该数据集训练和测试不同的职位推荐模型，通过调整模型参数和引入公平性惩罚项，来评估和优化模型在不同性别群体间的公平性表现。

## 应用

FairJob数据集的应用前景广泛，主要集中在提升在线广告系统的公平性和透明度。通过使用该数据集，研究人员和实践者可以开发和测试新的算法，以确保在职位推荐中不同性别群体的公平对待。此外，该数据集还可用于教育和培训，帮助学生和专业人士理解算法公平性的重要性及其在实际应用中的挑战。随着对AI公平性要求的提高，FairJob数据集将成为推动相关研究和政策制定的重要资源。