---
author: 'TechScribe'
title: '"遗忘的威胁：揭示机器学习模型中的隐私漏洞"'
date: '2024-07-06'
Lastmod: '2024-07-10'
description: 'Releasing Malevolence from Benevolence: The Menace of Benign Data on Machine Unlearning'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Releasing Malevolence from Benevolence: The Menace of Benign Data on Machine Unlearning](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05112v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05112v1)

## 摘要

本文探讨了机器学习模型在处理大量真实或合成数据时，尽管能够实现卓越的预测性能，但同时也引发了日益严重的隐私担忧。为了缓解这些担忧，提出了“机器遗忘”（machine unlearning）技术，旨在从机器学习模型中移除特定数据样本的信息。然而，最近的研究表明，恶意用户可能通过请求对经过扰动的数据进行遗忘来破坏遗忘模型。本文提出了一种新的攻击方法，称为“遗忘可用性攻击”（Unlearning Usability Attack），该攻击方法不依赖于模型或遗忘算法，且成本较低。通过将数据分布信息提炼成少量数据，这些数据被自动中毒检测工具标记为良性数据，尽管对机器学习有益，但在遗忘过程中会导致模型中大量数据信息的丢失。评估显示，在不同攻击场景下，遗忘这些不超过训练数据1%的良性数据，模型准确率最多可下降50%。这些发现促使未来研究重新思考机器遗忘背景下的“数据中毒”问题。<!--more-->

## 原理

遗忘可用性攻击的工作原理基于两个步骤：贡献和撤销。攻击者首先贡献精心准备的数据来训练模型，然后行使“被遗忘权”来撤销其对训练模型的贡献。当遗忘请求被执行后，遗忘模型会大幅降低其效用，使其对其他用户无用。攻击的直觉在于，通过提供高度信息化的数据来促进原始模型的训练，攻击者随后通过遗忘来撤销其贡献，从而破坏遗忘模型。为了实现这一攻击，攻击者可以利用数据集凝聚技术，将多个样本的知识凝聚到少数信息样本中。这种攻击方法的关键在于，尽管精心准备的数据对机器学习是良性的，但在遗忘过程中，这些数据会导致模型中大量关键信息的丢失。

## 流程

遗忘可用性攻击的工作流程如下：
1. **数据贡献阶段**：攻击者首先向模型贡献精心准备的数据集，这些数据集对模型的训练有积极贡献。
2. **遗忘请求阶段**：攻击者随后请求模型遗忘这些贡献的数据。
3. **模型更新阶段**：模型执行遗忘操作，更新模型参数，以移除与这些数据相关的信息。
4. **效用降低阶段**：由于这些数据包含大量关键信息，模型的效用大幅降低，导致模型对其他用户的无用性。

## 应用

遗忘可用性攻击的应用前景主要在于揭示机器遗忘技术中的安全漏洞，特别是在机器学习即服务（MLaaS）环境中。这种攻击方法的发现促使业界重新评估和加强机器遗忘的安全措施，以保护用户数据隐私并确保模型的稳定性和可靠性。未来的研究可能会集中在开发更健壮的遗忘程序和增强数据检测能力上，以平衡数据隐私、模型功能和安全性。