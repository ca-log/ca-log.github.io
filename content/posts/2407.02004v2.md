---
author: 'TechScribe'
title: '"SAVE模型：革新音频-视觉分割的轻量级解决方案"'
date: '2024-07-02'
Lastmod: '2024-07-10'
description: 'SAVE: Segment Audio-Visual Easy way using Segment Anything Model'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![SAVE: Segment Audio-Visual Easy way using Segment Anything Model](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02004v2.pdf_0.jpg)](https://arxiv.org/abs/2407.02004v2)

## 摘要

本文介绍了一种名为SAVE的轻量级音频-视觉分割（AVS）模型，该模型通过适应预训练的Segment Anything Model（SAM）来精确识别和定位视觉场景中的听觉元素。SAVE模型通过引入图像编码器适配器和残余音频编码器适配器，有效地融合了音频和视觉特征，提高了分割性能，同时降低了输入分辨率，加快了训练和推理速度。实验结果表明，SAVE模型在AVSBench数据集上显著优于现有的最先进方法，特别是在低分辨率输入下表现出色。<!--more-->

## 原理

SAVE模型的核心创新在于其图像编码器适配器和残余音频编码器适配器。图像编码器适配器通过在每个变换器块中添加适配层，增强了模型对特定数据集知识的转移能力，特别是在通道和空间维度上的融合。残余音频编码器适配器则通过多层感知机（MLP）和残余连接，将音频特征转换并注入到变换器块中，作为稀疏提示用于掩码解码器，从而在编码阶段实现有效的音频-视觉融合和交互。

## 流程

SAVE模型的工作流程包括以下步骤：首先，冻结原始图像编码器的所有参数，并在每个变换器块中添加图像编码器适配器。接着，通过残余音频编码器适配器处理音频特征，并将其作为稀疏提示输入到掩码解码器中。模型通过训练过程中的二元交叉熵损失和IoU损失进行优化，以提高分割质量。具体示例显示，SAVE模型能够准确地分割出视频帧中的声音对象，即使在多声音对象的复杂场景中也能保持高精度。

## 应用

SAVE模型的应用前景广泛，特别是在需要精确分割的视频监控、多模态视频编辑和机器人技术等领域。由于其高效的训练和推理速度，以及在低分辨率输入下的高性能，SAVE模型有望在实际应用中大幅提升音频-视觉分割任务的效率和准确性。