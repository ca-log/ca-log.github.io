---
author: 'TechScribe'
title: '揭秘人工智能的幻象：计算机真的能思考和感知吗？'
date: '2024-04-21'
Lastmod: '2024-07-05'
description: 'Minds, Brains, AI'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Minds, Brains, AI](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02495v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02495v1)

## 摘要

本文由Jay Seitz撰写，探讨了人工智能（AI）领域中关于通用人工智能（AGI）的广泛宣称，特别是关于计算机是否能够思考、推理、具有意识和心智理论的问题。文章通过广泛的科学研究和相关领域的文献，提出了三个主要命题：计算机是否能够思考或推理，计算机是否具有感知或意识，以及计算机是否具有心智理论。文章强调，尽管有许多宣称，但缺乏科学证据支持计算机具有这些人类特有的认知能力。文章还讨论了语言模型（LLMs）的工作原理和局限性，以及它们在模拟人类智能方面的表现。最终，文章指出，当前的计算机系统不具备真正的思考、感知或意识能力，也不具备心智理论。<!--more-->

## 原理

文章详细阐述了计算机（如大型语言模型LLMs）的工作原理，指出它们通过大量文本数据的统计关系来生成语言，并使用循环网络进行前馈和反馈机制。LLMs能够预测下一个单词或句子，并与其他文本元素建立统计联系。然而，LLMs经常产生基于其训练数据但未经验证的“幻觉”输出，这种现象被称为“幻觉”。此外，LLMs在预测和推理能力上存在严重缺陷，被批评为仅仅是“随机鹦鹉”，即它们能够听起来像人类写作，但实际上只是重新组合和混淆文本。文章还提到了Edward Tian开发的“AI检测器”，该工具能够准确地区分人类生成的文本和AI生成的文本。

## 流程

LLMs的工作流程包括接收输入提示，通过其训练的神经网络处理这些提示，并生成相应的文本输出。例如，当用户向ChatGPT（一种LLM）提出问题时，系统会分析问题并从其训练数据中提取相关信息，然后生成一个听起来合理的回答。然而，这种流程并不涉及真正的理解和推理，而是基于统计模式匹配和数据重组。

## 应用

尽管LLMs在模拟人类智能方面表现出一定的能力，但它们的应用前景仍然受限于其缺乏真正的理解和推理能力。LLMs在自动化文本生成、客户服务聊天机器人和数据分析等领域有应用潜力，但它们无法替代人类在需要深度理解和创造性思维的任务中的角色。未来的发展可能集中在增强LLMs的推理能力，使其能够更好地理解和处理复杂问题。