---
author: 'TechScribe'
title: '"视觉提示引领未来：多模态大型语言模型在传感器数据处理中的创新应用"'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10385v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10385v1)

## 摘要

本文探讨了在多模态大型语言模型（MLLMs）中，通过视觉提示结合传感器数据以解决普遍传感应用中的挑战。传统的文本提示方法在处理长序列传感器数据时性能显著下降。为此，本文提出了一种视觉提示方法，通过设计视觉提示指令，指导MLLMs利用可视化的传感器数据与目标传感任务描述相结合。此外，还引入了一个可视化生成器，自动创建针对特定传感任务的最优可视化，无需预先的任务特定知识。实验结果显示，该方法在九种传感任务中平均提高了10%的准确率，并显著降低了15.8倍的令牌成本，强调了视觉提示在多种传感任务中的有效性和成本效率。<!--more-->

## 原理

本文提出的视觉提示方法通过将传感器数据转换为图像形式，利用MLLMs的视觉输入能力来分析和理解这些数据。关键在于设计一种视觉提示，该提示包含可视化的传感器数据和任务特定指令，以指导MLLM如何利用这些图像数据来解决传感任务。此外，可视化生成器通过自动选择最合适的可视化工具，进一步优化了数据的可解释性和MLLM的决策过程。

## 流程

工作流程包括两个主要步骤：首先，传感器数据通过可视化生成器转换为图像格式，生成器根据任务描述和数据特性选择最佳的可视化方法。其次，这些图像与任务特定指令一起作为视觉提示输入到MLLM中，MLLM根据这些视觉信息进行任务解决。例如，在分类用户是行走还是跑步的任务中，传感器数据被转换为波形图，MLLM通过分析波形图的特征来做出判断。

## 应用

该方法的应用前景广泛，特别是在需要处理复杂传感器数据和长序列输入的领域，如医疗健康监测、环境监测和工业自动化等。通过提高数据处理效率和降低成本，该技术有望推动这些领域的智能化和自动化水平。