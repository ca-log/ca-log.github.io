---
author: 'TechScribe'
title: '探索知识推理：CHAIN-OF-KNOWLEDGE框架如何提升大型语言模型的智能水平'
date: '2024-06-30'
Lastmod: '2024-07-05'
description: 'Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00653v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00653v1)

## 摘要

本文介绍了一种名为CHAIN-OF-KNOWLEDGE的全面框架，旨在将知识推理能力集成到大型语言模型（LLMs）中。该框架包括数据集构建和模型学习的方法。为了构建数据集，作者通过在知识图谱（KGs）上进行规则挖掘创建了KNOWREASON数据集。在模型学习方面，作者观察到简单的训练方法会导致规则过拟合，因此提出了一种试错机制，模拟人类内部知识探索过程，以提高模型的泛化能力。实验结果表明，CHAIN-OF-KNOWLEDGE框架能有效提升LLMs在知识推理和一般推理基准上的表现。<!--more-->

## 原理

CHAIN-OF-KNOWLEDGE框架的核心在于通过知识图谱中的规则挖掘和知识选择，构建一个用于训练LLMs的数据集。在规则挖掘阶段，通过广度优先搜索算法从知识图谱中提取复合规则实例。知识选择阶段则确保所选知识适用于模型训练，避免数据泄露和过拟合。模型学习阶段，除了传统的模仿学习方法外，还引入了试错机制，使模型能够在缺乏支持事实时切换到更合适的推理路径，从而提高推理的准确性和泛化能力。

## 流程

CHAIN-OF-KNOWLEDGE的工作流程包括三个主要步骤：规则挖掘、知识选择和样本生成。首先，通过规则挖掘从知识图谱中提取复合规则实例。接着，在知识选择阶段，确保所选知识适用于模型训练，避免数据泄露和过拟合。最后，样本生成阶段将这些知识转化为自然语言样本，用于模型训练。例如，对于一个规则“Country(X,Y)←PlaceOfBirth(Z,X)∧CountryOfCitizenship(Z,Y)”，可以生成问题“Which country might Anykid be a citizen of?”和答案“Cckqlvy has Anykid as a part of their team. Cckqlvy is from the country Vevedgta. Therefore, Anykid may be a citizen of Vevedgta.”。

## 应用

CHAIN-OF-KNOWLEDGE框架的应用前景广泛，特别是在需要复杂推理能力的自然语言处理任务中。该框架不仅能够提升LLMs在知识推理任务上的表现，还能增强其在常识推理、算术推理和符号推理等其他推理任务上的能力。此外，该框架还有望应用于知识图谱的完善和下游任务，如链接预测和事实分类，进一步提升人工智能系统的智能水平和应用范围。