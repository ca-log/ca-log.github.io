---
author: 'TechScribe'
title: '实时动态视线跟踪与深度估计：革新透明显示器交互体验'
date: '2024-06-09'
Lastmod: '2024-07-05'
description: 'Realtime Dynamic Gaze Target Tracking and Depth-Level Estimation'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Realtime Dynamic Gaze Target Tracking and Depth-Level Estimation](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.18595v1.pdf_0.jpg)](https://arxiv.org/abs/2406.18595v1)

## 摘要

本文由Esmaeil Seraj等人撰写，针对透明显示器（如车辆中的抬头显示器HUD）中实时动态视线目标跟踪和深度级别估计的问题，提出了一种双模块的系统解决方案。该系统包括一个基于树的算法用于实时跟踪视线目标，以及一个多流自注意力架构用于从眼动追踪数据中估计视线深度级别。通过收集真实世界的眼动追踪数据集，论文展示了该系统在静态和动态环境中的可扩展性、精确性和实时可行性，为下一代用户与设备交互和体验设定了新的基准。<!--more-->

## 原理

论文提出的系统由两个主要模块组成：一是基于Quadtree的视线目标跟踪算法，该算法通过高效的空间分割和管理，能够快速准确地确定用户在透明显示器上的视线焦点；二是多流自注意力模型，用于从复杂的多维眼动追踪数据中估计视线深度级别，该模型通过捕捉眼动数据中的物理依赖关系，能够区分用户视线是聚焦于虚拟部件还是仅仅穿过它们。这两个模块并行工作，确保了系统的实时性和准确性。

## 流程

系统的工作流程如下：首先，通过现有的眼动追踪技术获取用户的实时眼动数据；然后，这些数据被输入到Quadtree算法中，该算法通过树结构快速定位用户视线所聚焦的部件；同时，眼动数据也被送入多流自注意力模型，该模型分析数据以确定视线深度级别。整个过程是并行且实时的，确保了在动态变化的显示内容中准确跟踪用户视线并估计其深度。

## 应用

该系统的应用前景广泛，特别是在增强现实（AR）和透明显示器的领域，如车辆HUD、AR眼镜和智能窗户等。通过实时准确地跟踪用户视线并估计其深度，系统能够提升用户体验，增强交互性，特别是在需要高度精确和实时反馈的应用场景中，如自动驾驶车辆的导航和安全系统。