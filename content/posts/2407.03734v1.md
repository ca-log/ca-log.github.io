---
author: 'TechScribe'
title: '创新口音适应技术：提升自监督预训练在自动语音识别中的性能'
date: '2024-07-04'
Lastmod: '2024-07-10'
description: 'Improving Self-supervised Pre-training using Accent-Specific Codebooks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Improving Self-supervised Pre-training using Accent-Specific Codebooks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03734v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03734v1)

## 摘要

本文由Darshan Prabhu等人撰写，针对自动语音识别（ASR）系统在处理不同口音时性能下降的问题，提出了一种基于口音特定码本的自监督预训练技术。该技术通过引入一组可训练的口音特定码本，使模型在预训练阶段就能捕捉到口音特定信息，并在后续的ASR微调阶段进一步细化。在Mozilla Common Voice数据集上的实验表明，该方法在已见和未见英语口音上均优于其他口音适应方法，实现了高达9%的相对词错误率（WER）降低。<!--more-->

## 原理

本文提出的方法主要通过在自监督学习（SSL）预训练阶段引入口音特定码本来增强模型的口音适应能力。具体来说，模型包括一个基于卷积的波形编码器（CONV）和一个基于Transformer的编码器（ENC），以及一个投影模块（FFNtok）。在预训练阶段，CONV模块将原始语音数据映射到特征空间，然后通过ENC模块生成上下文表示。同时，一个声学单元发现（AUD）模块生成伪目标标签，用于指导模型的预训练。关键的创新在于，在ENC模块中引入了口音特定码本和交叉注意力机制，使得模型能够学习并利用口音特定信息。这些码本在预训练阶段是可学习的，并在后续的ASR微调阶段进一步优化。

## 流程

本文提出的方法采用两阶段训练流程：1）自监督预训练阶段，使用SSL目标训练编码器；2）监督ASR微调阶段，使用预训练的编码器并进一步使用ASR特定的监督损失进行微调。在预训练阶段，模型通过交叉注意力机制将口音特定码本的信息融入到音频表示中。在微调阶段，模型使用联合CTC-注意力框架进行ASR任务的微调。具体的工作流程包括：输入原始语音数据，通过CONV模块提取特征，然后通过ENC模块生成上下文表示，同时通过AUD模块生成伪目标标签。在预训练阶段，模型通过交叉注意力机制利用口音特定码本的信息进行训练。在微调阶段，模型进一步使用ASR特定的监督损失进行优化。

## 应用

本文提出的口音特定码本技术不仅在已见口音上表现出色，而且在未见口音上也显示出强大的泛化能力。这表明该技术在处理多口音环境下的ASR任务具有广泛的应用前景。未来，该技术可以进一步扩展到其他语言和更广泛的语音处理任务中，如语音翻译、语音情感识别等。此外，通过结合无监督学习和未标记数据，可以进一步优化口音码本，提高模型的适应性和鲁棒性。