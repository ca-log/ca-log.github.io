---
author: 'TechScribe'
title: '"揭秘大型视觉-语言模型的幻觉累积问题及其解决方案"'
date: '2024-06-30'
Lastmod: '2024-07-05'
description: 'Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00569v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00569v1)

## 摘要

本文探讨了大型视觉-语言模型（LVLMs）在多模态交互中产生的幻觉问题，特别是在先前生成的幻觉影响下，模型是否会被误导并产生错误响应。研究提出了一个名为MMHalSnowball的框架，用于评估LVLMs在遇到生成的幻觉时的行为。实验结果显示，开源LVLMs的性能下降了至少31%，表明这些模型容易接受生成的幻觉并做出错误声明。为缓解这一问题，研究进一步提出了一种无需额外训练的方法——残余视觉解码（Residual Visual Decoding, RVD），通过调整模型的输出分布，使其直接访问视觉信息，从而减少超过24%的幻觉累积，同时保持模型的能力。<!--more-->

## 原理

MMHalSnowball框架通过精心设计的幻觉对话来评估LVLMs的行为。模型被要求在包含幻觉的对话中回答特定的视觉问题。关键在于，模型在回答问题时，其强大的语言能力使其倾向于过度自信于幻觉上下文，从而生成通常不会支持的错误声明，这种现象被称为多模态幻觉累积（Multimodal Hallucination Snowballing）。为解决这一问题，RVD方法通过残余连接视觉信息和当前用户指令，强调视觉信息，从而修正原始输出分布，实现对幻觉累积的缓解。

## 流程

1. **幻觉对话构建**：使用GQA数据集的验证集作为数据源，构建基于LVLMs常见幻觉类型的幻觉对话。
2. **幻觉生成**：利用ChatGPT重写与问题-答案对相关的幻觉答案和描述，确保这些幻觉与图像内容相矛盾。
3. **对话评估**：在包含幻觉的对话和无幻觉的对话中分别评估模型的回答，以确定模型是否受到幻觉累积的影响。
4. **RVD应用**：在多轮视觉文本对话场景中，通过动态调整输出分布，强调视觉信息，减少幻觉累积的影响。

## 应用

该研究不仅揭示了LVLMs在多模态交互中的幻觉问题，还提出了一种有效的缓解方法。这些发现和方法对于开发更可靠、更少幻觉的视觉-语言模型具有重要意义，特别是在需要高度准确性的应用场景中，如辅助视觉障碍者、自动驾驶等。