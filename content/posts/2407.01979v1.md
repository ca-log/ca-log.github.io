---
author: 'TechScribe'
title: '揭秘图神经网络的全局交互模式：迈向可解释的图分类'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01979v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01979v1)

## 摘要

本文提出了一种名为Global Interactive Pattern (GIP)学习的新型可解释图分类方案，旨在解决图神经网络(GNNs)在图级任务中缺乏解释性的问题。GIP通过引入可学习的全局交互模式，明确解释决策过程。该方案首先通过约束图聚类模块对大量节点进行聚类，然后将与粗化的全局交互实例与一批自解释图原型进行匹配，从而促进透明的图级推理过程。实验结果表明，GIP在合成和真实世界基准测试中显著提高了可解释性，并具有与最先进方法相竞争的性能。<!--more-->

## 原理

GIP框架的核心在于其两阶段的工作原理：首先通过聚类分配模块对图进行压缩，然后通过交互模式匹配模块识别粗化图中的交互模式。聚类分配模块通过迭代地聚合具有相似特征或紧密连接的组件，形成集群级表示，并基于局部结构之间的交互提取全局结构信息。交互模式匹配模块则定义了可学习的交互模式，以图结构的形式直接揭示图级的重要模式，并通过图核作为相似性度量，推动交互模式的学习和匹配。最终，通过相似性得分，使用带有softmax的全连接层计算每个类别的输出概率。

## 流程

GIP的工作流程包括以下步骤：
1. **输入图**：接收原始图数据作为输入。
2. **聚类分配模块**：对输入图进行多次压缩，每次压缩通过聚类算法将节点分组，形成更粗略的图表示。
3. **交互模式匹配模块**：定义一组可学习的交互模式，这些模式代表了图中的重要结构特征。通过计算粗化图与这些交互模式之间的相似度，确定哪些交互模式最相关。
4. **相似性基于的预测**：利用相似性得分，通过全连接层和softmax函数进行分类预测。
5. **输出预测结果**：输出每个类别的概率分布，以及与输入图最相似的交互模式作为解释。

## 应用

GIP框架的应用前景广泛，特别适用于需要高度解释性的领域，如生物信息学、社交网络分析、电力系统分析和分子生物学等。通过提供图级任务的透明解释，GIP有助于增强用户对模型决策的信任，并可能在安全和关键应用中发挥重要作用。