---
author: 'TechScribe'
title: 'FLOW方法：融合全局与局部视角的跨用户人类活动识别新突破'
date: '2024-06-03'
Lastmod: '2024-07-05'
description: 'FLOW: Fusing and Shuffling Global and Local Views for Cross-User Human Activity Recognition with IMUs'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![FLOW: Fusing and Shuffling Global and Local Views for Cross-User Human Activity Recognition with IMUs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.18569v1.pdf_0.jpg)](https://arxiv.org/abs/2406.18569v1)

## 摘要

本文介绍了一种名为FLOW的新型人工智能方法，用于通过惯性测量单元（IMU）进行跨用户人类活动识别（HAR）。FLOW方法通过融合和洗牌全局与局部视角，解决了IMU-HAR模型在不同用户间数据分布差异大的问题。该方法通过将IMU数据从局部坐标系转换到全局坐标系（NED坐标系），减少了由于传感器佩戴方式不同导致的数据分布差异。此外，FLOW方法还提出了一种多视角监督网络（MVFNet），通过洗牌和重组多个样本的视角，确保模型尽可能多地利用传感器信息进行最终决策。实验结果表明，FLOW方法在跨用户HAR任务中优于现有的最先进方法。<!--more-->

## 原理

FLOW方法的核心在于通过坐标转换和多视角融合来提高IMU-HAR的跨用户性能。首先，通过Mahony姿态解算算法和坐标基变换，将IMU数据从局部坐标系转换到全局坐标系（NED坐标系），这一过程称为“M&C”。这种转换减少了由于用户佩戴IMU设备方式不同导致的数据分布差异。其次，提出了一种名为MVFNet的多视角融合网络，该网络通过随机洗牌和独立监督不同视角，鼓励模型利用更丰富的特征进行分类。MVFNet包括一个主干网络、一个多视角融合层（MVF-Layer）和一个投票网络（Voting-net），通过这两个部分的协同工作，确保模型在训练过程中不会忽略重要信息。

## 流程

FLOW方法的工作流程包括两个主要步骤：全局视角提取和多视角融合训练。在全局视角提取阶段，使用Mahony算法和坐标基变换（M&C）将IMU数据从局部坐标系转换到NED全局坐标系，生成全局视角数据（vG）。在多视角融合训练阶段，MVFNet网络接受vL和vG作为输入，通过视角划分、视角洗牌和多视角融合网络的训练，确保模型能够独立理解每个视角并利用这些视角进行最终决策。具体来说，MVFNet在训练过程中会经历两次训练流程：第一次使用洗牌后的数据训练主干网络和MVF-Layer，第二次使用未洗牌的数据训练Voting-net，同时冻结主干网络和MVF-Layer。

## 应用

FLOW方法在跨用户人类活动识别领域具有广泛的应用前景。由于其能够有效减少不同用户间数据分布的差异，FLOW方法可以应用于各种需要高精度跨用户识别的场景，如健康监测、智能家居、老年人护理等。此外，该方法的多视角融合策略也可以推广到其他需要多传感器数据融合的领域，如机器人导航、虚拟现实等。随着可穿戴设备和物联网技术的普及，FLOW方法有望在这些领域发挥重要作用。