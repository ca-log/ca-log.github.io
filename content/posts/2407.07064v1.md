---
author: 'TechScribe'
title: '探索提示技术，提升LLM生成安全代码能力'
date: '2024-07-09'
Lastmod: '2024-07-10'
description: 'Prompting Techniques for Secure Code Generation: A Systematic Investigation'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Prompting Techniques for Secure Code Generation: A Systematic Investigation](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07064v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07064v1)

## 摘要

本文研究了不同提示技术对大型语言模型（LLM）生成安全代码的影响。通过对现有文献的系统综述，作者确定了15种可用于代码生成的提示技术，并将其分为5类。研究结果表明，提示技术可以有效提高LLM生成安全代码的能力，特别是递归批评和改进（RCI）技术，在减少安全漏洞方面表现出色。<!--more-->

## 原理

作者首先对现有文献进行了系统综述，确定了15种可用于代码生成的提示技术。然后，作者使用LLMSecEval数据集对这些技术进行了评估，该数据集包含150个可能导致不安全代码实现的自然语言安全相关代码生成提示。作者使用Bandit静态分析工具对LLM生成的代码进行了安全评估，并对评估结果进行了详细分析。

## 流程

1. 对现有文献进行系统综述，确定15种可用于代码生成的提示技术。
2. 使用LLMSecEval数据集对这些技术进行评估。
3. 使用Bandit静态分析工具对LLM生成的代码进行安全评估。
4. 对评估结果进行详细分析。

## 应用

本文的研究结果为开发更安全的代码生成工具提供了有价值的参考，有助于提高软件开发的安全性和可靠性。此外，本文的研究方法也可以应用于其他领域，如自然语言处理、机器学习等，为相关研究提供了新的思路和方法。