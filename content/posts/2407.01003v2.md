---
author: 'TechScribe'
title: '嵌入式提示调优：提升预训练模型在医学图像分析中的校准性能'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01003v2.pdf_0.jpg)](https://arxiv.org/abs/2407.01003v2)

## 摘要

本文探讨了在医学图像分类任务中，如何通过参数高效的微调（PEFT）方法来适应预训练的基础模型。针对主流提示调优方法在Transformer架构上的局限性，提出了一种新的嵌入式提示调优（EPT）方法，该方法通过在扩展通道中嵌入提示标记来优化输入标记，同时保持原始信息。此外，文章还提出了一种新的视角来理解提示调优：即提示调优是一种分布校准器，通过分析EPT中的逐块缩放和特征分离操作来支持这一观点。实验结果显示，EPT在少样本医学图像分类任务中显著优于几种最先进的微调方法，并且微调过程在高度竞争的时间内完成。<!--more-->

## 原理

EPT方法的核心在于通过在扩展通道中嵌入提示标记来优化输入标记，这种方法不仅保留了原始信息，还引入了额外的有用上下文。具体来说，EPT在Transformer的注意力计算中嵌入提示标记，这些提示标记在完成softmax计算后不再参与后续计算，从而实现了对输入标记的精细调整。此外，EPT通过逐块缩放操作缩短了同类样本在特征空间中的分布距离，增强了特征的表达能力和解耦能力。

## 流程

EPT的工作流程包括以下几个步骤：
1. 在输入图像的嵌入标记中嵌入提示标记。
2. 在Transformer的注意力计算中使用这些提示标记进行逐块缩放。
3. 通过softmax操作对注意力权重进行归一化。
4. 使用归一化的注意力权重对值矩阵进行加权求和，得到输出特征。
5. 将输出特征输入到多层感知机（MLP）中进行进一步处理。
6. 最终通过分类头进行分类预测。

## 应用

EPT方法在医学图像分析领域具有广泛的应用前景，特别是在少样本学习场景中，如疾病诊断、病理图像分类等。由于其参数高效和性能优越，EPT可以大幅减少计算和存储需求，适用于资源受限的环境。此外，EPT的分布校准特性使其在处理复杂和多样化的医学图像数据时表现出色，有望推动医学图像分析技术的进一步发展。