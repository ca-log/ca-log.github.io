---
author: 'TechScribe'
title: '嵌入式提示微调：提升预训练模型在医学图像分析中的校准能力'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01003v2.pdf_0.jpg)](https://arxiv.org/abs/2407.01003v2)

## 摘要

本文探讨了在医学图像分析领域中，预训练基础模型在跨域少样本场景下的参数高效微调（PEFT）方法的有效性。针对主流提示微调方法在Transformer架构上的局限性，提出了一种新的嵌入式提示微调（EPT）方法，通过将提示标记嵌入到扩展通道中，以优化输入标记并保持原始信息。实验结果显示，EPT在少样本医学图像分类任务中显著优于现有微调方法，并能在竞争性的时间内完成微调过程。此外，本文还提出了提示微调作为分布校准器的全新视角，并通过分析EPT中的补丁级缩放和特征分离操作来支持这一观点。<!--more-->

## 原理

EPT方法的核心创新在于将提示标记嵌入到扩展通道中，这种方式不仅保留了原始输入标记的信息，还引入了额外的有用上下文，从而实现对输入标记的细粒度优化。通过在Transformer的注意力计算中嵌入提示标记，EPT能够调整每个补丁级别的特征，实现补丁级缩放功能，这有助于减少同一类别样本在特征空间中的分布距离，增强特征的表示能力。此外，EPT通过增加特征维度，增强了特征的高维表达和解耦能力，从而在医学图像分类任务中展现出优越的性能。

## 流程

EPT的工作流程包括以下几个关键步骤：
1. **提示标记嵌入**：在输入图像的嵌入标记中嵌入可学习的提示标记。
2. **补丁级缩放**：在Transformer的注意力计算中，通过嵌入的提示标记实现对每个补丁级别特征的缩放。
3. **特征分离**：通过增加特征维度，增强特征的解耦能力。
4. **模型微调**：仅微调嵌入的提示标记和分类头，而保持模型的其他部分不变。
5. **评估与优化**：通过验证集确定最佳的提示长度，并在测试集上评估模型的性能。

## 应用

EPT方法在医学图像分析领域具有广泛的应用前景，特别是在少样本学习和跨域适应场景中。由于其参数高效和性能优越的特点，EPT可以被广泛应用于各种医学图像分类任务，如疾病诊断、病理分析等。此外，EPT的分布校准特性也使其在处理特征分布不均的医学图像数据时具有潜在优势。随着进一步的研究和优化，EPT有望成为医学图像分析领域的一种标准微调方法。