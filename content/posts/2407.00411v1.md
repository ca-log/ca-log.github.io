---
author: 'TechScribe'
title: '探索缺失数据对机器学习模型解释性的影响：插补方法的选择至关重要'
date: '2024-06-29'
Lastmod: '2024-07-05'
description: 'Explainability of Machine Learning Models under Missing Data'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Explainability of Machine Learning Models under Missing Data](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00411v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00411v1)

## 摘要

本文探讨了在缺失数据情况下机器学习模型的可解释性问题。缺失数据是一个普遍问题，可能严重影响模型的性能和解释性。论文通过实验研究了不同插补方法对Shapley值计算的影响，Shapley值是一种流行的解释复杂机器学习模型的技术。研究发现，插补方法的选择可能引入偏差，从而改变Shapley值，影响模型的解释性。此外，测试预测的均方误差（MSE）较低并不一定意味着Shapley值的MSE也较低。论文提供了关于选择合适插补方法的实用指导，强调了考虑插补效果以确保从机器学习模型中获得稳健和可靠洞察的重要性。<!--more-->

## 原理

Shapley值源自合作博弈理论，用于解释机器学习模型中每个特征对预测的贡献。它通过公平分配特征的边际贡献来确保特征重要性和交互作用的公正性。论文通过比较不同插补策略，探讨了它们如何影响模型的解释性和从Shapley值中得出的洞察的稳健性。理论分析显示，缺失数据对Shapley值的影响取决于插补方法和数据集的特性。

## 流程

论文首先介绍了Shapley值的基本概念和计算方法，然后详细描述了实验中使用的插补技术，包括XGBoost、均值插补、MICE、DIMV、missForest和SOFT-IMPUTE。实验设置包括数据集的选择、缺失值的模拟、实验的重复次数和计算环境。通过比较原始数据和插补后的数据的Shapley值，论文分析了不同插补方法对模型解释性的影响。

## 应用

论文的研究结果对于处理缺失数据并确保模型解释性的实践者具有重要指导意义。选择合适的插补方法对于确保模型解释性和预测性能至关重要。未来工作可以扩展到更广泛的数据集和机器学习模型，以及开发针对特定数据类型和模型结构的插补方法。