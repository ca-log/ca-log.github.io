---
author: 'TechScribe'
title: '探索工具增强的大型语言模型中的幻觉问题：ToolBH基准的全面诊断与分析'
date: '2024-06-28'
Lastmod: '2024-07-05'
description: 'ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.20015v1.pdf_0.jpg)](https://arxiv.org/abs/2406.20015v1)

## 摘要

本文介绍了一个名为ToolBH的综合诊断基准，用于评估工具增强的大型语言模型（LLMs）中的幻觉问题。由于缺乏相关基准，社区对这些模型中的幻觉问题理解不足。ToolBH基准通过深度和广度两个角度评估LLMs的幻觉现象。在深度方面，提出了一个多层次的诊断过程，包括可解决性检测、解决方案规划和缺失工具分析。在广度方面，考虑了基于工具集特征的三种场景：缺失必要工具、潜在工具和功能受限工具。此外，通过多轮人工注释收集了700个评估样本，并开发了相应的评估指标。实验结果显示，当前先进模型Gemini-1.5-Pro和GPT-4o在ToolBH基准上的总得分分别为45.3和37.0，表明模型参数的大小并不保证更好的性能，训练数据和响应策略在工具增强的LLM场景中也起着至关重要的作用。<!--more-->

## 原理

ToolBH基准通过两个主要维度评估工具增强的LLMs中的幻觉问题：深度和广度。在深度评估中，采用了一个多层次的诊断框架，包括三个阶段：
1. **可解决性检测**：评估模型是否能够判断给定的用户查询是否可以使用提供的工具集解决。
2. **解决方案规划**：要求模型根据任务需求提出一个工具使用计划，确保每个步骤都使用正确的工具。
3. **缺失工具分析**：在模型识别出某些任务步骤无法解决时，要求模型详细描述缺失工具的功能，以便进一步评估其推理能力。

在广度评估中，考虑了三种不同的工具可用性场景：
1. **缺失必要工具**：当工具集中缺少完成任务所需的工具时，模型可能会产生幻觉行为。
2. **潜在工具**：某些用户查询可能涉及特定的环境（如操作系统或网站），这些环境中可能包含未在用户请求中明确指定的潜在工具。
3. **功能受限工具**：工具可能具有多种功能，这可能导致误解。

通过这种多层次和多场景的评估，ToolBH基准能够全面地诊断和分析工具增强的LLMs中的幻觉问题，从而为模型的改进和优化提供指导。

## 流程

ToolBH基准的工作流程包括以下几个关键步骤：
1. **数据收集**：通过多轮人工注释收集了700个评估样本，每个样本包括用户查询、工具集和解决方案。
2. **深度评估**：使用多层次的诊断框架对模型进行评估，包括可解决性检测、解决方案规划和缺失工具分析。
3. **广度评估**：在三种不同的工具可用性场景下评估模型的表现，包括缺失必要工具、潜在工具和功能受限工具。
4. **结果分析**：根据评估结果，分析模型在不同任务和场景下的表现，识别模型在工具使用中的幻觉问题。

例如，在评估过程中，模型可能会在解决方案规划阶段错误地选择工具，或者在缺失工具分析阶段无法准确描述缺失工具的功能。通过这些具体的评估步骤和示例，ToolBH基准能够详细地揭示模型在工具使用中的幻觉行为。

## 应用

ToolBH基准的应用前景广泛，主要体现在以下几个方面：
1. **模型优化**：通过诊断和分析工具增强的LLMs中的幻觉问题，为模型的进一步优化提供方向和依据。
2. **训练数据改进**：识别模型在特定任务和场景下的表现不足，指导训练数据的改进和扩展。
3. **响应策略调整**：分析模型在不同评估阶段的响应策略，优化模型的输出质量和一致性。
4. **行业应用**：在实际应用中，如自动化任务处理、智能助手等领域，提高工具增强的LLMs的可靠性和准确性。

随着工具增强的LLMs在各个领域的广泛应用，ToolBH基准将成为评估和提升模型性能的重要工具，推动人工智能技术的进一步发展。