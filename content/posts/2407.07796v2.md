---
author: 'TechScribe'
title: '探索大型语言模型在游戏中的战略思维：一个创新的基准测试与排行榜'
date: '2024-07-10'
Lastmod: '2024-07-12'
description: 'Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07796v2.pdf_0.jpg)](https://arxiv.org/abs/2407.07796v2)

## 摘要

本文介绍了一种新颖且可扩展的大型语言模型（LLM）基准测试，通过基于网格的游戏如井字棋、四子棋和五子棋来进行评估。该基准测试提供了一个开源的游戏模拟代码，允许LLM在游戏中竞争，并生成详细的JSON、CSV、TXT和PNG格式的数据文件，用于排行榜排名和进一步分析。研究结果显示，不同LLM在不同游戏和提示类型中的表现存在显著差异，分析涵盖了胜率、淘汰率和无效移动分析。该研究增强了我们对LLM在未专门训练的游戏中能力的理解，有助于评估其规则理解和战略思维能力。在迈向通用人工智能（AGI）的道路上，本研究为进一步探索LLM在复杂决策场景中的实用性奠定了基础，揭示了其战略思维能力，并为未来对LLM在基于游戏框架中的极限的探索提供了方向。<!--more-->

## 原理

该基准测试通过模拟基于网格的游戏（如井字棋、四子棋和五子棋）来评估LLM的能力。游戏模拟代码是开源的，允许LLM在游戏中相互竞争，并生成详细的数据文件用于分析和排行榜排名。LLM在游戏中的表现通过胜率、淘汰率和无效移动等指标进行评估。此外，还分析了LLM在游戏中的战略决策能力，如错过胜利机会和阻止对手胜利的机会。通过这些分析，可以深入了解LLM在处理复杂和视觉提示格式时的能力限制，以及其在战略思维和决策制定方面的表现。

## 流程

游戏模拟的工作流程如下：用户通过网页界面选择游戏类型和参与的LLM模型，以及提示类型（列表、插图、图像）。游戏模拟开始后，系统将选择的提示发送给第一个LLM，并等待其移动。收到响应后，系统更新游戏状态，并发送给第二个LLM进行下一步移动。这个过程持续进行，直到游戏结束或玩家因无效移动被淘汰。每次移动的详细信息都被记录下来，包括游戏状态、LLM的响应和移动结果。这些数据以JSON、CSV、TXT和PNG格式存储，用于进一步分析和排行榜更新。

## 应用

该基准测试的应用前景广泛，不仅限于游戏领域。通过评估LLM在游戏中的表现，可以推断其在其他需要战略思维和决策制定的领域（如机器人、自动驾驶系统和交互式AI）中的潜在应用。此外，该基准测试的可扩展性允许未来加入更多类型的游戏和LLM模型，从而提供更全面的评估框架。通过社区的贡献和持续更新，该基准测试将成为评估和改进LLM能力的重要工具。