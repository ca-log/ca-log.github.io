---
author: 'TechScribe'
title: '探索大型语言模型的事实幻觉问题：基于知识图谱的虚假前提问题评估'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05868v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05868v1)

## 摘要

KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions 是一篇关于大型语言模型（LLMs）在面对虚假前提问题（FPQs）时产生事实幻觉问题的研究论文。论文提出了一种基于知识图谱（KGs）自动构建FPQs的方法，以评估LLMs在处理这些虚假信息时的性能。该研究通过创建一个包含约178,000个FPQs的综合基准（KG-FPQ），对多个代表性LLMs进行了广泛评估，揭示了LLMs在不同领域和任务格式下的表现差异。<!--more-->

## 原理

论文的核心工作原理是通过修改从知识图谱中提取的真实三元组（triplets）来创建虚假前提。具体步骤包括：首先，从知识图谱中提取真实三元组，然后通过编辑这些三元组的物体部分来创建虚假三元组。接着，利用GPT模型的先进能力，生成基于这些虚假三元组的语义丰富的FPQs。这种方法不仅自动化且可扩展，还允许在不同的知识领域和混淆级别上生成FPQs，从而全面评估LLMs对虚假信息的敏感性和处理能力。

## 流程

论文的工作流程包括以下几个关键步骤：
1. **三元组提取与编辑**：从知识图谱中提取真实三元组，并通过修改物体部分创建虚假三元组。
2. **数据生成**：使用GPT-3.5和GPT-4模型，根据虚假三元组生成Yes-No和WH格式的FPQs。
3. **数据验证**：通过人工审查确保数据质量，特别是在WH格式问题中纠正语法和语义错误。
4. **模型评估**：将生成的FPQs用于评估多个代表性和先进的LLMs，包括开源和闭源模型。
5. **自动评估**：引入一个名为FPQJudge的自动评估器，用于判断LLMs对FPQs的响应是否被虚假前提误导。

## 应用

KG-FPQ基准的应用前景广泛，主要体现在以下几个方面：
1. **模型评估与改进**：通过KG-FPQ基准，研究人员可以更准确地评估和改进LLMs在处理虚假信息方面的能力。
2. **安全性研究**：该基准有助于识别和缓解LLMs在面对虚假信息时的潜在安全风险，特别是在防止模型生成和传播错误信息方面。
3. **教育与培训**：KG-FPQ可以作为教育工具，帮助开发者和研究人员理解LLMs在实际应用中的局限性和挑战。
4. **政策制定**：该研究为政策制定者提供了关于如何监管和规范LLMs使用的科学依据。