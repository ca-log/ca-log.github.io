---
author: 'TechScribe'
title: '揭秘多语言大型语言模型的信息偏好：挑战与前景'
date: '2024-07-07'
Lastmod: '2024-07-10'
description: 'Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05502v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05502v1)

## 摘要

本文探讨了多语言大型语言模型（LLMs）在信息检索增强生成（RAG）系统中的信息差异问题。研究发现在多语言环境下，LLMs在信息检索和答案生成过程中存在系统性的语言偏好，倾向于使用与查询语言相同的语言文档，尤其是在查询语言为高资源语言时。这种偏好可能导致信息不平等，强化了语言特定的信息茧房，边缘化了低资源语言的观点。研究提出了新的多语言合成数据集，并通过实验验证了这些发现，强调了在多语言LLMs中实现信息平等的挑战。<!--more-->

## 原理

本文通过研究多语言LLMs在RAG系统中的行为，揭示了模型在处理多语言信息时的偏好。在信息检索阶段，模型倾向于检索与查询语言相同的文档，这种偏好不受查询类型的影响。在生成答案阶段，模型更倾向于使用与查询语言相同的文档内容来生成答案，即使存在其他语言的文档包含相关信息。这种行为是由于模型在训练过程中对某些语言的偏好，以及在实际应用中对高资源语言的依赖。

## 流程

研究团队设计了一个包含170个文档的多语言合成数据集，涵盖5种语言，模拟真实世界的信息环境。实验涉及13个多语言LLMs，通过7种不同类型的查询进行测试。工作流程包括两个主要阶段：检索和生成。在检索阶段，系统根据查询嵌入和文档嵌入的余弦相似度检索相关文档。在生成阶段，使用检索到的文档作为上下文来生成答案。实验结果显示，模型在检索和生成过程中都表现出对查询语言的偏好。

## 应用

本文的研究结果对多语言信息检索系统的设计和优化具有重要意义。了解和解决LLMs在多语言环境中的信息偏好问题，有助于提高信息检索的公平性和准确性，促进全球用户的信息平等访问。未来工作可以探索更有效的策略来平衡不同语言的信息权重，减少语言偏见，从而提升多语言LLMs的实用性和社会价值。