---
author: 'TechScribe'
title: '探索大型语言模型的规则颠覆：理论与实践的桥梁'
date: '2024-06-21'
Lastmod: '2024-07-05'
description: 'Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00075v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00075v1)

## 摘要

本文由宾夕法尼亚大学计算机与信息科学系的Anton Xue, Avishree Khare, Rajeev Alur, Surbhi Goel, 和 Eric Wong共同撰写，探讨了如何颠覆遵循规则的语言模型。文章通过将规则遵循建模为命题Horn逻辑中的推理，证明了即使理论上构建的模型能够忠实地遵循这些规则，恶意设计的提示仍然可以误导这些模型。实证研究发现，对理论模型的攻击与对大型语言模型的流行攻击相似。研究建议，通过研究较小的理论模型和定义明确的设置，可以深入理解大型语言模型在逻辑推理和越狱攻击中的行为。<!--more-->

## 原理

文章提出了一种基于逻辑的框架，用于分析规则颠覆（Section 2）。该框架将规则遵循建模为命题Horn逻辑中的推理，其中规则的形式为“如果P和Q，则R”。在此基础上，定义了三个属性——单调性、极大性和健全性，这些属性刻画了在此设置中的逻辑推理。该框架允许我们正式描述规则遵循，并让我们刻画模型不遵循规则的含义。

理论基础攻击转移到学习模型（Section 3）。首先考虑一个理论模型，用于研究如何颠覆从数据中训练出的推理器。该模型可以使用单层和单个自注意力头在提示的二值化编码上实现逻辑推理。此外，发现受限于我们理论中使用的尺寸的变换器（学习模型）可以高精度地学习逻辑推理，从而验证了理论推理器设置。此外，发现针对我们理论构造设计的两种攻击也对这些学习推理器有效。有趣的是，针对学习模型成功的标准对抗攻击策略与我们理论中提出的策略相似。这些发现展示了我们理论和学习推理器之间的联系。

流行越狱攻击反映理论基础攻击（Section 4）。发现针对LLM的越狱攻击与我们理论基础攻击的策略相似。特别是，发现成功越狱的特定注意力模式和令牌值与我们理论中研究的内容相似。我们的工作表明，对较小理论模型和定义明确设置的调查可以产生关于越狱在大规模语言模型中如何工作的见解。

## 流程

文章通过一个Minecraft视频游戏的例子来说明推理过程。给定一个配方列表和一些起始物品，玩家可能会形成以下提示来询问可以制作哪些其他物品：

```
Here are some crafting recipes: If I have Sheep, then I can create Wool. If I have Wool, then I can create String. If I have Log, then I can create Stick. If I have String and Stick, then I can create Fishing Rod. Here are some items I have: I have Sheep and Log as starting items. Based on these items and recipes, what items can I create?
```

通过将提示指定的指令翻译成一组推理规则Γ和已知事实Φ，模型使用前向链推理算法来推导所有可推导的命题。推理任务是找到所有可推导的命题集合。

## 应用

该研究的关键内容具有广泛的应用范围，特别是在提高大型语言模型的安全性和可靠性方面。通过理解越狱攻击的原理，开发者可以设计更有效的防护措施，确保模型在遵循规则的同时不会被恶意提示所误导。此外，该研究还为逻辑推理和语言模型的交互提供了新的视角，有助于推动相关领域的进一步发展。