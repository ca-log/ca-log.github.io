---
author: 'TechScribe'
title: '探索结构优化的未来：SOgym强化学习环境的创新与应用'
date: '2024-07-10'
Lastmod: '2024-07-11'
description: 'Structural Design Through Reinforcement Learning'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Structural Design Through Reinforcement Learning](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07288v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07288v1)

## 摘要

本文介绍了一种名为Structural Optimization gym (SOgym)的创新型开源强化学习环境，旨在推动机器学习在拓扑优化（TO）领域的应用。SOgym通过将物理学直接整合到奖励函数中，使RL代理能够学习生成物理上可行且结构上稳健的设计。为了增强可扩展性，SOgym利用特征映射方法作为与代理交互的网格无关接口，无论网格分辨率如何，都能有效处理设计变量。研究展示了使用无模型近端策略优化代理和基于模型的DreamerV3代理的基准结果。在三种观察空间配置中，受TopOpt游戏启发的配置在性能和样本效率方面表现最佳。DreamerV3的100M参数版本生成的结构在合规性方面达到了传统优化方法的54%，且断开率达到了0%，这一改进超过了监督学习方法。这些结果表明，强化学习有潜力解决连续的TO问题，并能够探索和学习多样化的设计解决方案。SOgym为开发复杂结构设计挑战的RL代理提供了一个平台，并公开可用以支持该领域的进一步研究。<!--more-->

## 原理

SOgym环境基于Gym框架，定义了代理与环境之间的交互。关键组件包括动作空间、观察空间和奖励函数。动作空间是一组连续动作，对应于拓扑的设计变量。观察空间表示当前TO问题的状态。奖励函数根据生成的结构的性能向代理提供反馈。SOgym使用特征映射方法作为更可扩展和可解释的接口，使RL代理能够与TO问题的材料分布交互。这种方法提供了两个主要优势：设计变量的数量与网格分辨率无关，增强了代理动作空间的可扩展性；设计变量具有几何可解释性，简化了最优拓扑的后处理阶段。SOgym使用改进的188行移动可变形组件（MMC）代码实现，代理在设计空间中顺序放置MMC组件，以在体积约束下创建最坚硬的结构。

## 流程

SOgym的工作流程包括代理在设计空间中顺序放置MMC组件，每个组件由端点坐标和两个厚度定义，形成线性变化的厚度。代理在每个步骤中放置组件，并进行有限元分析（FEA）以评估合规性。观察空间配置包括向量、图像和受TopOpt游戏启发的配置，其中TopOpt游戏配置提供了最丰富的观察，包括当前得分和归一化应变能的图像。奖励函数在最终时间步（𝑙?𝑚𝑎𝑥）提供稀疏奖励，对应于合规性的倒数，并带有体积和负载路径连通性的硬约束。如果结构的最终体积超过定义的约束或负载和支持断开，则奖励为0。SOgym使用自然对数压缩奖励信号，以使RL算法能够更好地泛化到多样化的环境。

## 应用

SOgym的应用前景广泛，特别是在需要复杂结构设计的领域，如航空航天、汽车和建筑行业。通过提供一个平台来开发和训练专门用于结构设计的RL算法，SOgym有望推动这些领域的设计创新和效率提升。此外，SOgym的开放源代码性质鼓励了该领域的进一步研究和应用，为未来的结构优化提供了新的可能性。