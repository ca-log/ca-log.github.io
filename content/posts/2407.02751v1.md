---
author: 'TechScribe'
title: '探索多模态对话中的情感与意图联合理解：MC-EIU数据集与EI2网络'
date: '2024-07-03'
Lastmod: '2024-07-05'
description: 'Emotion and Intent Joint Understanding in Multimodal Conversation: A Benchmarking Dataset'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Emotion and Intent Joint Understanding in Multimodal Conversation: A Benchmarking Dataset](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02751v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02751v1)

## 摘要

本文介绍了一种名为“多模态对话中的情感与意图联合理解”（MC-EIU）的新型基准数据集。该数据集旨在解码多模态对话历史中展现的语义信息，同时推断当前话语的情感和意图。MC-EIU是许多人机交互界面的使能技术，但目前缺乏在标注、模态、语言多样性和可访问性方面的可用数据集。本文提出的MC-EIU数据集具有7种情感类别、9种意图类别、3种模态（文本、声学和视觉内容）以及两种语言（英语和普通话），并且完全开源免费访问。此外，本文还开发了一个名为“情感与意图交互”（EI2）网络的参考系统，通过建模多模态对话中的情感与意图之间的深度关联，展示了所提出的EI2方法在MC-EIU数据集上的有效性。<!--more-->

## 原理

EI2网络通过以下组件实现情感与意图的联合理解：
1. **情感与意图编码器**：生成当前话语的多模态情感和意图表示。
2. **多模态历史编码器**：捕捉多模态历史中的上下文语义信息。
3. **情感-意图交互编码器**：学习对话中情感与意图之间的深度交互。
4. **情感与意图分类器**：基于情感-意图交互信息进行预测。

具体来说，情感与意图编码器通过视觉、文本和声学编码器提取特征，并通过Transformer融合网络生成多模态表示。多模态历史编码器使用GRU模型捕捉历史信息，并与当前话语的情感和意图特征融合。情感-意图交互编码器通过二元相关注意力、三重交互注意力和门控调节器学习情感与意图之间的深度交互信息，最终通过残差连接与分类器结合进行预测。

## 流程

1. **数据收集与预处理**：从英语和普通话的电视剧中收集对话视频片段，并进行预处理以提取文本、声学和视觉特征。
2. **数据标注**：招募标注者对情感、意图和说话者进行标注，使用多数投票策略确定最终标签。
3. **模型训练**：首先预训练情感与意图编码器，然后使用EI2网络进行联合训练，通过Focal Loss优化模型。
4. **模型评估**：在测试集上评估模型性能，使用加权平均F1分数（WAF）作为评价指标。

## 应用

MC-EIU数据集和EI2网络在情感与意图联合理解任务中具有广泛的应用前景，包括但不限于：
- **人机交互系统**：如虚拟助手和客户服务机器人。
- **心理健康辅导**：通过识别用户的情感和意图提供个性化支持。
- **教育技术**：分析学生的情感和意图，提供定制化教学。
- **娱乐产业**：改进交互式娱乐系统的用户体验。