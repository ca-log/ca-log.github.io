---
author: 'TechScribe'
title: '"VLM-PC：革新四足机器人自主导航的未来技术"'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02666v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02666v1)

## 摘要

本文介绍了一种名为VLM-Predictive Control (VLM-PC)的系统，该系统利用视觉-语言模型（VLMs）的常识推理能力，使四足机器人能够适应各种复杂的现实环境。VLM-PC通过结合上下文适应和未来技能规划两个关键组件，使机器人能够在没有详细人类指导的情况下，自主感知、导航和行动。研究团队在Go1四足机器人上进行了多项挑战性实验，结果显示VLM-PC显著提高了机器人在复杂环境中的自主导航能力。<!--more-->

## 原理

VLM-PC系统的工作原理基于两个关键技术：上下文适应和多步技能规划。上下文适应利用机器人与环境的交互历史，通过链式思维推理（chain-of-thought reasoning）来提高VLMs在新型情况下的鲁棒性。多步技能规划则促使模型提前规划多个技能步骤，并在每个时间步重新规划，以预见潜在的失败并作出调整。通过这两种技术的结合，VLM-PC能够生成一个历史条件下的高层次技能空间视觉模型预测控制。

## 流程

VLM-PC的工作流程如下：首先，机器人通过其摄像头获取当前视图和交互历史作为输入，VLM被提示生成一个多步技能计划。然后，模型根据机器人的当前状态和历史命令的进展，重新评估其多步计划，并在必要时进行调整。机器人执行计划中的第一个技能，然后VLM再次被查询以进行下一步的规划。例如，在一个实验中，机器人首先爬行通过沙发下方，然后当发现是死胡同时，它会退出并转向绕过沙发，爬过一个大的垫子，最终找到玩具。

## 应用

VLM-PC的应用前景广阔，特别是在需要机器人自主处理复杂、不可预测环境的场景，如搜索和救援任务、灾难响应、以及任何需要高度适应性和自主性的机器人操作。随着技术的进一步发展和优化，VLM-PC有望成为未来机器人技术中的一个重要组成部分。