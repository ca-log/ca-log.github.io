---
author: 'TechScribe'
title: '加速长音频合成：LiteFocus引领潜在扩散模型的新纪元'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'LiteFocus: Accelerated Diffusion Inference for Long Audio Synthesis'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![LiteFocus: Accelerated Diffusion Inference for Long Audio Synthesis](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10468v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10468v1)

## 摘要

本文由新加坡国立大学的研究团队提出，针对长音频合成中潜在扩散模型（Latent Diffusion Models）的推理效率问题，引入了一种名为LiteFocus的新方法。该方法通过优化模型的自注意力机制，实现了在长音频合成中的加速和质量提升。LiteFocus的核心创新在于采用双稀疏注意力计算形式，即同频聚焦（Same-frequency Focus）和跨频补偿（Cross-frequency Compensation），有效减少了计算量，同时保持了音频质量。实验结果表明，LiteFocus在合成80秒音频时，推理时间减少了1.99倍，同时音频质量得到改善。<!--more-->

## 原理

LiteFocus的工作原理主要基于对音频潜在扩散模型中自注意力机制的优化。传统的自注意力机制在处理长音频时，由于其O(N^2)的复杂度，导致计算成本急剧增加。LiteFocus通过识别和利用音频频谱图中的注意力模式，特别是同频带内的高交互性，实现了注意力计算的稀疏化。具体来说，LiteFocus将注意力计算分解为两个部分：同频聚焦和跨频补偿。同频聚焦专注于同一频率带内的交互，而跨频补偿则通过随机选择一部分跨频带的数据来补充全局上下文，从而在减少计算量的同时，保持了音频的连贯性和质量。

## 流程

LiteFocus的工作流程包括以下几个步骤：
1. **文本编码**：输入文本首先通过文本编码器转换为嵌入表示。
2. **迭代去噪**：使用U-Net架构在潜在空间中对采样的噪声进行迭代去噪，这一过程中LiteFocus优化了自注意力模块的计算。
3. **解码**：去噪后的潜在表示通过基于梅尔频谱图的变分自编码器（VAE）解码为音频。
4. **注意力优化**：在自注意力计算中，LiteFocus通过同频聚焦和跨频补偿机制，仅对特定频率带内的数据和随机选择的跨频数据进行注意力计算，大大减少了计算量。

## 应用

LiteFocus的应用前景广泛，特别是在需要高效处理长音频的场景中，如语音合成、音乐制作和辅助技术等。通过提高推理效率和音频质量，LiteFocus有助于推动文本到音频（TTA）技术在实际应用中的普及和优化。