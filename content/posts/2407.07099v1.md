---
author: 'TechScribe'
title: 'Nash CoT：降低成本，提升大型语言模型推理性能的新方法'
date: '2024-06-18'
Lastmod: '2024-07-11'
description: 'Nash CoT: Multi-Path Inference with Preference Equilibrium'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Nash CoT: Multi-Path Inference with Preference Equilibrium](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07099v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07099v1)

## 摘要

本文介绍了一种名为Nash Chain-of-Thought (Nash CoT)的新型推理方法，旨在提高大型语言模型（LLMs）在复杂问题上的推理能力，同时降低推理成本。Nash CoT通过将语言解码视为偏好共识游戏，构建了一个双玩家游戏系统，利用LLM自主选择上下文相关的模板并生成输出，以达到Nash均衡。这种方法在多个推理任务上实现了与现有方法相媲美或更优的性能，同时减少了所需的推理路径数量。<!--more-->

## 原理

Nash CoT的核心在于将语言解码过程概念化为一个偏好共识游戏，其中每个局部路径内构建一个双玩家游戏系统。具体来说，对于给定的问题，LLM自主选择上下文相关的模板，并根据此模板生成输出，旨在达到Nash均衡。这种方法通过引入偏好均衡（Preference Equilibrium），使得生成的输出在满足问题上下文的同时，保持一定的生成模式，从而在减少推理路径的同时保持或提升性能。

## 流程

Nash CoT的工作流程包括两个主要阶段：答案收集（Answer Gathering）和答案过滤（Answer Filtering）。在答案收集阶段，LLM通过多次生成（Mini-batch Loops）来收集候选答案，并在每次生成中寻找模板引导的生成（y*）。在答案过滤阶段，系统统计满足偏好均衡的答案频率，并选择最频繁的答案作为最终输出。例如，在硬币翻转问题中，LLM生成多个答案，最终选择达到偏好均衡的答案作为最终答案。

## 应用

Nash CoT的应用前景广泛，特别适用于需要复杂推理的任务，如阿拉伯语推理、常识问答和符号推理等。由于其能够在减少推理路径的同时保持或提升性能，Nash CoT有望在各种实际应用中降低成本，提高效率，尤其是在资源受限的环境中。