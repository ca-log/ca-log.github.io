---
author: 'TechScribe'
title: '利用LLMs跳过老虎机的冷启动阶段：一种创新的个性化推荐方法'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Jump Starting Bandits with LLM-Generated Prior Knowledge'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Jump Starting Bandits with LLM-Generated Prior Knowledge](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19317v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19317v1)

## 摘要

本文介绍了一种创新的方法，通过将大型语言模型（LLMs）与上下文多臂老虎机（Contextual Multi-Armed Bandit, CBs）框架结合，来优化推荐系统中的个性化建议。文章展示了LLMs在模拟人类行为和偏好方面的能力，能够有效地初始化上下文多臂老虎机，从而减少在线学习中的遗憾（regret）。通过提示LLMs生成用户偏好的预训练数据集，这种方法显著降低了训练这些模型的在线学习遗憾和数据收集成本。实验结果表明，该方法在不同的老虎机设置中都能有效减少早期遗憾，特别是在使用真实世界数据的选择型联合调查实验中。<!--more-->

## 原理

本文提出的方法利用LLMs生成合成奖励分布，用于预训练上下文多臂老虎机（CBs）。LLMs通过预训练在大量包含人类知识和偏好的语料库上，能够很好地模拟人类行为。在初始化CBs时，LLMs被用来生成一个包含近似人类偏好的预训练数据集。这种方法的核心在于，即使LLMs生成的奖励分布不完全匹配真实人类偏好，它们仍然提供了一个比冷启动CBs更好的随机基准。通过这种方式，LLMs能够帮助CBs在早期阶段做出更有效的选择，减少遗憾。

## 流程

文章描述了两种实验设置来验证这种方法的有效性。第一种实验设置是标准上下文多臂老虎机，其中臂代表不同风格的营销沟通，用于从模拟用户那里募集慈善捐款。第二种实验设置是使用真实世界人类偏好的睡眠老虎机（sleeping bandit）。在每种设置中，LLMs被用来生成用户交互和他们的偏好数据，然后这些数据被用来预训练CBs。预训练后的模型在实际用户交互数据上进行微调，以进一步优化性能。具体的工作流程包括生成合成用户、计算文本嵌入、模拟用户偏好、生成奖励分布，并使用这些数据预训练CBs。

## 应用

这种方法的应用前景广泛，特别是在需要个性化内容推荐的系统中，如电子邮件营销、新闻推荐和产品推荐等。通过减少数据收集成本和提高个性化推荐的准确性，这种方法有助于提高用户体验和系统的整体性能。此外，使用LLMs生成用户数据和模拟偏好，不仅降低了数据收集的成本，还缓解了隐私问题，因为不需要使用真实的用户数据。