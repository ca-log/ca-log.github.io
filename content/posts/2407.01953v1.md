---
author: 'TechScribe'
title: '"数据融合与微调：提升大型语言模型在金融领域的应用性能"'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01953v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01953v1)

## 摘要

本文介绍了在IJCAI-2024 FinLLM挑战赛中，如何利用数据融合技术对大型语言模型（LLMs）进行微调，以提高其在金融领域的应用性能。研究聚焦于金融分类、金融文本摘要和单一股票交易三个关键任务，通过采用Llama3-8B和Mistral-7B作为基础模型，并应用参数高效微调（PEFT）和低秩适应（LoRA）技术，结合任务1和任务2的数据集进行数据融合，以提升模型在复杂金融任务中的准确性和决策能力。<!--more-->

## 原理

本文的核心工作原理在于通过数据融合策略，对预训练的大型语言模型进行微调，以适应特定的金融任务。具体来说，使用了Llama3-8B和Mistral-7B这两个具有大量参数的模型，这些模型能够捕捉金融文本数据中的复杂模式和细微差别。通过PEFT和LoRA技术，即使在有限的标记数据情况下，也能有效地对模型进行专业化调整，使其更好地适应金融领域的特定任务。此外，数据融合策略通过结合不同任务的数据集，增强了模型的泛化能力和对金融文本的理解能力。

## 流程

论文提出的工作流程包括以下几个步骤：首先，从金融文本分类和金融文本摘要两个任务中筛选和预处理训练数据集。其次，选择Llama3-8B和Mistral-7B作为预训练的基础模型，并应用PEFT和LoRA技术进行微调。接着，将微调后的模型应用于三个不同的金融任务中，包括金融分类、文本摘要和单一股票交易，以评估其在实际金融应用中的效能和性能。具体实验结果显示，Mistral-7B模型在分类和摘要任务中表现优异，但在单一股票交易任务中未见显著提升。

## 应用

本文提出的方法在金融领域的多个应用场景中展现出潜力，特别是在金融文本分析、风险评估和投资决策支持等方面。通过提高模型的准确性和决策能力，可以为金融分析师和投资者提供更强大的工具，帮助他们更好地理解和处理复杂的金融信息。未来，随着更多数据和更先进技术的应用，这些模型在金融领域的应用前景将更加广阔。