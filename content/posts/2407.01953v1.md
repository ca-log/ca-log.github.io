---
author: 'TechScribe'
title: '"金融智能新突破：大型语言模型在FinLLM挑战中的应用与前景"'
date: '2024-07-02 05:04:13+00:00'
Lastmod: '2024-07-04 01:17:40.872817'
description: 'CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01953v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01953v1)

## 摘要

本文介绍了在IJCAI-2024 FinLLM挑战赛中，如何利用数据融合技术对大型语言模型（LLMs）进行微调，以提高其在金融领域的应用性能。研究聚焦于金融文本分类、文本摘要和单股票交易三个关键任务，通过采用Llama3-8B和Mistral-7B作为基础模型，并结合参数高效微调（PEFT）和低秩适应（LoRA）技术，实现了对这些复杂金融任务的精确处理和决策支持。<!--more-->

## 原理

本文的核心工作原理在于通过数据融合策略对预训练的大型语言模型进行微调。具体来说，选择了Llama3-8B和Mistral-7B这两个具有大量参数的模型，这些参数使得模型能够捕捉到金融文本数据中的复杂模式和细微差别。通过PEFT和LoRA技术，即使在有限的标记数据情况下，也能有效地对模型进行专业化调整，以适应金融领域的特定任务。此外，数据融合策略通过结合任务1和任务2的数据集，进一步增强了模型的性能和适应性。

## 流程

论文提出的工作流程包括以下几个步骤：首先，从金融文本分类和金融文本摘要两个任务中筛选和预处理训练数据集。然后，使用这些数据集对预训练的LLMs进行微调，主要采用PEFT和LoRA技术。微调后的模型随后被应用于三个具体任务中进行评估。例如，在金融文本分类任务中，模型需要区分文本中的主张和前提；在文本摘要任务中，模型则需要将长篇金融文档精炼为简洁的摘要。

## 应用

本文提出的方法在金融领域的多个应用场景中展现出广阔的前景。通过提高金融文本处理的准确性和效率，这些模型可以支持更精确的市场分析、风险评估和投资决策。特别是在金融监管、投资顾问服务和自动化交易系统中，这些技术的应用有望显著提升业务流程的智能化水平。