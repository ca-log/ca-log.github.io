---
author: 'TechScribe'
title: '"金融领域的语言模型革命：数据融合与微调技术的突破"'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01953v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01953v1)

## 摘要

本文介绍了在IJCAI-2024 FinLLM挑战赛中，如何通过数据融合技术对大型语言模型（LLMs）进行微调，以提高其在金融领域的应用性能。研究主要集中在金融文本分类、金融文本摘要和单一股票交易三个关键任务上。通过采用Llama3-8B和Mistral-7B作为基础模型，并结合参数高效微调（PEFT）和低秩适应（LoRA）技术，本文展示了LLMs在处理复杂金融任务时的改进精度和决策能力。<!--more-->

## 原理

本文的核心在于利用PEFT和LoRA技术对预训练的LLMs进行微调，以适应特定的金融任务。PEFT技术通过仅调整模型的一小部分参数，实现高效的模型适应性，而LoRA则通过低秩分解来减少模型参数，从而在保持性能的同时降低计算成本。这两种技术的结合使得模型能够更好地捕捉金融文本中的复杂模式和细微差别，同时保持对大规模数据集的广泛理解。

## 流程

论文提出的工作流程包括以下几个步骤：首先，选择Llama3-8B和Mistral-7B作为基础模型，这两个模型因其大量的参数和广泛的预训练数据集而被选中。接着，通过PEFT和LoRA技术对这些模型进行微调，特别是在金融文本分类和金融文本摘要任务的数据集上进行训练。最后，将微调后的模型应用于所有三个任务，以评估其在实际金融应用中的效用和性能。例如，在金融文本分类任务中，模型需要区分金融文档中的主张和前提，而在文本摘要任务中，模型则需要将长篇金融报告浓缩为简洁的摘要。

## 应用

本文的研究成果在金融领域的多个应用场景中具有广阔的前景。通过提高金融文本处理的准确性和效率，LLMs可以帮助投资者和金融机构更好地理解和分析市场信息，从而做出更明智的投资决策。此外，这些技术还可以应用于风险评估、市场预测和自动化交易系统中，进一步推动金融科技的发展。