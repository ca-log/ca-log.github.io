---
author: 'TechScribe'
title: 'CodeV：通过多级摘要技术革新Verilog代码生成'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'Empowering LLMs for Verilog Generation through Multi-Level Summarization'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Empowering LLMs for Verilog Generation through Multi-Level Summarization](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10424v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10424v1)

## 摘要

本文介绍了CodeV，一系列用于Verilog代码生成的指令调优大型语言模型（LLMs）。面对现代处理器设计复杂性和高成本带来的自动化需求，以及现有LLMs在Verilog生成上的局限性，CodeV通过多级摘要技术，利用真实世界的高质量Verilog代码，生成自然语言描述，进而构建高质量的指令调优数据集。实验结果显示，CodeV在VerilogEval和RTLLM基准测试中相对超越了之前的开源和商业SOTA模型，显示出在电路设计自动化领域的广阔应用前景。<!--more-->

## 原理

CodeV的工作原理基于以下观察：（1）真实世界的Verilog代码质量高于LLMs生成的代码；（2）LLMs如GPT-3.5擅长总结Verilog代码而非生成。CodeV通过收集和过滤高质量的Verilog模块，利用GPT-3.5进行多级摘要，生成高层次描述，并与相应模块配对，构建高质量数据集。随后，对基础LLMs进行微调，生成CodeV模型。这种方法通过逆向指令生成，即先提供Verilog代码，再由LLM生成相应自然语言描述，有效提升了Verilog代码生成的质量和准确性。

## 流程

CodeV的工作流程包括以下步骤：
1. 从GitHub等开源代码库中收集超过150万行Verilog代码，进行过滤和去重，确保代码的完整性和语法正确性。
2. 使用GPT-3.5对这些高质量Verilog模块进行多级代码摘要，生成详细的功能描述和高层次需求总结。
3. 将这些描述与代码配对，形成高质量的指令调优数据集。
4. 对基础LLMs（如CodeLlama, DeepSeekCoder, CodeQwen）进行监督微调，生成CodeV系列模型。
例如，对于一个Verilog模块，GPT-3.5首先生成其功能描述，然后总结出高层次的设计需求，最终形成一个描述-代码对，用于训练CodeV模型。

## 应用

CodeV在电路设计自动化领域具有广泛的应用前景。其高质量的Verilog代码生成能力可以显著降低电路设计的门槛和成本，加速新产品的开发周期。此外，CodeV的开源模型和数据集将促进LLM、电子设计自动化（EDA）和编程语言社区的进一步研究和合作。