---
author: 'TechScribe'
title: 'AutoRAG-HP：革新RAG系统超参数优化的在线自适应框架'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19251v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19251v1)

## 摘要

本文介绍了一种名为AutoRAG-HP的框架，旨在解决在大型语言模型（LLMs）背景下，检索增强生成（RAG）系统中超参数优化和在线适应的挑战。该框架将超参数调整问题形式化为一个在线多臂老虎机（MAB）问题，并引入了一种新颖的两级层次MAB（Hier-MAB）方法，以高效地探索大型搜索空间。通过在ALCE-ASQA和Natural Questions数据集上进行广泛的实验，证明了基于MAB的在线学习方法在搜索空间具有显著梯度的场景中，能够实现Recall@5 ≈ 0.8，仅使用网格搜索方法所需LLM API调用的约20%。此外，提出的Hier-MAB方法在更具挑战性的优化场景中表现优于其他基线。<!--more-->

## 原理

AutoRAG-HP框架的核心在于将RAG系统中的超参数选择问题转化为一个在线多臂老虎机（MAB）问题。MAB问题是一种序列决策问题，要求代理在探索不同臂（即超参数组合）以学习其奖励概率和利用已知能产生较高奖励的臂之间进行平衡。通过引入两级层次MAB（Hier-MAB）方法，该框架在高层MAB中选择要调整的超参数，在低层MAB中搜索每个超参数的最佳设置。这种层次结构使得每个MAB都有合理的臂数进行选择，同时所有MAB组合能够覆盖大型搜索空间。

## 流程

AutoRAG-HP的工作流程包括以下步骤：
1. **问题形式化**：将超参数调整问题形式化为一个MAB问题。
2. **两级层次MAB**：在高层MAB中选择要调整的超参数，在低层MAB中搜索每个超参数的最佳设置。
3. **实验设置**：使用ALCE-ASQA和Natural Questions数据集进行实验，评估不同超参数组合的效果。
4. **奖励设置**：引入权重参数w来平衡令牌长度和准确性之间的权衡。
5. **优化算法**：采用UCB作为每个臂选择的优化算法，命名为Hier-UCB。
6. **基线方法比较**：与UCB、Thompson Sampling和随机搜索等基线方法进行比较。
7. **评估指标**：使用Recall@x作为评估指标，通过与网格搜索方法的结果进行比较来评估在线学习方法的性能。

## 应用

AutoRAG-HP框架的应用前景广泛，特别是在需要高效和自适应超参数调整的RAG系统中。该框架不仅能够提高系统的性能，还能够减少LLM API调用的成本，适用于各种需要优化超参数的场景，如文档块大小、LLM API设置或其他基于LLM的解决方案（如代理框架）。此外，该框架还可以扩展到离线超参数调整，为大型搜索空间提供更高效的参数扫描方法。