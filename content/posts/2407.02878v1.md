---
author: 'TechScribe'
title: '高效融合与任务导向嵌入：自动驾驶的新里程碑'
date: '2024-07-03 07:45:58+00:00'
Lastmod: '2024-07-04 01:53:03.021517'
description: 'Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02878v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02878v1)

## 摘要

本文由浙江大学的Yipin Guo, Yilin Lang, Qinyuan Ren共同撰写，题为“Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving”。论文主要针对自动驾驶系统中的传感器融合和安全风险预测问题，提出了一种名为EfficientFuser的高效解决方案。该方案利用EfficientViT进行视觉信息提取，并通过交叉注意力机制整合特征图，再利用仅解码器的Transformer进行多特征融合。此外，论文还引入了可学习的向量作为嵌入令牌，通过注意力机制探索任务与传感器特征之间的关联。在CARLA模拟平台上进行的评估显示，EfficientFuser在参数和计算量上显著减少，同时保持了高水平的驾驶性能和安全性。<!--more-->

## 原理

EfficientFuser的核心创新在于其高效的视觉信息处理和特征融合机制。首先，利用EfficientViT作为视觉主干，从多视角图像中提取特征。EfficientViT通过级联组注意力机制，能够在保持效率的同时，处理小尺寸的图像块，从而减少计算资源的需求。接着，通过交叉注意力机制，EfficientFuser能够无缝整合来自不同视角的特征信息，这种机制允许模型在不同尺度的特征图之间进行信息交换，增强了环境理解的丰富性。最后，仅解码器的Transformer架构被用于预测过程，其中嵌入了可学习的向量，这些向量在训练过程中学习任务相关的信息，通过注意力机制找到任务与传感器特征之间的联系，从而提高了预测的准确性和效率。

## 流程

EfficientFuser的工作流程可以分为三个主要阶段：特征提取、特征融合和预测。在特征提取阶段，多视角的RGB图像被输入到EfficientViT中，提取出视觉特征。在特征融合阶段，通过交叉注意力机制，这些特征被整合成一个统一的特征表示。在预测阶段，仅解码器的Transformer利用这些融合的特征和嵌入的可学习向量进行预测，生成控制指令和路径点。例如，在CARLA模拟环境中，EfficientFuser能够根据前视图和侧视图的图像信息，预测出安全的驾驶路径和相应的控制动作。

## 应用

EfficientFuser的设计使其非常适合于实际的自动驾驶系统部署，特别是在计算资源受限的车载计算机环境中。其高效的模型大小和计算需求，以及优秀的驾驶性能和安全性，使其成为自动驾驶技术商业化的有力候选。此外，EfficientFuser的模块化设计也为其在不同自动驾驶场景和平台上的应用提供了灵活性，预示着广阔的应用前景。