---
author: 'TechScribe'
title: '高效融合与任务导向嵌入：自动驾驶的新里程碑'
date: '2024-07-03'
Lastmod: '2024-07-05'
description: 'Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02878v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02878v1)

## 摘要

本文由浙江大学的Yipin Guo, Yilin Lang, Qinyuan Ren共同撰写，题为“Efficient Fusion and Task Guided Embedding for End-to-end Autonomous Driving”。该论文主要针对自动驾驶系统中的传感器融合和安全风险预测问题，提出了一种名为EfficientFuser的高效解决方案。该方案利用EfficientViT进行视觉信息提取，并通过交叉注意力机制整合特征图，再结合解码器仅用变换器进行多特征融合。此外，通过嵌入可学习向量作为令牌，利用注意力机制探索任务与传感器特征之间的关联。在CARLA模拟平台上进行的评估显示，EfficientFuser在参数和计算量上远低于现有轻量级方法，且驾驶评分接近领先的安全增强方法，显示出其在实际自动驾驶系统部署中的有效性和潜力。<!--more-->

## 原理

EfficientFuser的核心工作原理基于以下几个关键技术：首先，使用EfficientViT作为视觉骨干网络，提取多视角图像的视觉信息。其次，通过交叉注意力机制，将不同视角的特征图进行融合，这一过程允许模型在不同尺度上无缝集成多视角信息，而不会过度增加计算负担。最后，采用仅用解码器的变换器架构进行预测，其中嵌入了可学习向量，这些向量在解码器层中早期阶段与其他令牌共同学习，以发现任务与传感器特征之间的关联。这种设计不仅提高了模型的效率，还增强了其在复杂驾驶场景中的适应性和安全性。

## 流程

EfficientFuser的工作流程可以分为三个主要步骤：首先，从多视角RGB图像中提取图像特征，使用EfficientViT作为视觉骨干网络。其次，通过交叉注意力机制融合这些特征图，这一步骤确保了不同视角的信息能够有效且高效地集成。最后，使用仅用解码器的变换器进行预测，其中嵌入了可学习向量，这些向量在解码器层中早期阶段与其他令牌共同学习，以发现任务与传感器特征之间的关联。例如，在CARLA模拟平台上的测试中，EfficientFuser能够有效地处理复杂的驾驶场景，如多车道、高速公路出口、桥梁和地下通道等，显示出其强大的实时处理能力和低延迟特性。

## 应用

EfficientFuser的设计使其非常适合应用于资源受限的自动驾驶系统中，如小型车辆或无人机。其高效的计算和参数使用率意味着它可以在较低的硬件配置下运行，同时保持高性能。此外，由于其模块化的设计，EfficientFuser可以轻松集成到现有的自动驾驶系统中，或与其他先进技术结合，进一步提高系统的整体性能。随着自动驾驶技术的不断发展，EfficientFuser有望成为推动该领域向前迈进的关键技术之一。