---
author: 'TechScribe'
title: '探索语法掩蔽：提升大型语言模型在模型生成任务中的语法正确性'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06146v2.pdf_0.jpg)](https://arxiv.org/abs/2407.06146v2)

## 摘要

本文介绍了一种名为“语法掩蔽”的方法，用于指导大型语言模型（LLM）生成符合给定上下文无关语法（CFG）的语法正确模型。传统的提示工程方法如少样本学习或引导虽然可以提高LLM生成正确语法模型的概率，但随着语法复杂性的增加，这些方法变得耗时且效果不佳。本文提出的方法通过约束解码确保输出遵循有效的语法结构，使用多个基于MontiCore构建的DSL和多个LLM进行测试，并通过相应的解析器验证每个模型的语法正确性。结果显示，语法掩蔽可以显著提高多个LLM的建模能力，减少对精细提示的需求，同时增加生成正确模型的机会。<!--more-->

## 原理

语法掩蔽方法的核心在于使用给定DSL的上下文无关语法（CFG）来过滤掉LLM生成过程中任何语法无效的输出。该方法通过约束解码技术，确保LLM的输出严格遵循预定义的语法规则。具体来说，该方法利用Guidance框架，将DSL的语法转换为Lark语法，并通过Guidance进行约束解码。Guidance框架通过在线解析器引导生成，同步解析器和扫描器与LLM，动态确定每一步的有效令牌。此外，Guidance还引入了提交点，强制解析器提交到特定的解析路径，有效地修剪搜索空间并避免回溯。

## 流程

1. **初始化**：使用MontiCore语法构建DSL，并将其转换为Lark语法。
2. **约束解码**：通过Guidance框架，将转换后的语法提供给LLM，进行约束解码。
3. **生成模型**：LLM根据约束解码生成模型，这些模型通过解析器进行语法验证。
4. **验证与优化**：验证生成的模型是否符合语法规则，并根据需要进行优化。

例如，对于一个简单的类图DSL（CD4A），LLM首先生成一个初始模型，然后通过Guidance框架的解析器进行验证。如果模型不符合语法规则，解析器会指导LLM进行修正，直到生成符合语法规则的模型。

## 应用

语法掩蔽方法的应用前景广泛，特别是在模型驱动的软件工程（MDSE）和领域特定语言（DSL）的生成任务中。该方法不仅可以提高LLM生成模型的语法正确性，还可以减少对精细提示的依赖，使得模型生成更加高效和可靠。此外，该方法还可以扩展到其他基于MontiCore的DSL，甚至可以应用于任何可以转换为Lark语法的语法。随着进一步的研究和优化，语法掩蔽方法有望在更多的领域和场景中得到应用。