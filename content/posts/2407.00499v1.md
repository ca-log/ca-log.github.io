---
author: 'TechScribe'
title: '探索LLMs中的不确定性：一种新的保形预测方法'
date: '2024-06-29'
Lastmod: '2024-07-05'
description: 'ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00499v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00499v1)

## 摘要

本文探讨了在自然语言生成（NLG）任务中，大型语言模型（LLMs）的不确定性量化（UQ）问题。针对LLMs在生成过程中可能产生的幻觉和错误，研究者提出了一种基于采样和自一致性的不确定性度量方法，并结合了保形预测（CP）技术，以提供严格理论保证的预测集。该方法通过在多个开放式NLG数据集上进行实验，证明了其优于现有方法的性能，并能够在不固定答案分布的模型中严格控制正确答案的覆盖率。<!--more-->

## 原理

本文提出的方法ConU利用了LLMs的自一致性和采样技术来量化不确定性。首先，通过采样多个答案并进行语义聚类，计算每个生成的不确定性分数。接着，利用保形预测技术，将这些不确定性分数转化为具有理论保证的预测集。具体来说，保形预测通过计算非一致性分数（NS）的量化值，确保预测集包含正确答案的概率至少为用户指定的概率。这种方法不仅适用于黑箱LLMs，而且能够在不访问模型内部状态的情况下，提供严格的不确定性估计。

## 流程

1. **采样与聚类**：对每个输入提示，模型生成多个候选答案，并对这些答案进行语义聚类。
2. **不确定性度量**：计算每个候选答案的不确定性分数，考虑其语义频率和与其他聚类的语义一致性。
3. **非一致性分数计算**：对于每个校准样本，选择与参考答案语义最一致且相似度最高的生成，计算其非一致性分数。
4. **保形预测集构建**：利用校准样本的非一致性分数，计算不确定性阈值，并据此构建测试样本的预测集。
5. **正确性覆盖保证**：验证预测集是否包含正确答案，并确保在用户指定的错误率下，预测集的正确覆盖率。

## 应用

ConU方法适用于各种需要高可靠性保证的NLG应用场景，特别是在医疗、法律等高风险领域。通过提供严格的不确定性量化和正确性覆盖保证，ConU有助于增强用户对LLMs生成内容的信任，推动LLMs在实际应用中的广泛部署。