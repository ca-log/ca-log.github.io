---
author: 'TechScribe'
title: '探索大型语言模型在代码生成中的编码风格一致性：挑战与解决方案'
date: '2024-06-29'
Lastmod: '2024-07-05'
description: 'Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00456v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00456v1)

## 摘要

本文探讨了大型语言模型（LLMs）在代码生成中的编码风格一致性问题。尽管LLMs在代码生成方面取得了显著进展，但以往研究主要集中在代码生成的功能正确性上，而对LLMs与人类开发者之间编码风格差异的研究较少。本文通过实证分析，比较了主流代码LLMs生成的代码与人类开发者编写的代码在可读性、简洁性和鲁棒性方面的差异，并总结了编码风格不一致的分类。研究结果揭示了LLMs和开发者之间在编码风格上的显著差异，并探讨了这些不一致的可能原因及解决方案。<!--more-->

## 原理

本文通过手动分析大量代码生成结果，总结了编码风格不一致的类型，并将其分类为五个维度：格式不一致、语义不一致、表达/声明不一致、控制流不一致和容错不一致。研究团队比较了LLMs生成的代码与人类编写的代码，发现LLMs在某些编码风格上与人类开发者存在显著差异，特别是在声明/表达和格式维度上。此外，研究还探讨了可能导致这些不一致的原因，并提出了通过提示工程改善编码风格的策略。

## 流程

研究团队首先选择了四个主流的开源代码LLMs（CodeLlama-7B, StarCoder2-7B, DeepSeekCoder1.3B, DeepSeekCoder-6.7B），并在CoderEval基准上进行了实验。通过手动分析这些模型的代码生成结果，并与基准中的真实代码进行比较，总结了24种编码风格不一致类型。随后，研究团队分析了这些不一致的分布，包括不一致的比例、频率和不同模型间的差异。最后，通过实验不同的提示策略，探索了改善代码LLMs编码风格的方法。

## 应用

本文的研究成果不仅提供了对LLMs编码风格不一致性的深入理解，还为未来的研究和开发提供了实用的解决方案。这些发现可以应用于改进现有的代码生成模型，使其生成的代码更符合人类开发者的编码习惯，从而提高代码的可读性和可维护性。此外，这些研究成果还可以帮助开发者在选择和使用代码生成工具时，更好地理解和评估其生成的代码质量。