---
author: 'TechScribe'
title: '深度伪造音频检测的新突破：基于频谱图和深度学习模型的集成系统'
date: '2024-07-01 20:10:43+00:00'
Lastmod: '2024-07-04 01:17:47.724422'
description: 'Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of Deep Learning Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of Deep Learning Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01777v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01777v1)

## 摘要

本文提出了一种基于深度学习的系统，用于检测深度伪造音频。该系统通过将输入音频转换为多种频谱图，并利用多种深度学习模型进行分类，以识别音频的真伪。研究在ASVspoof 2019基准数据集上进行了评估，最佳集成模型达到了0.03的等误差率（EER），显示出高度的竞争力。实验结果强调了选择性频谱图和深度学习方法在增强音频深度伪造检测任务中的潜力。<!--more-->

## 原理

本文的核心在于通过多种频谱图转换方法（如短时傅里叶变换STFT、常数Q变换CQT、小波变换WT）和听觉滤波器（如Mel、Gammatone、线性滤波器LF）生成频谱图，然后利用深度学习模型进行分类。具体包括三种深度学习方法：直接训练频谱图的端到端方法、从计算机视觉模型微调的转移学习方法，以及利用预训练音频模型提取音频嵌入的音频嵌入方法。最终，通过融合这些方法中的高性能模型来达到最佳性能。

## 流程

1. 输入音频首先被分割成2秒的片段，然后转换为频谱图。
2. 使用三种深度学习方法处理这些频谱图：
   - 端到端方法：直接使用CNN、RNN和CRNN模型训练频谱图。
   - 微调方法：微调计算机视觉领域的基准网络架构，如ResNet-18、MobileNet-V3等。
   - 音频嵌入方法：利用预训练的音频模型（如Whisper、Speechbrain、Pyannote）提取音频嵌入，然后通过MLP模型进行分类。
3. 通过平均每个2秒片段的预测概率来计算整个音频记录的预测概率。
4. 使用MEAN融合技术集成各个模型的结果，最终确定音频样本的真伪。

## 应用

该研究为深度伪造音频检测提供了强有力的技术支持，适用于各种依赖语音识别的系统，如智能家居设备、语音银行、家庭自动化系统和虚拟助手。随着深度伪造技术的不断发展，该系统的应用前景广阔，对于保护语音激活系统的完整性和真实性具有重要意义。