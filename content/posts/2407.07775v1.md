---
author: 'TechScribe'
title: 'Mobility VLA：革命性的多模态指令导航系统'
date: '2024-07-10'
Lastmod: '2024-07-11'
description: 'Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07775v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07775v1)

## 摘要

本文介绍了一种名为Mobility VLA的新型导航系统，该系统利用长上下文视觉语言模型（VLMs）和拓扑图来实现多模态指令导航。Mobility VLA通过结合高层次的VLM和低层次的基于拓扑图的导航策略，能够理解包括自然语言和图像在内的多模态输入，并执行有效的导航任务。该系统在836平方米的真实环境中进行了评估，显示出在处理先前未解决的多模态指令（如“我应该把这个还到哪里？”同时手持塑料箱）时具有高成功率。<!--more-->

## 原理

Mobility VLA的工作原理基于分层导航策略。高层次策略使用长上下文VLM处理演示视频和多模态用户指令，以识别视频中的目标帧。低层次策略则利用目标帧和离线构建的拓扑图来生成机器人在每个时间步的行动指令。这种分层设计充分利用了VLM的环境理解和常识推理能力，同时通过拓扑图确保了导航行动的准确性和效率。

## 流程

Mobility VLA的工作流程包括两个主要阶段：离线阶段和在线阶段。在离线阶段，系统从演示视频中构建拓扑图。在线阶段，系统首先使用VLM处理用户的多模态指令和演示视频，确定导航目标帧。随后，低层次策略利用拓扑图和当前摄像头观察来计算并执行导航行动。例如，当用户询问“我应该把这个还到哪里？”时，系统会识别出视频中的相关帧，并指导机器人导航到相应位置。

## 应用

Mobility VLA的应用前景广泛，特别适用于需要复杂环境理解和多模态交互的场景，如智能家居、办公自动化和辅助导航等。该系统的成功实施表明，未来机器人能够更加自然和直观地与人类交互，极大地提升了机器人的实用性和普及性。