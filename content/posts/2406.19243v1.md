---
author: 'TechScribe'
title: '"革新语音识别：ASV系统在VC与TTS模型中的先进应用"'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Application of ASV for Voice Identification after VC and Duration Predictor Improvement in TTS Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19243v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19243v1)

## 摘要

本文探讨了自动说话人验证系统（ASV）在语音识别领域的应用，特别是在语音转换（VC）和文本到语音（TTS）模型改进后的声音识别。文章指出，随着神经网络质量的提升，语音数据操纵技术如VC和TTS模型也日益增多，这为语音生物识别伪造领域带来了挑战。论文提出的系统通过提取目标说话者的音频嵌入，获取其声音的重要特征，如音高、能量和音素持续时间，以验证经过语音转换的用户声音。该模型在SSTC挑战中展示了20.669的等错误率（EER）。<!--more-->

## 原理

论文中的模型通过一系列编码器从不同音频前端提取高级特征图，包括常数Q变换（CQT）、Mel频谱图和音高频谱图。CQT编码器使用非平稳Gabor变换算法，通过复杂的卷积层、复杂的ELU激活函数和复杂的dropout处理音频数据。Mel频谱图编码器采用Vision Transformer（ViT）配置，而音高频谱图编码器则通过连续小波变换（CWT）处理。这些编码器输出的向量通过全连接层和ELU激活函数处理，最终使用加性边际Softmax（AM-Softmax）损失函数进行训练，以确保同一说话者的嵌入在多维空间中接近，不同说话者的嵌入则远离。

## 流程

模型的工作流程包括音频数据的预处理、特征提取、嵌入生成和验证。首先，4秒的音频片段被随机从原始录音中选取，并重采样至24,000Hz。然后，音频数据通过CQT、Mel频谱图和音高频谱图编码器进行处理，生成特征向量。这些向量通过全连接层和ELU激活函数生成主要嵌入，最后使用AM-Softmax损失函数进行训练。在SSTC挑战中，模型被用于验证经过语音转换的声音，展示了其有效性。

## 应用

该模型在语音识别和反欺骗领域具有广泛的应用前景。它可以用于增强TTS系统的性能，改进语音转换技术的安全性，以及在需要高安全性的语音验证场景中，如金融交易、身份验证等。随着技术的进一步发展，该模型有望在更多领域实现自动化和智能化，提高语音识别的准确性和可靠性。