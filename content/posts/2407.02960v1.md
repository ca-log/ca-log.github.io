---
author: 'TechScribe'
title: '"ObfuscaTune：保护隐私的大型语言模型离场微调与推理新方法"'
date: '2024-07-03 09:54:08+00:00'
Lastmod: '2024-07-04 01:52:57.540268'
description: 'ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02960v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02960v1)

## 摘要

本文探讨了一个及时但未充分探索的问题：如何在确保模型和数据保密性的前提下，对由模型提供商拥有的专有大型语言模型（LLM）进行离场微调和推理。文章提出了一种名为ObfuscaTune的新方法，该方法结合了简单的混淆技术和高效的保密计算使用，确保了模型和数据的保密性，同时保持了性能和效率。通过在四个NLP基准数据集上对不同大小的GPT-2模型进行实证验证，证明了该方法的有效性。<!--more-->

## 原理

ObfuscaTune方法的核心在于使用混淆技术保护模型参数和数据嵌入，同时利用可信执行环境（TEE）进行计算。模型提供商将专有模型发送到云提供商基础设施上的TEE中，通过混淆技术保护高度参数化的注意力和MLP层，然后将其发送出TEE。数据所有者将加密的数据批次直接发送到TEE，进行解密和嵌入，然后通过混淆方法保护嵌入数据。在TEE外，混淆的数据嵌入通过混淆的模型层传递，产生混淆的中间嵌入，再返回TEE进行解混淆和进一步处理。这种方法通过使用随机矩阵进行混淆，确保了数据和模型参数的保密性，同时保持了计算的高效性。

## 流程

ObfuscaTune的工作流程涉及三个主要利益相关者：模型提供商、数据所有者和云提供商。模型提供商将专有模型发送到云提供商的TEE中进行保护。数据所有者将加密数据发送到TEE进行解密和嵌入。在TEE内，数据和模型参数通过混淆技术进行保护，然后进行必要的计算和处理。最终，模型输出被发回给数据所有者或用于计算损失和参数更新。例如，在GPT-2模型中，输入文本和输出文本始终保持在TEE内以防止逆向攻击，而中间层的处理则在TEE内外交替进行，确保了数据和模型的安全。

## 应用

ObfuscaTune方法的应用前景广泛，特别是在需要高度保密和隐私保护的领域，如金融、医疗和法律服务。该方法能够确保在第三方云服务上进行模型微调和推理时，模型和数据的保密性不受威胁。随着对数据隐私和模型安全性的需求日益增长，ObfuscaTune提供了一种有效的解决方案，有望在未来的AI服务和应用中发挥重要作用。