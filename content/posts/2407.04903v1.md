---
author: 'TechScribe'
title: '探索 MMSci：提升科学理解的多模态数据集'
date: '2024-07-06'
Lastmod: '2024-07-10'
description: 'MMSci: A Multimodal Multi-Discipline Dataset for PhD-Level Scientific Comprehension'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![MMSci: A Multimodal Multi-Discipline Dataset for PhD-Level Scientific Comprehension](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.04903v1.pdf_0.jpg)](https://arxiv.org/abs/2407.04903v1)

## 摘要

本文介绍了一个名为 MMSci 的多模态、多学科数据集，旨在评估大型语言模型（LLM）和大型多模态模型（LMM）对博士水平科学内容的理解能力。该数据集包含来自 72 个科学学科的高质量、同行评审的学术文章和图表，可用于评估模型对科学文章和图表的理解能力。此外，作者还探索了将该数据集作为训练资源的方法，通过构建视觉指令跟随数据和交错的文章文本和图表图像，提高了模型对科学内容的理解能力。<!--more-->

## 原理

作者通过收集来自高质量、开放获取的 Nature Communications 期刊的多模态、多学科数据集 MMSci，创建了一个基准来评估 LMM 对博士水平多模态科学知识的理解能力。该基准包括科学图表标题和视觉问答（VQA）任务，通过不同的设置全面评估 LMM 对科学图表和内容的理解能力。作者还探索了使用数据集作为训练资源的方法，通过构建视觉指令跟随数据和交错的文章文本和图表图像，提高了模型对科学内容的理解能力。

## 流程

作者首先收集了来自 Nature Communications 期刊的多模态、多学科数据集 MMSci，然后创建了一个基准来评估 LMM 对博士水平多模态科学知识的理解能力。该基准包括科学图表标题和视觉问答（VQA）任务，通过不同的设置全面评估 LMM 对科学图表和内容的理解能力。作者还探索了使用数据集作为训练资源的方法，通过构建视觉指令跟随数据和交错的文章文本和图表图像，提高了模型对科学内容的理解能力。

## 应用

该数据集可以用于评估和增强生成模型的科学理解能力，从而推动基于人工智能的科学助手的发展。此外，该数据集还可以用于研究科学知识的表示和理解，以及探索多模态信息在科学研究中的作用。