---
author: 'TechScribe'
title: '"无声的挑战：大型语言模型在工具使用中的错误检测与应对"'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Tools Fail: Detecting Silent Errors in Faulty Tools'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Tools Fail: Detecting Silent Errors in Faulty Tools](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19228v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19228v1)

## 摘要

本文探讨了大型语言模型（LLMs）在使用工具时面临的挑战，特别是如何检测和应对“无声”的工具错误。传统上，工具使用的主要挑战被认为是选择合适的工具，而本文提出了一种更广泛的框架，指导我们探索模型检测这些错误并进行规划的能力。文章通过在受控的计算器设置和多模态指令遵循代理中进行实验，展示了LLMs能够检测不带有明确错误信号的错误输出，并提出了三种情境干预措施，发现LLMs能够学会对工具产生怀疑并检测错误。<!--more-->

## 原理

本文的关键在于引入了一种新的框架，用于检测和处理LLMs在使用工具时可能遇到的“无声”错误。这些错误不同于传统的输入错误，它们不会伴随明显的错误信号，因此需要LLMs具备主动检测、推断错误来源和规划恢复策略的能力。文章通过定义一个错误阈值ϵ，来确定工具输出的偏差是否“关键”错误，从而需要干预。此外，文章还提出了一种分类法，用于分类工具相关错误的来源和恢复方法，强调了在多工具或多LM设置中，需要联合考虑不确定性和知识。

## 流程

文章通过两个主要实验设置来验证LLMs的错误检测能力：一是在受控环境中使用损坏的计算器解决算术问题，二是在更自然的“损坏”工具设置中涉及多模态指令遵循代理。在计算器实验中，LLMs被要求使用一个返回错误结果的计算器来解决数学问题，并检测这些错误输出。在多模态代理实验中，LLMs需要评估对象检测器和动作规划器的输出，决定是否接受或拒绝这些输出。文章通过这些实验展示了LLMs如何在不同情境下检测和处理工具错误。

## 应用

本文的研究为LLMs在实际应用中的工具使用提供了重要的见解，特别是在需要高度可靠性的任务中，如机器人导航和操作。通过提高LLMs检测和处理工具错误的能力，可以显著增强其在复杂任务中的表现和可靠性。未来的研究可以进一步探索如何将这些方法应用于更广泛的工具和场景，以及如何通过改进LLMs的元认知能力来进一步提升其错误处理能力。