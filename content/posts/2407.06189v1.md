---
author: 'TechScribe'
title: '"Video-STaR：革新视频理解的自训练方法"'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06189v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06189v1)

## 摘要

本文介绍了一种名为Video Self-Training with augmented Reasoning (Video-STaR)的新方法，该方法允许使用任何标记的视频数据集进行视频指令调优。Video-STaR通过在指令生成和微调之间循环，提高了视频理解能力，并使大型视觉语言模型（LVLMs）能够适应新的下游任务。该方法在多个基准测试中展示了显著的性能提升，特别是在视频问答（VQA）和动作质量评估（AQA）任务中。<!--more-->

## 原理

Video-STaR的核心在于利用现有的视频标签作为弱监督，通过循环迭代生成和验证答案来训练模型。在生成阶段，模型被提示生成候选答案，然后通过标签验证阶段过滤出包含正确视频标签的答案。接着，模型在经过验证的数据集上进行微调。这种方法通过仅训练包含正确标签的生成答案，有效地利用了现有视频标签作为弱监督。

## 流程

1. **答案生成**：模型被提示对视频提出问题并生成答案。
2. **标签验证**：生成的答案被过滤，只保留那些包含原始视频标签的答案。
3. **指令调优**：模型在经过验证的答案数据集上进行微调。
4. **循环迭代**：上述过程不断循环，直到模型性能达到稳定。

例如，在Kinetics700数据集上，模型被问及视频中的活动类型，生成的答案详细描述了视频内容，并通过标签验证确保答案的准确性。

## 应用

Video-STaR的应用前景广泛，特别是在需要复杂视频理解的领域，如体育分析、安全监控和教育辅助。该方法不仅提高了模型的性能，还使其能够适应新的、多样化的任务，从而在多个行业中实现更广泛的应用。