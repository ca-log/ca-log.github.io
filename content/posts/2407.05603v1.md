---
author: 'TechScribe'
title: '探索WSI-VQA：引领全幻灯片图像解释的新纪元'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05603v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05603v1)

## 摘要

本文介绍了一种名为WSI-VQA的创新框架，用于通过生成式视觉问答（VQA）来解释全幻灯片图像（WSI）。WSI-VQA通过将各种幻灯片级任务重新构建为问答模式，展示了其通用性，使病理学家能够通过人机交互实现免疫组织化学分级、生存预测和肿瘤分型。此外，研究团队建立了一个包含8672个幻灯片级问答对的WSI-VQA数据集，并开发了名为Wsi2Text Transformer（W2T）的生成模型，该模型在医学正确性方面优于现有的判别模型，显示出在临床场景中的应用潜力。<!--more-->

## 原理

WSI-VQA框架的核心是Wsi2Text Transformer（W2T）模型，该模型通过视觉编码器提取和聚合补丁级嵌入，同时通过文本编码器获取问题词嵌入。在解码器中，通过共注意力映射将补丁嵌入和词嵌入对齐，从而生成答案。与传统的VQA方法不同，WSI-VQA的生成模型能够以自由形式逐字预测答案，适用于多样化的临床问题，尤其是在没有对比或分类候选答案的情况下。

## 流程

WSI-VQA的工作流程包括数据集构建、模型训练和推理阶段。数据集构建涉及从TCGA数据库中选择病理报告和临床指标，通过大型语言模型（LLM）生成问答对，并进行临床验证以确保数据质量。模型训练阶段，W2T模型通过视觉和文本提取器处理输入的WSI和问题，通过共注意力机制生成答案，并使用语言模型损失目标进行训练。在推理阶段，模型使用波束搜索进行答案生成。

## 应用

WSI-VQA框架在病理学领域具有广泛的应用前景，能够处理多种幻灯片级任务，如肿瘤分级、生存预测和肿瘤分型。其生成式模型和共注意力映射的可视化提高了模型的可解释性，有助于在临床实践中获得病理学家的信任。此外，WSI-VQA数据集的公开将促进病理学领域视觉语言学习的发展。