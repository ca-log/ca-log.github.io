---
author: 'TechScribe'
title: '探索实时蒙特卡洛树搜索在通用视频游戏玩中的增强技术'
date: '2024-07-03 12:18:28+00:00'
Lastmod: '2024-07-04 01:52:34.290555'
description: 'Enhancements for Real-Time Monte-Carlo Tree Search in General Video Game Playing'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Enhancements for Real-Time Monte-Carlo Tree Search in General Video Game Playing](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03049v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03049v1)

## 摘要

本文探讨了在通用视频游戏玩（GVGP）领域中，实时蒙特卡洛树搜索（MCTS）的八项增强技术。GVGP要求代理能够玩各种事先未知的实时视频游戏，这限制了领域特定启发式方法的使用。MCTS是一种不依赖于领域特定知识的搜索技术。本文讨论的增强技术包括渐进历史（PH）、N-Gram选择技术（NST）、树重用（TR）、广度优先树初始化（BFTI）、损失避免（LA）、新颖性基于剪枝（NBP）、知识基于评估（KBE）和确定性游戏检测（DGD）。这些增强技术单独应用时，大多数都能显著提高胜率。当组合应用时，这些增强技术将平均胜率从31.0%提高到48.4%，接近2015年GVG-AI竞赛最佳代理的水平。<!--more-->

## 原理

本文提出的MCTS增强技术通过多种机制提高搜索效率和游戏表现。例如，渐进历史（PH）和N-Gram选择技术（NST）通过在选择和模拟步骤中偏向于先前模拟中表现良好的动作或动作序列，从而提高搜索的效率。树重用（TR）通过在新的搜索过程中重用先前游戏刻的树的一部分，减少了重新计算的需要。广度优先树初始化（BFTI）通过在开始MCTS之前生成根节点的直接后继，提供了先验评估，避免了在小模拟次数下的随机行为。损失避免（LA）通过在遇到失败游戏状态时立即寻找更好的替代方案，保持了对节点价值的乐观初始视图。新颖性基于剪枝（NBP）通过基于新颖性测试剪枝节点，避免了冗余的搜索路径。知识基于评估（KBE）通过使用模拟过程中收集的知识和对象距离来区分具有相同评估的状态，提高了状态评估的准确性。确定性游戏检测（DGD）通过检测游戏是否可能是确定性的，并相应地调整MCTS和TR及NBP的增强技术，优化了搜索策略。

## 流程

MCTS的基本工作流程包括选择、模拟、扩展和反向传播四个步骤。本文提出的增强技术通过修改这些步骤来提高性能。例如，在选择步骤中，PH和NST引入了对先前表现良好的动作的偏向。在模拟步骤中，LA在遇到失败状态时立即寻找更好的替代方案。在扩展步骤中，TR重用了先前游戏刻的树的一部分。在反向传播步骤中，KBE通过添加基于知识的评估来改进状态评估。这些增强技术通过结合这些步骤的修改，提高了MCTS的整体性能。

## 应用

本文提出的MCTS增强技术不仅适用于GVGP领域，还可以扩展到其他需要实时决策和搜索的领域，如机器人导航、自动驾驶和实时策略游戏。这些技术的组合使用可以显著提高代理在复杂环境中的决策能力和游戏表现，具有广泛的应用前景。