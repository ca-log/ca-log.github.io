---
author: 'TechScribe'
title: 'VIMI：引领多模态视频生成新纪元'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'VIMI: Grounding Video Generation through Multi-modal Instruction'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![VIMI: Grounding Video Generation through Multi-modal Instruction](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06304v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06304v1)

## 摘要

本文介绍了一种名为VIMI的新型视频生成框架，该框架通过多模态指令实现视频生成的视觉定位。传统的文本到视频扩散模型依赖于仅包含文本的编码器进行预训练，但由于缺乏大规模多模态提示视频数据集，导致视觉定位能力不足，限制了其在多模态集成中的应用。为解决这一问题，VIMI构建了一个大规模多模态提示数据集，并采用两阶段训练策略，使同一模型能够执行多样化的视频生成任务。第一阶段提出了一种多模态条件视频生成框架，用于在这些增强数据集上进行预训练，建立一个基础的视频生成模型。第二阶段在三个视频生成任务上对模型进行微调，进一步提高了模型处理多样输入和任务的能力，确保了多模态信息的无缝集成。VIMI在多个基准测试中展示了其优越的性能，特别是在UCF101基准测试中取得了最先进的文本到视频生成结果。<!--more-->

## 原理

VIMI框架的核心在于其两阶段的训练策略和多模态指令调优。在第一阶段，通过检索方法构建了一个大规模的多模态提示数据集，并利用这些数据进行预训练，使模型能够理解文本和多模态输入，为视频生成打下基础。第二阶段通过在多个视频生成任务上进行微调，进一步提升了模型处理复杂输入和任务的能力。VIMI的创新之处在于其能够生成与文本和视觉输入紧密相关的视频，同时保持视频的时序一致性和语义控制。

## 流程

VIMI的工作流程分为两个主要阶段：检索增强预训练和多模态指令微调。在预训练阶段，首先通过大规模检索方法将多模态上下文示例与给定的文本提示配对，构建一个多模态提示数据集。然后，使用这些配对数据预训练一个多模态视频生成器。在微调阶段，模型在多个视频生成任务上进行微调，包括主题驱动的视频生成、视频预测和文本到视频生成，通过多模态指令进一步优化模型的性能。例如，在主题驱动的视频生成任务中，模型通过提取文本中的实体词并使用Grounding DINO进行对象检测和SAM进行图像分割，确保每个文本元素都有视觉上的对应。

## 应用

VIMI框架的应用前景广泛，特别是在需要多模态输入的视频生成领域，如电影制作、广告创意、虚拟现实和游戏开发等。其能够生成高质量、时序一致且语义丰富的视频，为这些领域提供了强大的工具。此外，VIMI的灵活性和可扩展性也使其能够适应未来更多复杂的视频生成任务。