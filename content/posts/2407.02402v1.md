# 探索大型语言模型在代码克隆检测中的先进性能与挑战

[![Assessing the Code Clone Detection Capability of Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02402v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02402v1)

## 摘要

本文由Zixian Zhang和Takfarinas Saber撰写，旨在评估大型语言模型（LLMs）如GPT-3.5和GPT-4在代码克隆检测任务中的性能。研究通过对比这两个模型在不同类型和相似度级别的代码克隆检测中的表现，发现GPT-4在所有克隆类型中均优于GPT-3.5。此外，研究还探讨了模型在处理人类编写的代码克隆与LLM生成的代码克隆时的性能差异。结果显示，尽管LLMs在代码克隆检测方面取得了进展，但仍需进一步改进，特别是在识别复杂类型（如Type-4）的代码克隆方面。

## 原理

大型语言模型（LLMs）如GPT-3.5和GPT-4通过预训练学习大量语言数据，从而能够理解和生成文本。在代码克隆检测中，这些模型利用其对代码语法的理解和生成能力，通过分析代码片段的相似性和功能一致性来识别克隆。GPT-4相较于GPT-3.5，通过更复杂的架构和更多的参数，提高了对代码语义的理解能力，从而在检测代码克隆时表现出更高的准确性。

## 流程

研究首先选择了两个数据集：BigCloneBench（人类编写的代码克隆）和GPTCloneBench（LLM生成的代码克隆）。然后，通过精心设计的提示（prompt）引导模型进行代码克隆检测。例如，使用少样本提示（few-shot prompt），提供简单的指令、输入样本和代码克隆定义，以指导模型判断给定的代码对是否为克隆。实验结果通过真阳性（TP）、假阴性（FN）和召回率（Recall）等指标进行评估。

## 应用

该研究展示了LLMs在代码克隆检测领域的潜力，特别是在集成开发环境（IDEs）中与LLM工具（如GPT-4和Microsoft Copilot）结合使用时。未来，随着软件工程师越来越多地利用LLM进行代码生成和重构，LLMs在代码克隆检测方面的应用将更加广泛，有助于提高代码质量和减少冗余。

