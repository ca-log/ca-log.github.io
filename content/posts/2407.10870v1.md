---
author: 'TechScribe'
title: '探索GPT-4o在医学影像中的应用：无需微调的手势识别新方法'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via VLM'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via VLM](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10870v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10870v1)

## 摘要

本文探讨了使用大型视觉语言模型（LVLMs）如GPT-4o从手臂超声图像中解码手势的能力。文章指出，尽管这些模型在一般任务中表现出色，但在特定任务如生物医学数据集上的性能通常受限。由于完全微调这些大型模型需要大量的计算资源和数据，本文展示了GPT-4o可以在无需微调的情况下，通过少样本上下文学习（ICL）策略，从手臂超声数据中解码手势，并显著提高分类准确性。这一研究为医学影像领域中LVLMs的应用开辟了新的可能性。<!--more-->

## 原理

GPT-4o是一种多模态生成预训练转换器，具有处理文本和图像的能力。它通过集成文本和图像在一个模型中，增强了人机交互的准确性和响应性。在本文中，GPT-4o被用于分析手臂超声图像，通过将超声图像数据编码为base64格式的文本，使其能够理解和处理。通过提供一些标记的示例图像，GPT-4o能够利用ICL策略，无需修改预训练模型，仅通过增加任务特定示例到输入上下文中，来提高手势识别的性能。

## 流程

研究中，超声数据从三名受试者收集，每名受试者执行五种不同的手势。数据通过Sonostar 4L线性手掌多普勒超声探头采集，并使用Python脚本捕获超声图像的截图。GPT-4o通过Azure OpenAI模块进行推理，图像数据被转换为文本格式以便GPT-4o处理。实验包括0-shot、1-shot、2-shot和3-shot ICL策略，通过提供不同数量的示例图像来评估GPT-4o的性能。例如，在1-shot策略中，每个类别的第一个图像被展示给模型，并附带类别标签，然后模型被要求预测手势类别。

## 应用

本文的研究表明，GPT-4o在无需微调的情况下，通过少样本ICL策略能够有效分类手臂超声图像，这对于控制假手、远程操作机器人夹具和控制虚拟现实接口等领域具有重要应用价值。此外，这种方法在资源受限的环境中尤其有价值，因为它避免了完全微调所需的大量计算和数据需求。未来，这种方法可能会扩展到更多的医学影像应用，如手术肿瘤学和放射学诊断。