---
author: 'TechScribe'
title: '"情感交互与差异结果训练：推动人机相互学习的新前沿"'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01280v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01280v1)

## 摘要

本文探讨了在人机交互中，通过情感语言交互和差异结果训练（Differential Outcomes Training, DOT）来促进人机间的相互学习。研究灵感来源于儿童与照顾者的互动，通过模拟机器人尝试学习如何最佳地传达其内部需求，同时人类“照顾者”学习如何满足机器人的需求。研究结果显示，使用差异结果训练（DOT）相比非差异结果训练（Non-DOT）显著提高了人机间的学习效率和准确性。此外，机器人使用探索-利用策略选择相比纯利用策略选择进一步提升了学习效果。这些发现对于在治疗和教育领域中使用社交辅助机器人（SAR）具有重要意义。<!--more-->

## 原理

本研究的核心在于通过情感语言交互和差异结果训练（DOT）来增强人机间的相互学习。机器人（Reachy）通过模拟表达内部需求（如口渴、饥饿和好奇），并使用特定的“babbling”声音来传达这些需求。人类参与者则需要通过这些声音来判断机器人的需求，并提供相应的物体来满足这些需求。DOT的实现是通过机器人对正确和错误响应的不同情感反应（如不同的肢体动作和声音）来强化学习过程。这种差异化的反馈机制有助于人类更快地学习如何正确响应机器人的需求，同时也帮助机器人学习如何更有效地传达其需求。

## 流程

研究中，参与者与模拟的Reachy机器人进行交互。每个实验条件包括25个周期（试验），参与者在每个周期中需要根据机器人的“babbling”声音选择正确的物体来满足其需求。机器人通过Q-learning算法学习如何选择最有效的“babbling”声音来传达其需求。在DOT条件下，机器人对正确和错误的响应提供不同的情感反应，而在非DOT条件下，反应是随机的。通过这种方式，机器人和人类参与者在相互学习的过程中不断优化其交互策略。

## 应用

本研究的成果在社交辅助机器人（SAR）的应用领域具有广泛的前景，特别是在治疗和教育领域。通过提高人机间的相互学习效率，可以更有效地使用机器人进行认知干预、教育辅助和情感支持。此外，这种基于情感语言交互和差异结果训练的方法也可以扩展到其他需要复杂人机交互的场景，如老年护理和儿童发展支持。