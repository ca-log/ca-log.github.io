# RankRAG：革新大型语言模型的检索增强生成技术

[![RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02485v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02485v1)

## 摘要

本文介绍了一种名为RankRAG的新型指令微调框架，该框架统一了上下文排序与检索增强生成（RAG）在大型语言模型（LLMs）中的应用。RankRAG通过在训练混合中加入少量排序数据，使单一LLM能够同时进行上下文排序和答案生成，显著提升了模型在知识密集型基准测试中的表现，尤其是在生物医学领域等特定域的应用前景广阔。

## 原理

RankRAG的工作原理基于指令微调技术，通过设计一个专门的任务来识别给定问题相关的上下文或段落，并将此任务结构化为常规的问答形式。在推理阶段，LLM首先对检索到的上下文进行重新排序，然后基于精炼后的top-k上下文生成答案。这种设计使得LLM能够在保持高召回率的同时，提高生成内容的质量和相关性。

## 流程

RankRAG的工作流程包括两个主要阶段：第一阶段是监督微调（SFT），通过混合高质量的指令遵循数据集来增强LLM的指令遵循能力；第二阶段是统一指令微调，用于增强LLM在RAG任务中的表现，特别是通过引入上下文丰富的问答数据和排序数据来提升模型筛选无关上下文的能力。在实际应用中，模型首先使用检索器从语料库中检索top-N文档，然后通过RankRAG模型计算问题与检索文档的相关性得分，重新排序后保留top-k文档，最后基于这些文档生成最终答案。

## 应用

RankRAG框架不仅在通用领域的知识密集型NLP任务中表现出色，还展示了在生物医学等特定领域的强大泛化能力。由于其能够有效处理长尾知识、提供最新信息并适应特定任务，RankRAG有望在未来的智能问答系统、专业领域咨询服务等多个应用场景中发挥重要作用。

