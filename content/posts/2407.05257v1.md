---
author: 'TechScribe'
title: 'OvSW: 突破二值神经网络的沉默权重，实现高效训练与部署'
date: '2024-07-07'
Lastmod: '2024-07-10'
description: 'OvSW: Overcoming Silent Weights for Accurate Binary Neural Networks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![OvSW: Overcoming Silent Weights for Accurate Binary Neural Networks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05257v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05257v1)

## 摘要

本文针对二值神经网络（BNNs）中的“沉默权重”问题进行了深入研究。在传统的BNNs中，超过50%的权重在训练过程中其符号保持不变，这些权重不仅分布在权重分布的尾部，而且在零附近普遍存在。这种现象显著减慢了模型的收敛速度并导致精度下降。为了解决这一问题，本文提出了Overcome Silent Weights（OvSW）方法，通过引入自适应梯度缩放（AGS）和沉默感知衰减（SAD）策略，有效地提高了权重符号更新的效率。实验结果表明，OvSW在多个数据集和架构上实现了更快的收敛速度和最先进的性能，例如在ImageNet1K数据集上，使用二值化的ResNet18和ResNet34架构分别达到了61.6%和65.5%的top-1准确率。<!--more-->

## 原理

OvSW方法的核心在于通过AGS和SAD两种技术来克服“沉默权重”问题。AGS通过建立梯度与潜在权重分布之间的关系，自适应地缩放梯度，从而提高权重符号更新的整体效率。SAD则通过跟踪权重符号翻转状态，自动识别“沉默权重”，并对这些权重施加额外的惩罚，以促进其符号的翻转。这两种技术的结合使得OvSW能够有效地更新权重符号，加速模型的收敛并提升性能。

## 流程

OvSW的工作流程包括前向传播和反向传播两个阶段。在前向传播中，首先对激活和权重进行二值化处理，然后通过二值卷积操作计算特征，并计算损失。在反向传播中，计算损失对权重和激活的梯度，并应用AGS和SAD策略对梯度进行调整，最后使用SGD优化器更新权重和缩放因子。具体流程如下：
1. 前向传播：
   - 对激活和权重进行二值化处理。
   - 通过二值卷积操作计算特征。
   - 计算损失。
2. 反向传播：
   - 计算损失对权重和激活的梯度。
   - 应用AGS策略对梯度进行自适应缩放。
   - 应用SAD策略对“沉默权重”施加额外惩罚。
   - 使用SGD优化器更新权重和缩放因子。

## 应用

OvSW方法在二值神经网络的训练中展现出显著的优势，能够有效提升模型在资源受限平台上的部署效率。其应用前景广泛，包括但不限于移动设备、嵌入式系统、物联网设备等。此外，OvSW的良好兼容性使其可以作为即插即用的模块，增强现有二值神经网络的性能，进一步推动二值神经网络在实际应用中的普及和优化。