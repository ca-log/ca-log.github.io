---
author: 'TechScribe'
title: 'Arena Learning：通过模拟聊天机器人竞技场构建LLMs后训练数据飞轮'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10627v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10627v1)

## 摘要

本文介绍了一种名为Arena Learning的创新方法，旨在通过模拟聊天机器人竞技场（Chatbot Arena）来评估大型语言模型（LLMs）的有效性。传统的在线Chatbot Arena评估方法受限于人工标注的成本和时间。Arena Learning采用AI驱动的标注方式，通过模拟竞技场战斗来评估战斗结果，从而实现目标模型的持续改进。该方法包括两个关键元素：一是通过WizardArena管道确保离线模拟与在线竞赛之间的一致性；二是基于战斗结果不断改进训练数据。实验结果表明，Arena Learning能够显著提升目标模型WizardLM-β的性能，为LLMs的后训练提供了一个高效、自动化的训练和评估管道。<!--more-->

## 原理

Arena Learning的核心在于模拟一个离线的聊天机器人竞技场，利用一个强大的“评判模型”（judge model）来自动模仿人类标注者在评判两个模型响应对的方式，并提供排名、分数和解释。这种方法通过AI评判模型来预测不同模型在竞技场战斗中的表现排名，从而实现对LLMs的持续改进。Arena Learning通过监督微调（SFT）、直接偏好优化（DPO）和近端策略优化（PPO）等训练策略，使目标模型WizardLM-β能够从多个不同模型的优势中学习，并通过迭代战斗和训练过程不断更新和重新评估模型，确保其与领域内最新顶尖竞争者保持竞争力和更新。

## 流程

Arena Learning的工作流程包括三个主要阶段：离线成对LLM战斗竞技场、迭代后训练和模型评估。在离线成对LLM战斗竞技场阶段，目标模型（如WizardLM-β）与各种最先进的模型在大量的指令数据上进行模拟战斗。这些合成战斗结果随后用于通过SFT、DPO和PPO等训练策略增强WizardLM-β。在模型评估阶段，使用精心准备的离线测试集WizardArena来自动化成对评判过程，生成Elo排名和详细的胜/负/平统计数据。整个过程通过迭代战斗和训练，使WizardLM-β能够持续改进并适应竞技场的不断变化。

## 应用

Arena Learning的应用前景广泛，特别是在需要高效、自动化评估和训练大型语言模型的场景中。该方法不仅能够减少人工标注的成本和时间，还能够提供一个可靠的离线评估平台，用于选择最佳模型和预测模型性能。此外，Arena Learning的迭代训练和评估过程使其适用于持续改进和扩展LLMs的能力，特别是在需要模型适应用户新意图和指令的动态环境中。