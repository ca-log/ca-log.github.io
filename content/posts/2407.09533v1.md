---
author: 'TechScribe'
title: '探索视频占用模型（VOCs）：新一代视频预测模型的前沿技术'
date: '2024-06-25'
Lastmod: '2024-07-16'
description: 'Video Occupancy Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Video Occupancy Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.09533v1.pdf_0.jpg)](https://arxiv.org/abs/2407.09533v1)

## 摘要

本文介绍了一种新型的视频预测模型——视频占用模型（VOCs），旨在支持下游控制任务。VOCs在紧凑的潜在空间中运行，避免了逐像素预测的需要，并直接预测未来状态的折扣分布，从而无需多步展开。文章展示了VOCs在构建用于下游控制的视频预测模型中的有效性。代码已公开在github.com/manantomar/video-occupancy-models。<!--more-->

## 原理

VOCs通过生成时间差分（TD）学习直接预测观察的潜在表示的未来折扣分布。具体来说，VOCs计算当前观察的生成目标，通过以概率1 − γ采样下一个观察的表示，并以概率γ从模型自举中采样未来表示。随后，使用自回归变换器架构在潜在表示空间上实现这一生成TD算法。VOCs通过三种方法将原始观察转换为潜在表示：量化自动编码（VQ-VAEs）、逆动力学建模（利用动作数据）和自监督蒸馏基础目标（避免像素级预测）。

## 流程

VOCs的工作流程包括两个主要部分：一个专门的表示空间，用于捕获视频帧序列中的信息，以及一个生成模型，用于在表示空间上进行时间预测。生成模型采用自回归模型，如GPT-2，预测一系列令牌。表示空间将连续的帧/观察序列表示量化为离散令牌，作为生成模型的输入。VOCs仅将少量观察编码到当前表示zt中，并通过类似方式计算时间目标，捕获未来观察中的信息。量化后的当前和时间目标表示被连接成一系列离散令牌，GPT模型（表示为M）被训练来进行下一个令牌预测。

## 应用

VOCs的应用前景广泛，特别是在需要高效价值估计和模型预测控制的领域。由于VOCs能够直接在潜在空间中进行预测，避免了多步展开的需要，因此在实时控制和决策制定中具有显著优势。此外，VOCs的模型结构使其能够适应高维像素空间，为复杂环境下的控制任务提供了新的解决方案。