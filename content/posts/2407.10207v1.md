---
author: 'TechScribe'
title: '模型不确定性下的智能体引导策略：理论与实践'
date: '2024-07-14'
Lastmod: '2024-07-16'
description: 'Learning to Steer Markovian Agents under Model Uncertainty'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Learning to Steer Markovian Agents under Model Uncertainty](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10207v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10207v1)

## 摘要

本文探讨了在模型不确定性下如何设计额外奖励以引导多智能体系统向期望策略发展的问题。通过引入基于模型的非情节强化学习框架，本文重点关注学习依赖历史的引导策略以处理智能体学习动态的固有模型不确定性。文章提出了一种新的目标函数，旨在以合理的成本实现良好的引导结果，并从理论上确定了引导策略存在的条件。此外，文章还提供了近似解决目标函数的经验算法，并通过实证评估展示了算法的有效性。<!--more-->

## 原理

文章提出的方法通过一个外部“中介”来影响和引导智能体的学习动态，通过修改原始奖励来实现。中介可以通过提供货币激励来鼓励联合行动或采用创新技术。文章的核心在于开发针对马尔可夫智能体的引导策略，这些智能体的策略学习动态仅依赖于当前策略和修改后的奖励函数。主要目标是引导智能体达到某些期望策略，同时确保引导奖励的成本合理。

## 流程

1. 中介确定一个模型类F，包含智能体的真实学习动态f˚。
2. 中介通过访问模型类F中的模型，进行模拟学习以决定最佳引导行动u1, u2, ..., uT。
3. 中介在实际智能体中部署这些引导行动，进行一次有限视野的非情节学习过程。
4. 中介通过学习历史依赖的引导策略，优化平均性能。
5. 中介在实际智能体中部署最优引导策略ψ˚，进行引导。

## 应用

文章提出的引导策略可以应用于广泛的经济应用场景，如社会规划者通过提供货币激励来鼓励技术公司采用创新技术。此外，该方法还可以扩展到非马尔可夫智能体的引导问题，具有广泛的应用前景。