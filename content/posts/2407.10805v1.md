---
author: 'TechScribe'
title: '探索知识图谱与大型语言模型的深度融合：Think-on-Graph 2.0引领新一代AI推理技术'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10805v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10805v1)

## 摘要

本文介绍了一种名为Think-on-Graph 2.0（ToG2.0）的增强型检索增强生成（RAG）框架，旨在通过知识图谱引导的检索，深化和细化信息收集与整合过程。ToG2.0通过将问题与知识图谱对齐并利用其作为导航工具，不仅提高了大型语言模型（LLMs）响应的准确性和可靠性，还展示了混合结构化知识系统在推进LLM推理方面的潜力，使其更接近人类的表现。论文通过在四个公共数据集上的广泛实验，证明了该方法相对于基线的优势。<!--more-->

## 原理

ToG2.0的核心在于利用知识图谱（KG）作为导航工具，通过KG引导的导航促进深度和长程关联，以保持逻辑一致性并优化检索范围，从而提高精度和互操作性。该框架通过结合非结构化文档中的知识与知识图谱中的结构化洞察，形成了一个增强复杂问题解决能力的地图。具体来说，ToG2.0通过实体在探索过程中遇到的限制检索语料库的规模，提高效率，并通过查询、当前三元链和从当前实体上下文中检索到的参考文献来排名和选择实体，减少实体歧义并确保下一步探索的准确方向。

## 流程

ToG2.0的工作流程包括初始化、关系修剪（RP）、实体修剪（EP）和检查与推理（ER）三个主要步骤。初始化阶段选择合适的推理起点，关系修剪阶段选择最有可能找到包含有用上下文信息的实体的关系，实体修剪阶段识别所有互联的候选实体节点并获取其相关文档，最后在检查与推理阶段，LLM被提示检查逻辑一致性和事实证据的完整性。如果LLM认为可以回答问题，迭代结束；否则，基于问题和收集到的上下文线索生成新的线索查询，进入下一轮迭代。

## 应用

ToG2.0的应用前景广泛，特别是在需要复杂推理和保持逻辑一致性的领域，如开放域问答、多跳知识库问答（KBQA）和事实验证。通过提高LLMs的推理能力和响应的准确性，ToG2.0有望在各种高多样性和复杂性的应用中发挥重要作用，推动人工智能技术向更接近人类智能的方向发展。