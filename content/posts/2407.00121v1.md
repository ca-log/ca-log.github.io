---
author: 'TechScribe'
title: 'IBM GRANITE-20B-FUNCTIONCALLING模型：开启智能函数调用新时代'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00121v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00121v1)

## 摘要

本文介绍了IBM的GRANITE-20B-FUNCTIONCALLING模型，这是一个通过多任务学习方法训练的大型语言模型（LLM），旨在赋予模型识别、调用和与外部工具及应用程序接口（APIs）交互的能力。该模型在多个领域展现了卓越的性能，特别是在函数调用方面，它能够访问最新的和特定领域的信息，并能够将超出其处理范围的任务外包给可靠的工具，如Python解释器或计算器。GRANITE-20B-FUNCTIONCALLING模型在多个基准测试中表现优异，尤其是在Berkeley Function Calling Leaderboard上，它是所有开源模型中表现最好的，并且在整体排名中位列第四。<!--more-->

## 原理

GRANITE-20B-FUNCTIONCALLING模型通过多任务学习方法进行训练，这种方法允许模型同时学习多个相关的任务，从而提高其在特定任务上的表现和泛化能力。模型训练涉及七个基本任务，包括嵌套函数调用、函数链、并行函数、函数名检测、参数-值对检测、下一个最佳函数和响应生成。这些任务的训练数据来自多个领域，确保了模型在不同场景下的适应性和准确性。通过这种方式，模型能够理解和执行复杂的函数调用序列，从而有效地与外部工具和API进行交互。

## 流程

GRANITE-20B-FUNCTIONCALLING的工作流程包括以下几个关键步骤：
1. **数据统一化**：将来自不同数据集的API、工具和函数转换为统一的JSON格式，以便于模型处理和解析。
2. **任务特定指令嵌入**：根据任务的不同，将特定的指令嵌入到训练数据中，指导模型如何执行特定的函数调用任务。
3. **多任务训练**：使用包含多个任务的数据集进行训练，每个任务都有其特定的指令和数据格式，确保模型能够处理各种复杂的函数调用场景。
4. **评估与优化**：通过在多个基准测试和实际应用场景中进行评估，不断优化模型的性能和准确性。

例如，在处理一个用户查询“拉斯维加斯和大峡谷之间的典型驾驶时间是多少？”时，模型会生成一个包含两个函数调用的序列，第一个函数的输出将作为第二个函数的输入，从而准确地计算出驾驶时间。

## 应用

GRANITE-20B-FUNCTIONCALLING模型的应用前景广泛，特别是在需要复杂函数调用和与外部工具交互的场景中。例如，在企业环境中，模型可以用于自动化数据处理、报告生成和决策支持系统。此外，该模型还可以集成到各种智能助手和聊天机器人中，提供更加智能和高效的用户交互体验。随着模型的进一步优化和扩展，其在更多领域的应用潜力将进一步显现。