---
author: 'TechScribe'
title: 'IBM GRANITE-20B-FUNCTIONCALLING：开启大型语言模型的新纪元，实现复杂函数调用的自主代理'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00121v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00121v1)

## 摘要

本文介绍了IBM的GRANITE-20B-FUNCTIONCALLING模型，这是一个通过多任务学习方法训练的大型语言模型（LLM），旨在赋予模型识别、调用和与外部工具及API交互的能力。该模型在多个领域如编程、推理和多模态交互中展现出广泛的应用潜力。通过在七个基本任务上的训练，包括嵌套函数调用、函数链、并行函数、函数名检测、参数-值对检测、下一个最佳函数和响应生成，GRANITE-20B-FUNCTIONCALLING模型在多个跨领域的数据集上进行了全面评估，显示出优于其他开源模型的性能，并在Berkeley函数调用排行榜上位列第四。<!--more-->

## 原理

GRANITE-20B-FUNCTIONCALLING模型通过多任务学习方法进行训练，这种方法允许模型同时学习多个相关的任务，从而提高其在特定任务上的性能和泛化能力。模型通过学习如何处理复杂的函数调用任务，如嵌套函数调用和函数链，以及如何从用户查询中检测和填充参数-值对，来增强其与外部工具和API的交互能力。此外，模型还学习如何生成自然语言响应，这是作为LLM的基本功能之一。通过这种方式，模型不仅能够执行精确的函数调用，还能够生成连贯和相关的自然语言输出。

## 流程

GRANITE-20B-FUNCTIONCALLING的工作流程包括以下几个关键步骤：
1. **数据统一化**：将来自不同数据集的API、工具和函数转换为统一的JSON格式，以便于模型处理和解析。
2. **多任务训练**：模型在多个任务上进行训练，每个任务都有特定的指令和数据格式，如函数名检测、参数-值对检测和响应生成。
3. **指令调优**：通过生成包含所有任务数据的训练混合物，并对模型进行指令调优，以确保模型能够理解和执行各种函数调用任务。
4. **评估与优化**：模型在多个评估数据集上进行测试，包括Berkeley函数调用排行榜和其他学术基准，以评估其性能并进行必要的优化。

## 应用

GRANITE-20B-FUNCTIONCALLING模型的应用前景广泛，特别是在需要复杂函数调用和自然语言生成的领域，如企业自动化、智能助手和软件开发工具。该模型的能力使其能够作为自主代理，在需要与外部工具和API交互的场景中发挥重要作用，从而提高效率和准确性。