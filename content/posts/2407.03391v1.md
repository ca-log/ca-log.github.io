---
author: 'TechScribe'
title: '"软乞求：保护大型语言模型免受提示注入和越狱攻击的新策略"'
date: '2024-07-03'
Lastmod: '2024-07-10'
description: 'Soft Begging: Modular and Efficient Shielding of LLMs against Prompt Injection and Jailbreaking based on Prompt Tuning'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Soft Begging: Modular and Efficient Shielding of LLMs against Prompt Injection and Jailbreaking based on Prompt Tuning](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03391v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03391v1)

## 摘要

本文探讨了大型语言模型（LLMs）面临的重大安全问题，特别是提示注入（包括直接和间接）和越狱攻击。为了解决这些问题，论文提出了一种名为“软乞求”（Soft Begging）的新型防护方法，该方法通过训练软提示来中和受污染提示对LLM输出的影响。论文不仅介绍了提示注入和越狱攻击的背景，还详细阐述了“软乞求”技术的理论基础，并评估了其有效性。<!--more-->

## 原理

“软乞求”技术的工作原理基于参数高效的微调技术，通过训练所谓的软提示（即可训练的输入向量）来中和潜在有害提示部分对LLM行为的影响。这些软提示不是通过过滤步骤来实现，而是在参数级别上隐式地进行，即在不改变提示的情况下，有效地“乞求”网络忽略有害部分。这种方法的优势在于，参数级别的控制比文本级别的控制更为有效，且软提示的训练速度远快于整个模型的微调，同时LLM本身的参数保持不变。此外，软提示可以模块化以适应不同类型的攻击，甚至可以组合使用，使其成为一个非常有效和可定制的防护选项。

## 流程

“软乞求”技术的工作流程包括以下步骤：首先，训练软提示以产生从受污染提示到清洁输出的映射。这些软提示被训练成能够从受污染的提示中产生清洁的输出。其次，可以通过训练不同的软提示来应对不同的注入攻击，并通过提示融合或其他机制组合它们。最后，软提示可以与过滤机制结合，首先识别威胁类型（无需定位），然后根据识别结果选择匹配的软提示。例如，在处理间接提示注入攻击时，软提示可以被训练来识别并中和嵌入在恶意文档中的恶意提示。

## 应用

“软乞求”技术在保护LLMs免受提示注入和越狱攻击方面具有广泛的应用前景。由于其模块化和高效的特点，该技术可以应用于各种集成LLMs的应用场景，包括但不限于聊天机器人、内容生成系统和智能助手等。随着LLMs在更多领域的集成应用，这种防护技术的重要性将日益凸显，有助于确保这些系统的安全性和可靠性。