---
author: 'TechScribe'
title: '图神经网络中节点相似性的可解释性研究：基于梯度的方法的优越性'
date: '2024-07-10'
Lastmod: '2024-07-11'
description: 'Explaining Graph Neural Networks for Node Similarity on Graphs'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Explaining Graph Neural Networks for Node Similarity on Graphs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07639v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07639v1)

## 摘要

本文探讨了图神经网络（GNNs）在图数据上计算节点相似性的可解释性问题。在引文网络或知识图谱等多种应用中，相似性搜索是一个基础任务。尽管从启发式方法到图嵌入和图神经网络（GNNs）已经广泛研究了这一任务，但相似性的解释性却较少受到关注。本文通过研究基于互信息（MI）和基于梯度的解释（GB）两种主要方法，评估了它们在GNNs中计算节点相似性的性能，并讨论了它们的适用性。实验结果表明，与MI解释相比，基于梯度的解释具有可操作性、一致性和可修剪性等优点，这些特性使得它们更适合于解释节点相似性。<!--more-->

## 原理

本文的核心在于评估和比较两种解释图神经网络（GNNs）中节点相似性的方法：基于互信息（MI）的方法和基于梯度（GB）的方法。基于MI的方法通过选择与预测具有高互信息的子图来解释预测，而基于GB的方法则通过计算预测相对于输入的梯度来提供解释。实验验证了基于GB的方法在解释节点相似性方面的优越性，主要体现在以下几个方面：
1. **可操作性**：基于GB的方法允许根据解释选择输入，从而可预测地改变相似性得分。
2. **一致性**：选择某些输入的效果与丢弃它们的效果几乎没有重叠，表明解释具有一致性。
3. **可修剪性**：可以显著修剪解释以获得稀疏解释，同时保留对相似性得分的影响。

## 流程

本文的工作流程包括以下几个关键步骤：
1. **数据准备**：使用多个图数据集，包括引文网络和知识图谱，进行实验。
2. **模型训练**：实现多种无监督学习方法，如图自编码器（GAE）和变分图自编码器（VGAE），训练图神经网络（GNNs）以学习节点嵌入。
3. **解释方法评估**：使用GNNExplainer（基于MI）和两种基于梯度的方法（GB1和GB2）对节点相似性进行解释，并计算忠诚度指标和效果重叠度。
4. **结果分析**：分析基于GB的方法在忠诚度和效果重叠度方面的表现，验证其在节点相似性解释中的有效性和优越性。

## 应用

本文的研究为需要解释节点相似性的系统提供了实用的见解，特别是在使用图神经网络（GNNs）的应用中。基于梯度的解释方法不仅在理论上具有优势，而且在实际应用中也显示出其有效性，特别是在需要可预测性和一致性的场景中。未来，这些方法可以扩展到更广泛的图相似性搜索问题，以及设计先验可解释的相似性搜索方法。