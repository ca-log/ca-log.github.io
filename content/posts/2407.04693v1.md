---
author: 'TechScribe'
title: 'ANAH-v2：突破大型语言模型幻觉检测的新前沿'
date: '2024-07-05'
Lastmod: '2024-07-10'
description: 'ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.04693v1.pdf_0.jpg)](https://arxiv.org/abs/2407.04693v1)

## 摘要

本文介绍了一种名为ANAH-v2的迭代自训练框架，旨在解决大型语言模型（LLMs）在长篇问答任务中产生的幻觉问题。当前幻觉检测和缓解数据集在领域和规模上受限，且由于高昂的劳动力成本和现有幻觉标注器的不充分可靠性，难以扩展。ANAH-v2框架通过同时扩展幻觉标注数据集和提高标注器准确性，基于期望最大化（EM）算法，在每次迭代中应用幻觉标注流程并训练更准确的标注器。实验结果表明，最终获得的仅7B参数的标注器在HaluEval和HalluQA基准测试中通过零样本推理超越了GPT-4的性能，为LLMs的幻觉评估和缓解提供了新的前沿技术。<!--more-->

## 原理

ANAH-v2框架的核心在于其迭代自训练过程，该过程基于EM算法。在E步骤中，使用当前最佳的幻觉标注器估计扩展数据集的地面真实幻觉标注，并通过自一致性策略提供更稳健的标注估计。在M步骤中，结合现有标注和E步骤中得出的扩展数据标注来训练新的幻觉标注器。这一过程通过多维数据扩展的三个阶段进行，逐步增加数据集的多样性和规模，同时提高标注器的准确性和鲁棒性。

## 流程

ANAH-v2的工作流程包括三个主要阶段：初始阶段使用人工标注的数据集训练基础标注器；第二阶段通过收集更多开源LLMs的幻觉响应来提高标注器的泛化能力；第三阶段通过扩展主题和问题数量来进一步扩展数据集。每个阶段都通过迭代过程逐步优化标注器和数据集，最终形成一个大规模、多样化的数据集和高度准确的幻觉标注器。

## 应用

ANAH-v2不仅能够自动评估现有开源模型的幻觉水平，还通过简单的重排序策略展示了其在幻觉缓解方面的潜力。该框架的应用前景广泛，包括但不限于改进其他自然语言生成任务中的幻觉问题，以及提高跨语言、任务和主题的标注器通用性。