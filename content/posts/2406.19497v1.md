---
author: 'TechScribe'
title: '探索大型语言模型在科学写作中的性别偏见与个性特征表现'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19497v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19497v1)

## 摘要

本文探讨了大型语言模型（LLMs）在科学写作中的应用，特别是它们如何影响性别偏见和个性特征的表现。研究通过分析LLMs生成的科学摘要与人类作者的摘要，使用语言探究和词数统计（LIWC）框架来评估文本的词汇、心理和社会特征。研究发现，尽管LLMs能够生成与人类写作风格相似的文本，但它们在某些特征上表现出显著的性别偏见，特别是在词汇使用和情感表达上。研究强调了开发更加包容和无偏见的LLMs的重要性，以促进学术讨论的多样性和公平性。<!--more-->

## 原理

本研究使用LIWC框架来量化LLMs生成的文本和人类作者文本的特征。LIWC通过数千个预定义的词典来分析文本，提取出词汇、心理和社会特征。研究选择了三个流行的LLMs——Claude 3 Opus、Mistral AI Large和Gemini 1.5 Flash，通过特定的提示（prompt）让它们重写科学摘要。然后，通过LIWC分析这些重写的摘要，比较它们与原始人类作者摘要的特征，以评估LLMs是否能够准确地模仿人类作者的写作风格和个性特征，以及是否存在性别偏见。

## 流程

研究首先从CORE数据集中选择了3,390篇科学摘要，并使用genderextractor库为作者分配性别。然后，使用三个LLMs重写这些摘要，并使用LIWC框架分析生成的文本。研究进行了两种类型的分析：相关性分析和t检验分析。相关性分析使用皮尔逊相关系数来评估人类作者和LLMs生成文本的特征之间的相似度。t检验分析则用于比较男性和女性作者的文本特征，以及LLMs为男性和女性作者生成的文本特征。通过这些分析，研究能够确定LLMs在模仿人类写作风格时的准确性和存在的性别偏见。

## 应用

本研究的结果强调了LLMs在科学写作中的潜在应用，特别是在辅助作者改进文本质量和一致性方面。然而，研究也揭示了LLMs可能加剧性别偏见的问题，这需要在未来的LLMs开发和部署中得到解决。未来的研究应该关注于如何减少LLMs中的偏见，并提高它们生成公平和多样化文本的能力。此外，研究还可以扩展到不同的学术领域和时间跨度，以更全面地评估和减少研究社区中的偏见。