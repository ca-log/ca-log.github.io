---
author: 'TechScribe'
title: '探索大型语言模型中的性别偏见：科学写作的新视角'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19497v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19497v1)

## 摘要

本文由Naseela Pervez和Alexander J. Titus共同撰写，探讨了大型语言模型（LLMs）在科学摘要生成中的包容性问题，特别是性格特征和性别偏见。研究通过分析三个著名LLMs——Claude 3 Opus、Mistral AI Large和Gemini 1.5 Flash在科学摘要生成任务中的表现，使用Linguistic Inquiry and Word Count (LIWC)框架提取文本的词汇、心理和社会特征，发现尽管这些模型生成的文本与人类作者的内容相似，但在风格特征上存在显著的性别偏见。研究强调了开发能够保持多样化写作风格以促进学术讨论包容性的LLMs的重要性。<!--more-->

## 原理

该研究采用LIWC框架来分析LLMs生成的科学摘要的词汇、心理和社会特征。LIWC是一种文本分析工具，通过数千个词典来量化文本的这些特征。研究通过比较人类作者和LLMs生成的摘要的LIWC特征，使用Pearson相关系数和t检验来评估两者之间的相似性和差异。研究发现，尽管LLMs能够生成与人类写作风格相似的文本，但在某些特征上存在性别偏见，特别是在词汇使用和情感表达上。

## 流程

研究首先从CORE数据集中选取了3,390篇科学摘要，使用genderextractor库为作者分配性别。然后，利用Claude 3 Opus、Mistral AI Large和Gemini 1.5 Flash这三个LLMs重新生成这些摘要，并使用LIWC-22词典分析生成的文本。通过Pearson相关系数分析和t检验，研究比较了人类作者和LLMs生成的摘要的LIWC特征，特别是关注性别在写作风格上的差异。例如，研究发现女性作者在摘要中使用更多情感相关的词汇，而男性作者则更多使用确定性和权威性的词汇。

## 应用

该研究的结果对于改进LLMs的设计和应用具有重要意义，特别是在科学写作领域。通过减少性别偏见，LLMs可以更公平地支持不同性别的作者，促进科学交流的包容性和多样性。此外，这项研究也为未来在不同学术领域和时间跨度上研究性别偏见提供了方法论基础。