---
author: 'TechScribe'
title: '让漫画触手可及：为盲人和低视力读者打造的人工智能辅助阅读新篇章'
date: '2024-07-11'
Lastmod: '2024-07-12'
description: 'Toward accessible comics for blind and low vision readers'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Toward accessible comics for blind and low vision readers](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.08248v1.pdf_0.jpg)](https://arxiv.org/abs/2407.08248v1)

## 摘要

本文探讨了如何通过使用提示工程技术对大型语言模型进行微调，结合上下文信息，为盲人和低视力读者生成准确的漫画文本描述。文章提出利用现有的计算机视觉和光学字符识别技术，从漫画图像内容中构建基于事实的上下文，如面板、角色、文本、阅读顺序以及气泡和角色的关联。随后，通过上下文感知的面板描述，包括角色的外观、姿势、情绪、对话等，推断角色身份并生成漫画脚本。研究认为，这种丰富的内容描述可以轻松用于制作有声读物和电子书，为角色、字幕和播放音效提供多种声音。<!--more-->

## 原理

本文的核心在于利用大型语言模型（LLM）和提示工程技术，通过上下文信息增强漫画内容的理解。首先，通过计算机视觉和光学字符识别技术提取漫画图像中的关键元素，如面板、角色、文本等，并确定其阅读顺序和关联。然后，这些信息作为额外的上下文，用于指导LLM生成每个面板的精确描述。LLM通过提示工程技术，如链式提示，最大化利用这些技术，显著提高预测质量，无需额外数据或注释时间。生成的描述旨在通过提供整体场景描述、命名角色、对话和互动，按照自然阅读顺序反映图像内容。

## 流程

文章提出的工作流程包括以下几个步骤：首先，通过预处理图像分析算法提取所有视觉和文本元素，生成一个结构化的漫画脚本文件。其次，对文本进行分类，识别对话、音效和字幕。接着，通过角色聚类和名称推断，自动识别并命名角色。最后，结合上下文信息，生成每个面板的详细描述，包括场景、动作和对话。例如，通过链式提示技术，LLM被引导逐步推理出角色的名称和关系，从而生成更丰富的漫画脚本。

## 应用

本文提出的方法不仅限于特定类型的漫画，而且可以扩展到其他漫画类型和多语言环境中。生成的脚本可以用于高级文本搜索和索引，同时通过文本到语音工具转换为有声读物，极大地提高了漫画的可访问性。未来的工作计划包括探索更多的文本类别，增强面板描述的连贯性，并通过与可访问性专家的合作，进一步验证和优化这些增强功能。