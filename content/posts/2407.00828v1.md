---
author: 'TechScribe'
title: '"深度强化学习在混合车辆通信网络中的创新应用：提升V2X应用性能"'
date: '2024-04-03'
Lastmod: '2024-07-05'
description: 'DRL-Based RAT Selection in a Hybrid Vehicular Communication Network'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![DRL-Based RAT Selection in a Hybrid Vehicular Communication Network](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00828v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00828v1)

## 摘要

本文由Badreddine Yacine YACHEUR、Toufik AHMED和Mohamed MOSBAH共同撰写，探讨了在混合车辆通信网络中基于深度强化学习（DRL）的无线接入技术（RAT）选择问题。文章针对智能交通系统中的车辆到一切（V2X）应用，特别是高级驾驶员辅助系统（ADASs）和连接自动驾驶（CAD）应用，提出了一个智能、可扩展的混合车辆通信架构。该架构利用多种RAT的优势，通过DRL算法实现通信模式选择，以最大化网络可靠性并限制资源消耗。研究结果表明，与静态RAT选择策略和多准则决策（MCDM）选择算法相比，该混合架构能显著提高数据包接收率（PRR）并优化资源利用效率。<!--more-->

## 原理

本文提出的混合车辆通信架构通过集成ITS-G5和LTE-V2X技术，利用DRL算法进行通信模式选择。DRL算法的核心在于通过深度学习模型预测和选择最优的通信模式，以适应车辆网络中动态变化的信道状态和应用需求。每个车辆被视为一个代理，通过环境状态的观测（包括信号噪声比（SNIR）、数据包接收率（PRR）、延迟和可靠性要求）来选择行动。代理根据接收到的反馈（包括消息接收评估、性能满意度（PS）和链路质量（LQ）增强）来调整其策略，从而实现网络性能的最优化。

## 流程

文章详细描述了DRL算法的工作流程，包括环境状态的初始化、行动选择、反馈接收和策略更新。每个代理根据当前环境状态选择行动，并根据最早的链路质量测量接收反馈。代理使用双深度Q学习算法（Double Deep Q-Learning）来更新其策略，该算法结合了Q学习和深度学习，通过神经网络模型来近似Q值，并使用经验回放机制来优化学习过程。具体的工作流程包括初始化行为网络和目标网络参数、设置回放缓冲区和批量大小、执行行动并接收反馈、存储转换并训练模型，以及定期更新目标网络参数。

## 应用

本文提出的混合车辆通信架构和DRL算法选择策略具有广泛的应用前景，特别是在需要高可靠性、低延迟和高吞吐量的V2X应用中，如ADASs和CAD。该技术能够有效提升车辆网络的性能，减少资源浪费，并支持未来智能交通系统的发展。此外，该研究还为未来在实际设备上评估该选择算法以及探索ITS-G5和C-V2X在5.9 GHz频段的共存提供了基础。