---
author: 'TechScribe'
title: '"从人工针到真实草堆：提升LLMs在长上下文中的检索能力"'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19292v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19292v1)

## 摘要

本文由威斯康星大学麦迪逊分校的研究人员提出，针对大型语言模型（LLMs）在处理长上下文输入时信息检索和推理能力不足的问题，提出了一种基于合成数据集的微调方法。该方法通过设计包含数值键值检索任务的合成数据集，对模型如GPT-3.5 Turbo和Mistral 7B进行微调，显著提升了模型在长上下文设置下的信息检索和推理能力。研究结果显示，这种方法不仅提高了模型在特定任务如多文档问答（MDQA）和灵活长度问答（FLenQA）上的表现，而且在通用基准测试上的性能几乎保持不变，避免了其他长上下文增强数据可能导致的幻觉问题。<!--more-->

## 原理

本文提出的方法通过创建一个合成数据集，该数据集包含简单的键值检索任务和多子键键值检索任务。这些任务的特点是键和值均为整数，且键可以是单个整数或整数元组。模型在接收到这些合成数据后，通过微调学习如何从这些结构化的数据中准确地检索和推理信息。这种微调方法的关键在于，通过在合成数据上训练，模型能够更好地理解和处理长上下文中的信息，从而在实际应用中表现出更强的检索和推理能力。此外，合成数据的使用避免了包含事实信息可能导致的幻觉问题，确保了模型输出的准确性和可靠性。

## 流程

论文中详细描述了微调过程的工作流程。首先，对于Mistral 7B模型，使用包含350个样本的简单键值检索任务数据集进行微调，每个任务包含85个字典，每个字典有3到4个键。微调过程中，模型仅对答案部分进行训练，屏蔽了指令部分。对于GPT-3.5 Turbo模型，由于其在简单键值检索任务上已有良好表现，因此选择更复杂的多子键键值检索任务进行微调。在评估阶段，模型在多文档问答（MDQA）和灵活长度问答（FLenQA）任务上进行测试，结果显示微调后的模型在这些任务上的表现有显著提升。

## 应用

本文提出的微调方法在提升大型语言模型在长上下文任务中的表现方面显示出巨大潜力。这种方法不仅适用于问答系统，还可以扩展到需要复杂信息检索和推理能力的多种应用场景，如法律文档分析、科学研究文献处理等。此外，由于合成数据的使用避免了幻觉问题，这种方法在需要高度可靠性和准确性的领域，如医疗诊断和金融分析中，也具有广泛的应用前景。