---
author: 'TechScribe'
title: '"解构复杂问题：基于知识与视觉推理的VQA新方法"'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.18839v1.pdf_0.jpg)](https://arxiv.org/abs/2406.18839v1)

## 摘要

本文研究了基于知识的视觉问答（KB-VQA）问题，其中模型需要将问题与视觉模态相结合以找到答案。尽管近期许多工作使用问题依赖的图像描述生成器和大型语言模型（LLM）来解决VQA问题，但研究结果显示它们在处理多跳问题时表现不佳。本文提出通过将复杂问题分解为多个简单问题来提取更多相关信息，并增强对图像的理解。此外，通过分析分解后的问题，确定所需信息的模态，并使用图像描述生成器处理视觉问题，同时使用LLM作为非视觉KB-VQA问题的通用知识源。实验结果表明，在OKVQA、A-OKVQA和KRVQA三个知名VQA数据集上，使用简单问题进行信息检索前的方法提高了准确率，最高可达2%。<!--more-->

## 原理

本文的核心创新在于通过问题分解技术，将复杂的VQA问题分解为多个简单的子问题，从而提高模型对图像的理解和答案的准确性。具体来说，使用GPT-3.5模型将复杂问题分解为多个简单的子问题，然后根据这些子问题的性质（视觉或非视觉）选择合适的模型进行信息提取。对于视觉问题，使用如PromptCap或InstructBlip等模型提取图像中的视觉信息；对于非视觉问题，则使用GPT模型从外部知识源中提取相关信息。最后，将所有提取的信息整合，使用LLM生成最终答案。这种方法通过简化问题和增强信息提取的针对性，显著提高了VQA任务的性能。

## 流程

1. **问题分解**：使用GPT-3.5模型将复杂问题分解为多个简单的子问题。
2. **类型检查**：确定每个子问题是视觉问题还是非视觉问题。
3. **信息提取**：
   - 对于视觉问题，使用图像描述生成器（如PromptCap或InstructBlip）提取图像中的视觉信息。
   - 对于非视觉问题，使用GPT模型从外部知识源中提取相关信息。
4. **信息整合**：将所有提取的信息整合，形成一个丰富的上下文。
5. **答案生成**：使用LLM基于整合的上下文生成最终答案。

例如，对于问题“摩托车骑手嘴里有什么？”，模型可能分解为以下子问题：
- 摩托车骑手是否戴着头盔？
- 摩托车骑手是否在说话或吃东西？
- 摩托车骑手是否在吸烟或咀嚼口香糖？
- 我们能看到摩托车骑手嘴里的东西吗？

通过这些子问题，模型能够更精确地提取和理解图像中的相关信息，从而生成更准确的答案。

## 应用

本文提出的方法不仅提高了VQA任务的准确性，还为处理复杂的多模态问题提供了新的思路。这种方法可以广泛应用于需要结合视觉和语言信息的领域，如教育、娱乐、辅助技术等。特别是在需要复杂推理和多模态理解的场景中，如智能辅导系统、增强现实应用等，这种方法具有巨大的潜力。