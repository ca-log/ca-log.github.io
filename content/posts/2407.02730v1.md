---
author: 'TechScribe'
title: '探索医疗领域大型视觉语言模型的幻觉问题：MedVH数据集的引入与评估'
date: '2024-07-03 00:59:03+00:00'
Lastmod: '2024-07-04 01:53:09.420731'
description: 'MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02730v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02730v1)

## 摘要

本文介绍了一项关于大型视觉语言模型（LVLMs）在医疗领域中幻觉现象的研究。研究团队引入了新的基准数据集——医学视觉幻觉测试（MedVH），旨在评估特定领域LVLMs在处理小数据集时的幻觉问题。MedVH包含五个任务，用于评估LVLMs在医疗环境中的幻觉情况，包括对文本和视觉输入的综合理解以及长文本响应生成。实验结果显示，尽管医疗LVLMs在标准医疗任务上表现出色，但它们在幻觉问题上比通用模型更为脆弱，这引发了对其在实际医疗应用中可靠性的重大担忧。<!--more-->

## 原理

本文提出的MedVH数据集通过五个特定领域的任务来评估LVLMs的幻觉问题。这些任务包括多选视觉问答（MC-VQA）和医学报告生成等，旨在测试模型在处理医学图像和文本时的准确性和鲁棒性。关键在于模型能否区分正确与误导性的输入，并在生成长文本响应时避免幻觉。通过这些任务，研究揭示了医疗LVLMs在处理复杂医疗信息时的局限性，特别是在面对可能导致幻觉的输入时。

## 流程

研究团队首先通过MC-VQA任务评估模型对视觉和文本信息的理解能力，这些任务包括疾病识别和严重性评估。随后，通过医学报告生成和错误自信度验证任务，评估模型在生成长文本时的幻觉倾向。实验中使用了三种类型的LVLMs：通用模型、医疗LVLMs和胸部X光（CXR）微调LVLMs。通过这些实验，研究团队展示了模型在不同任务上的表现，并分析了其在实际应用中的潜在风险。

## 应用

本文的研究成果为未来评估和改进医疗LVLMs的鲁棒性和专业性提供了基础。通过MedVH数据集，研究人员可以更系统地测试和优化模型，以确保其在医疗决策支持系统中的可靠性和安全性。随着技术的进步，这些模型有望在临床诊断和治疗计划中发挥重要作用，提高医疗服务的质量和效率。