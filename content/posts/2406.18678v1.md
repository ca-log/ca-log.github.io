---
author: 'TechScribe'
title: 'FERMI：大语言模型的少样本个性化新方法'
date: '2024-06-26'
Lastmod: '2024-07-05'
description: 'Few-shot Personalization of LLMs with Mis-aligned Responses'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Few-shot Personalization of LLMs with Mis-aligned Responses](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.18678v1.pdf_0.jpg)](https://arxiv.org/abs/2406.18678v1)

## 摘要

本文提出了一种新的方法FERMI，用于大语言模型（LLMs）的少样本个性化，特别是在模型响应与用户意见不一致的情况下。FERMI的核心思想是通过迭代改进个性化提示，基于用户资料（如人口统计信息）和少量先前的意见，学习一组针对每个用户的个性化提示。该方法通过整合LLMs的错误响应上下文，有效地实现了LLMs的个性化，显著提高了在各种基准测试中的性能。<!--more-->

## 原理

FERMI的工作原理基于三个关键步骤的迭代过程：评分提示、更新记忆和生成新提示。首先，使用LLM对初始或当前提示进行评分，评估其在预测用户先前答案时的准确性。其次，更新记忆，保留表现最佳的提示及其评分和错误响应的上下文。最后，基于更新后的记忆，使用LLM生成新的改进提示。此外，FERMI还开发了一种有效的推理方法，通过考虑测试查询的上下文来进一步利用个性化提示。

## 流程

FERMI的工作流程包括以下步骤：
1. **评分提示**：使用LLM评估每个提示的准确性，并收集与用户答案不一致的QA对。
2. **更新记忆**：构建一个优化记忆，包含表现最佳的提示及其评分和错误响应的上下文。
3. **生成新提示**：使用LLM基于更新后的记忆生成新的改进提示。
4. **推理**：在给定测试查询时，选择与查询上下文最相关的个性化提示进行响应。

## 应用

FERMI的应用前景广泛，特别是在需要个性化响应的领域，如搜索引擎、聊天机器人等。该方法能够有效提升LLMs在处理特定用户需求时的性能，尤其对于少数群体用户，能够减少模型偏见，提供更加公正和个性化的服务。