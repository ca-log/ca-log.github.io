---
author: 'TechScribe'
title: '**神奇的LoRA压缩术：让你的AI服务飞起来！**'
date: '2024-06-17'
Lastmod: '2024-07-05'
description: 'Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00066v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00066v1)

## 摘要

本文介绍了一种名为“Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead”的方法，该方法旨在解决在服务实时响应查询时，需要处理大量不同LoRA适配器的挑战。通过压缩LoRA适配器，该方法可以在服务数千个LoRA时提高吞吐量，同时保持较高的性能。<!--more-->

## 原理

该方法的核心思想是将低秩适配器（LoRA）的更新参数化，通过学习神经网络矩阵的低秩加性变化来实现参数高效的微调。具体来说，该方法通过奇异值分解（SVD）将LoRA适配器的权重矩阵分解为两个较小的矩阵，从而实现压缩。此外，该方法还提出了一种联合压缩算法，通过寻找共享基和LoRA特定的缩放矩阵来进一步提高压缩效率。

## 流程

1. 准备数据：收集需要压缩的LoRA适配器，并将其转换为适合压缩的格式。
2. 压缩LoRA适配器：使用SVD或联合压缩算法对LoRA适配器进行压缩。
3. 服务压缩后的LoRA适配器：将压缩后的LoRA适配器部署到服务中，以提高吞吐量和性能。

## 应用

该方法可以应用于各种需要处理大量LoRA适配器的场景，如自然语言处理、计算机视觉等。通过压缩LoRA适配器，可以提高服务的吞吐量和性能，降低成本，同时保持较高的准确性。