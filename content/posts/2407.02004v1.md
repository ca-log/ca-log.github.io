---
author: 'TechScribe'
title: '"SAVE模型：革新音频-视觉分割技术的轻量级解决方案"'
date: '2024-07-02 07:22:28+00:00'
Lastmod: '2024-07-04 01:17:38.280272'
description: 'SAVE: Segment Audio-Visual Easy way using Segment Anything Model'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![SAVE: Segment Audio-Visual Easy way using Segment Anything Model](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02004v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02004v1)

## 摘要

本文介绍了一种名为SAVE的轻量级音频-视觉分割（AVS）模型，该模型通过适应预训练的Segment Anything Model（SAM）来高效地识别和定位视觉场景中的听觉元素。SAVE模型通过引入图像编码器适配器和残余音频编码器适配器，有效地融合了音频和视觉特征，提高了分割的准确性和速度。实验证明，SAVE在AVSBench数据集上的表现优于现有的最先进方法，尤其是在输入分辨率为256像素时，性能显著提升。<!--more-->

## 原理

SAVE模型的核心创新在于其图像编码器适配器和残余音频编码器适配器。图像编码器适配器通过在每个变换器块中添加适配层，冻结原始图像编码器的参数，从而在通道和空间维度上增强数据集特定知识的传递。残余音频编码器适配器则通过多层感知机（MLP）和残余连接，将音频特征转换并注入到变换器块中，最终输出作为稀疏提示用于掩码解码器。这种设计不仅加速了训练和推理速度，还提高了模型的性能和泛化能力。

## 流程

SAVE模型的工作流程包括以下步骤：首先，输入图像通过冻结的图像编码器进行处理，同时在每个变换器块中加入图像编码器适配器以增强特征。接着，音频特征通过残余音频编码器适配器进行编码，并作为稀疏提示输入到掩码解码器中。最后，掩码解码器结合音频-视觉融合特征生成最终的分割掩码。例如，在AVSBench数据集上，SAVE模型能够准确地分割出视频帧中的单个或多个发声对象，如猫、枪支等。

## 应用

SAVE模型在视频监控、多模态视频编辑和机器人技术等领域具有广泛的应用前景。其高效的音频-视觉分割能力可以提升这些领域的自动化水平和精确度。此外，SAVE模型在低分辨率输入下的高性能表现，使其在资源受限的环境中尤为适用。