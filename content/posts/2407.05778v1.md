---
author: 'TechScribe'
title: '"挑战自一致性：LLMs通过更长推理文本实现更准确预测"'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'When is the consistent prediction likely to be a correct prediction?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![When is the consistent prediction likely to be a correct prediction?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05778v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05778v1)

## 摘要

本文由Alex Nguyen等人撰写，针对自一致性（Self-consistency）方法在大型语言模型（LLMs）中的应用提出了一种修正。自一致性方法认为，通过LLMs生成的最一致答案更有可能是正确的。然而，本文通过实验观察到，通过更多计算（即更长的推理文本）得到的答案，而不是仅仅考虑所有输出中最一致的答案，更有可能是正确的。这是因为LLMs在生成更长响应时，能够自主产生链式思维（CoT）风格的推理，而不需要任何自定义提示。在零样本设置中，通过多次采样Mixtral-8x7B模型并考虑更长的响应，作者实现了在GSM8K和MultiArith数据集上达到86%的自一致性性能。此外，文章还强调了LLMs生成更长响应的概率较低，因此需要基于输出长度的解码策略。<!--more-->

## 原理

本文的核心在于探讨LLMs在生成更长推理文本时，如何自发产生链式思维（CoT）风格的推理，从而提高答案的准确性。CoT推理涉及引导LLMs通过逐步分解示例来处理问题，这在传统上需要特定的提示前缀。然而，本文发现LLMs在生成更长响应时，能够独立产生CoT风格的推理，无需任何前缀提示。这种自发产生的CoT推理通过更长的推理文本增强了模型的性能，使其在推理基准上表现更佳。

## 流程

文章通过实验展示了LLMs在生成更长推理文本时，如何自发产生CoT风格的推理。具体流程如下：
1. 使用Mixtral-8x7B和Llama-2 70B模型进行实验。
2. 在推理提取步骤中，通过设置温度为1.2和top-k采样（k=40）来鼓励推理提取的多样性。
3. 在答案提取步骤中，使用贪婪解码采样50个令牌，以减少答案的变异性。
4. 通过不添加任何前缀的零样本设置，仅在生成的令牌数超过60时考虑响应。
5. 通过多次采样并考虑超过特定长度阈值的响应，选择最一致的答案，观察到性能显著提升。
6. 在更长的响应中，自发出现CoT风格的推理，无需特定提示。

## 应用

本文提出的方法在数学推理基准上展示了显著的性能提升，特别是在零样本设置中。这种方法的应用前景广泛，包括但不限于教育领域的智能辅导系统、复杂问题解答系统以及需要高级推理能力的自动化决策支持系统。通过进一步优化解码策略和模型架构，未来LLMs在处理复杂推理任务上的能力有望得到进一步提升。