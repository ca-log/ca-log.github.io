---
author: 'TechScribe'
title: '探索开放词汇时间动作定位的自训练方法：利用未标记视频提升泛化能力'
date: '2024-07-09'
Lastmod: '2024-07-10'
description: 'Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07024v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07024v1)

## 摘要

本文探讨了在开放词汇时间动作定位（OV-TAL）中通过自训练方法利用未标记的YouTube视频来扩展词汇量的有效性和可扩展性。由于大规模标注数据集的稀缺，现有的OV-TAL方法依赖于小规模的完全标注数据集进行训练。本文提出了一种两阶段的自训练方法，首先在人工标注的数据集上训练一个类别无关的动作定位器，然后使用该定位器为未标记的视频生成伪标签，并将这些伪标签与人工标注的数据集结合，以训练更通用的动作定位器。实验证明，利用网络规模的视频进行自训练显著提高了动作定位器的泛化能力。此外，本文还指出了现有OV-TAL评估方案的问题，并提出了一种新的评估协议。<!--more-->

## 原理

本文提出的自训练方法分为两个阶段。第一阶段，使用人工标注的时间动作定位（TAL）数据集训练一个类别无关的动作定位器。这个定位器能够生成未标记视频的伪标签。第二阶段，将这些伪标签与人工标注的数据集结合，用于训练动作定位器。这种方法的关键在于利用大规模的未标记视频数据来增强模型的泛化能力，而不是依赖于有限的人工标注数据。通过这种方式，模型能够学习到更多样化的动作类别和视频域，从而提高其在未见过的数据上的表现。

## 流程

本文的工作流程如图1所示。首先，在人工标注的TAL数据集上训练一个类别无关的动作定位器。然后，使用这个定位器为未标记的视频生成伪标签。由于高标注成本，人工标注的数据集在数量和类别上都是有限的，而伪标签则不受这些限制。最后，将结合了伪标签的数据集用于训练定位器，增强其在多样动作类别和视频域上的泛化能力。实验中还探索了两种数据源：域内数据（包括目标基准的新类别视频）和开放域数据（包括随机的网络视频）。通过增加mAP（平均精度）值，证明了自训练方法的可扩展性。

## 应用

本文提出的自训练方法不仅提高了动作定位器的泛化能力，还为OV-TAL领域引入了新的评估基准，包括广义零样本设置和跨数据集泛化评估。这些改进有望推动OV-TAL技术在更广泛的应用场景中的发展，如视频监控、体育分析和社交媒体内容分析等。通过利用未标记的大规模视频数据，该方法为实现更灵活和强大的动作定位系统提供了新的可能性。