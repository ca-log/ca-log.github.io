---
author: 'TechScribe'
title: 'TransMA：革命性的多模态深度学习模型，引领mRNA递送技术的新纪元'
date: '2024-07-08'
Lastmod: '2024-07-09'
description: 'TransMA: an explainable multi-modal deep learning model for predicting properties of ionizable lipid nanoparticles in mRNA delivery'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![TransMA: an explainable multi-modal deep learning model for predicting properties of ionizable lipid nanoparticles in mRNA delivery](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05736v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05736v1)

## 摘要

本文介绍了一种名为TransMA的可解释多模态深度学习模型，用于预测离子化脂质纳米粒子（LNPs）在mRNA递送中的性质。TransMA模型通过融合分子结构的多模态信息，揭示了原子级别的结构-转染关系，并在当前最大的LNPs数据集上实现了最先进的性能。该模型不仅提高了预测的准确性，还增强了模型的可解释性，为LNPs的设计和初步筛选提供了有价值的见解。<!--more-->

## 原理

TransMA模型采用了一种多模态分子结构融合架构，其中包括两个主要组件：分子3D Transformer和分子Mamba。分子3D Transformer负责提取分子的三维空间特征，而分子Mamba则提取一维分子特征。这两个组件的输出通过一个名为mol-attention的机制块进行融合，该机制块能够对原子级别的结构-转染关系进行解释。具体来说，分子3D Transformer通过预训练和微调的方式，利用自注意力机制捕捉分子内部的原子间关系，而分子Mamba则通过状态空间模型处理分子的SMILES表示，提取一维序列信息。最后，mol-attention机制块将这两种特征融合，并通过注意力机制确定哪些原子对转染效率有显著影响。

## 流程

TransMA的工作流程包括以下几个步骤：首先，分子3D Transformer和分子Mamba分别对输入的分子结构信息进行特征提取。分子3D Transformer通过预训练任务（如掩码语言建模和噪声坐标预测）提取三维结构特征，而分子Mamba则通过选择性扫描操作和离散化的状态空间模型方程提取一维序列特征。接着，这两个组件的输出特征通过mol-attention机制块进行融合，该机制块通过注意力机制计算每个原子的重要性得分。最后，模型通过回归层预测转染效率。例如，在处理一个具体的LNPs数据集时，模型首先对数据进行预处理，然后通过上述流程进行特征提取和融合，最终输出转染效率的预测结果。

## 应用

TransMA模型在预测离子化脂质纳米粒子（LNPs）的转染效率方面具有广泛的应用前景。由于其高精度和可解释性，该模型可以用于加速mRNA药物递送系统的设计和筛选过程，特别是在需要高转染效率的医疗应用中，如疫苗开发、蛋白质替代疗法和癌症免疫疗法等。此外，TransMA的泛化能力使其能够适应不同的细胞系和外部数据集，进一步扩大了其在生物医学领域的应用范围。