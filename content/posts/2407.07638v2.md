---
author: 'TechScribe'
title: '"利用候选标签进行视觉-语言模型微调：提示对齐框架的创新应用"'
date: '2024-07-10'
Lastmod: '2024-07-12'
description: 'Tuning Vision-Language Models with Candidate Labels by Prompt Alignment'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Tuning Vision-Language Models with Candidate Labels by Prompt Alignment](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07638v2.pdf_0.jpg)](https://arxiv.org/abs/2407.07638v2)

## 摘要

本文探讨了在视觉-语言模型（VLMs）中使用候选标签进行提示学习的问题。传统的提示学习方法依赖于精确的标签数据，这在实际应用中由于数据隐私或敏感性问题可能难以获取。本文首次研究了在仅能获得包含真实标签的候选标签集的情况下，如何有效地进行提示学习。研究者提出了一种新的框架，通过动态混合由可学习提示和手工提示预测的类别后验概率，并将其与模型输出对齐，从而提高模型在处理候选标签时的鲁棒性。实验证明，该框架在多个基准数据集上显著提升了性能，尤其是在标签模糊度较高的情况下。<!--more-->

## 原理

本文提出的框架通过结合手工提示和可学习提示的优势，利用混合类别后验概率来指导模型学习过程。具体来说，模型首先通过手工提示和可学习提示分别预测类别后验概率，然后通过一个动态混合策略将这两者结合起来，形成一个混合的类别后验概率。这个混合后验概率随后与模型的输出进行对齐，通过加权交叉熵损失来优化模型参数。这种对齐机制使得模型能够更好地利用预训练VLMs的零样本能力，从而在处理模糊标签时更加稳健。

## 流程

1. **输入处理**：模型接收输入图像和候选标签集。
2. **提示生成**：生成手工提示和可学习提示。
3. **类别后验概率预测**：分别通过手工提示和可学习提示预测类别后验概率。
4. **混合策略**：应用动态混合策略将两者的类别后验概率结合起来。
5. **对齐优化**：将混合的类别后验概率与模型输出对齐，通过加权交叉熵损失进行优化。
6. **输出预测**：模型输出最终的类别预测。

例如，在图像分类任务中，模型可能会接收到一张包含鹰、雕和隼的图像，这三个标签作为候选标签。通过上述流程，模型能够更准确地识别出图像中的真实标签。

## 应用

该框架适用于需要处理模糊标签的多种实际应用场景，如网络挖掘、在线标注和生态信息学等。由于其能够有效利用预训练VLMs的零样本能力，该框架在处理大规模数据集和复杂标签环境时具有显著优势。未来，该框架可以进一步扩展到其他多模态学习和零样本学习任务中，具有广泛的应用前景。