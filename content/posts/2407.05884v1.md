---
author: 'TechScribe'
title: '挑战传统认知模型：单一系统如何同时学习和记忆事件与规则'
date: '2024-07-08'
Lastmod: '2024-07-09'
description: 'One system for learning and remembering episodes and rules'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![One system for learning and remembering episodes and rules](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05884v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05884v1)

## 摘要

本文由Joshua T. S. Hewson、Sabina J. Sloman和Marina Dubova共同撰写，探讨了人类学习个体事件和可概括规则的能力，并强调了这两种学习在时间上的保持能力。传统观点认为，学习个体事件和规则以及学习和记忆是两个需要独立互补学习系统的竞争过程。本文挑战了这一观点，提出这些权衡源于容量限制而非认知过程的内在不兼容性。通过一个关联学习任务，研究显示一个具有过剩表征容量的系统能够同时学习和记忆事件和规则。<!--more-->

## 原理

本文的核心在于探讨如何通过增加计算模型的容量来克服传统上观察到的学习个体事件和规则之间的权衡，以及学习和记忆之间的权衡。研究采用了多层感知器架构，通过调整模型的容量（即隐藏节点的数量），展示了在过剩容量条件下，模型不仅能够学习新的规则和事件，还能保留先前学习的知识，避免了“灾难性遗忘”现象。这一发现挑战了传统上认为需要两个独立系统来处理学习和记忆的观点，证明了单一系统在足够容量下可以同时处理这两种认知任务。

## 流程

研究首先定义了不同容量的模型：受限容量、足够容量和过剩容量模型。在实验中，模型首先在第一阶段学习将一组数据（Atrain）与目标数据（B）关联，同时测试其对新数据（Atest）到另一目标数据（C）的泛化能力。在第二阶段，模型被要求学习新的关联（Atrain与C），并测试其对先前学习的关联（Atrain与B）的记忆能力。通过这种设置，研究展示了过剩容量模型在学习和记忆方面的优越性能。

## 应用

本文的研究成果对于持续学习、迁移学习和高级认知架构的发展具有重要意义。通过理解不同容量条件下的学习特性，可以为设计更高效、灵活的AI系统和认知模型提供理论基础。此外，这一研究也为解决AI领域中的灾难性遗忘问题提供了新的视角和方法。