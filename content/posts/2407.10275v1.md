---
author: 'TechScribe'
title: '跨语言多跳知识编辑：CLEVER-CKE系统的创新与应用'
date: '2024-07-14'
Lastmod: '2024-07-16'
description: 'Cross-Lingual Multi-Hop Knowledge Editing -- Benchmarks, Analysis and a Simple Contrastive Learning based Approach'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Cross-Lingual Multi-Hop Knowledge Editing -- Benchmarks, Analysis and a Simple Contrastive Learning based Approach](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10275v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10275v1)

## 摘要

本文介绍了一种名为“跨语言多跳知识编辑”的新范式，旨在评估和分析不同最先进（SoTA）知识编辑技术在跨语言环境中的性能。文章提出了一个并行的跨语言基准测试CROLIN-MQUAKE，用于测量知识编辑能力，并发现跨语言设置与以英语为中心的设置之间存在显著的性能差距。为了解决这一问题，文章提出了一种改进的系统CLEVER-CKE，该系统基于检索、验证和生成知识编辑框架，通过引入语言感知和基于硬负样本的对比目标，提高了跨语言和细粒度事实检索与验证过程的性能。实验结果显示，CLEVER-CKE在多个大型语言模型（LLMs）、八种语言和两个数据集上的性能比先前方法提高了多达30%。<!--more-->

## 原理

CLEVER-CKE系统的工作原理基于一个三阶段的框架：检索、验证和生成。首先，系统使用一个检索器从编辑的事实记忆中召回相关事实。然后，通过一个验证过程确定检索到的事实是否有助于回答问题。最后，LLM利用这些信息生成答案。CLEVER-CKE通过引入语言感知的对比损失和硬负样本挖掘，增强了检索器的跨语言和细粒度理解能力，从而提高了知识编辑的准确性和效率。

## 流程

CLEVER-CKE的工作流程包括以下步骤：
1. **子问题分解**：LLM将多跳问题分解为多个子问题。
2. **事实检索**：对于每个子问题，检索器从外部记忆中召回最相关的事实。
3. **事实验证**：通过对比损失函数验证检索到的事实是否有助于回答子问题。
4. **答案生成**：LLM利用验证后的信息生成子问题的答案，并最终组合成完整的答案。

## 应用

CLEVER-CKE的应用前景广泛，特别是在需要跨语言知识编辑和多跳问题回答的场景中，如全球客户服务、多语言信息检索和国际合作项目。该系统的高效性和准确性使其成为处理复杂跨语言知识编辑任务的有力工具。