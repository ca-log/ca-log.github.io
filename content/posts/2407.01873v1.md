---
author: 'TechScribe'
title: '开源小规模GLMs在自动文本评分中的应用与挑战'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Automated Text Scoring in the Age of Generative AI for the GPU-poor'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Automated Text Scoring in the Age of Generative AI for the GPU-poor](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01873v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01873v1)

## 摘要

本文由Christopher Ormerod和Alexander Kwako共同撰写，探讨了在资源有限的条件下，使用开源的小规模生成语言模型（GLMs）进行自动文本评分（ATS）的性能和效率。研究结果表明，通过微调，这些GLMs能够达到虽非最先进但足够的表现水平。此外，研究还尝试通过提示GLMs解释其评分，分析模型生成反馈的能力，显示出一定的潜力，但需要更严格的评估，特别是在特定使用案例中。<!--more-->

## 原理

本文采用了一种参数高效的微调方法，结合了量化（quantization）和低秩适配器（LoRA），使得在不超过8GB内存的条件下，能够对GLMs进行微调。量化通过降低模型参数的精度来减少内存需求，而LoRA则通过引入低秩矩阵来更新模型的大型前馈层，从而在不显著增加参数数量的情况下实现有效的微调。这种组合方法被称为QLoRA，它不仅减少了内存消耗，还保持了模型的性能。

## 流程

研究首先选择了四个能够在标准消费者硬件上运行的开源模型：Llama-3、Mistral v0.2、Gemma-1.1和Phi-3。这些模型通过Huggingface-hub加载，并使用bitsandbytes进行4位量化，然后使用LoRA进行训练。训练过程中，学习率设置为2e-4，线性衰减超过10个周期，r和α参数均设置为32。模型在24GB A10 GPU上进行训练，使用早期停止策略，基于开发集上的最佳QWK性能。训练和推理时间相对于标准BERT分类模型进行了标准化处理。

## 应用

本文的研究表明，即使在资源有限的环境下，通过微调开源的小规模GLMs，也能够实现自动文本评分和生成反馈的功能。这种方法不仅提高了模型的透明度和安全性，还为教育领域的应用提供了新的可能性。未来，这种方法可以进一步扩展到更多的教育评估场景，特别是在需要个性化反馈和低成本解决方案的领域。