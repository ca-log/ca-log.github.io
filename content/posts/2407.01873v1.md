---
author: 'TechScribe'
title: '开源小规模生成语言模型在自动文本评分中的应用与前景'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Automated Text Scoring in the Age of Generative AI for the GPU-poor'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Automated Text Scoring in the Age of Generative AI for the GPU-poor](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01873v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01873v1)

## 摘要

本文探讨了在资源有限的环境下，使用开源的小规模生成语言模型（GLMs）进行自动文本评分（ATS）的性能和效率。研究者分析了这些模型在自动作文评分（AES）和自动简答题评分（ASAS）中的表现，并探索了模型生成评分解释的能力。结果显示，通过微调，这些GLMs能够达到虽非最先进但足够的表现水平，并且能够生成初步的评分反馈。此外，研究还强调了在教育评估中使用这些模型的透明度和安全性优势。<!--more-->

## 原理

本文采用的生成语言模型（GLMs）是基于开源的小规模模型，这些模型通常具有较少的参数和较低的计算需求，能够在消费级硬件上运行。通过使用低秩适配器（LoRA）和量化技术，这些模型可以在有限的GPU资源下进行高效的微调。LoRA通过引入低秩矩阵来调整预训练模型的权重，而量化则通过降低模型参数的精度来减少内存需求。这两种技术的结合使得模型在保持性能的同时，大大降低了训练和部署的成本。

## 流程

研究者首先选择了四个开源的GLMs（包括Llama-3、Mistral v0.2、Gemma-1.1和Phi-3），这些模型均能在8GB或更少的内存下运行。然后，使用自动学生评估奖（ASAP）数据集中的作文和简答题数据对这些模型进行微调。微调过程中，采用了LoRA和量化技术来优化模型参数。微调后的模型被用于预测作文和简答题的分数，并通过特定的提示模板生成评分解释。整个流程包括数据准备、模型选择、微调、评分预测和反馈生成。

## 应用

本文的研究表明，开源的小规模GLMs在自动文本评分领域具有广阔的应用前景。这些模型不仅能够在资源有限的环境中高效运行，还能够提供透明的评分过程和安全的评分结果。未来，这些模型可以进一步优化，以提供更准确的评分和更有价值的反馈，特别是在教育评估和个性化学习支持方面。此外，随着技术的进步，这些模型还可以扩展到其他语言和更广泛的文本类型评分中。