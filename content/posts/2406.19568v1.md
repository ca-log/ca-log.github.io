---
author: 'TechScribe'
title: '揭秘AI视频生成：如何识别Sora等模型的假视频？'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'What Matters in Detecting AI-Generated Videos like Sora?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![What Matters in Detecting AI-Generated Videos like Sora?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19568v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19568v1)

## 摘要

本文由Chirui Chang等研究者撰写，探讨了当前基于扩散的视频生成模型（如Stable Video Diffusion和Sora）与真实世界视频之间的差距。文章通过分析视频的外观、运动和几何三个基本方面，揭示了合成视频与真实视频之间的显著差异。研究团队训练了三个基于3D卷积网络的分类器，分别针对外观、运动和几何特征，以检测AI生成的假视频。此外，研究还提出了一个集成专家模型，该模型结合了外观、光学流和深度信息，以提高假视频检测的鲁棒性和泛化能力。实验结果表明，即使在没有接触过Sora视频的情况下，该模型也能准确检测出由Sora生成的视频，这表明真实与假视频之间的差距可以跨不同的视频生成模型泛化。<!--more-->

## 原理

本文的核心工作原理在于通过三个关键的视觉维度——外观、运动和几何，来分析和比较AI生成的视频与真实视频之间的差异。研究者使用3D卷积神经网络（3D ConvNets）来训练分类器，每个分类器专注于一个特定的视觉维度。外观分类器利用视觉基础模型（如DINOv2）提取的高级特征来分析视频的纹理、颜色和光照条件；运动分类器通过光学流（如RAFT提取的）来捕捉视频中的动态变化；几何分类器则通过单目深度估计（如Marigold和UniDepth提供的）来评估视频中的空间结构和形状。通过这种方式，研究者能够量化并可视化AI生成视频与真实视频在各个维度上的差异，从而开发出能够有效检测假视频的集成模型。

## 流程

研究的工作流程首先涉及数据集的构建，包括从Pexels等来源收集的真实世界视频和使用Stable Video Diffusion模型生成的合成视频。接着，研究者设计了一个综合视频表示（CVR）框架，该框架将视频分解为外观、运动和几何三个组成部分，并分别提取相应的特征。然后，使用3D卷积网络对这些特征进行分类，以判断视频的真伪。为了提高模型的泛化能力，研究者进一步开发了一个集成专家模型，该模型结合了三个分类器的输出，通过加权投票机制来确定最终的分类结果。整个流程还包括使用Grad-CAM技术来可视化和分析分类器在决策过程中依赖的关键区域，从而深入理解AI生成视频的局限性。

## 应用

本文提出的方法不仅限于检测特定模型（如Sora）生成的视频，其泛化能力表明该技术可以应用于各种视频生成模型，这对于打击虚假信息、保护媒体真实性具有重要意义。此外，该研究也为视频生成技术的进一步发展提供了方向，特别是在提高视频生成质量、缩小与真实视频差距方面。随着技术的进步，未来可能会有更多基于此研究的实际应用出现，如视频内容验证、版权保护和智能监控等领域。