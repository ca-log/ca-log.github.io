---
author: 'TechScribe'
title: '分层多模态Transformer：革新长文档分类的新方法'
date: '2024-07-14'
Lastmod: '2024-07-16'
description: 'Hierarchical Multi-modal Transformer for Cross-modal Long Document Classification'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Hierarchical Multi-modal Transformer for Cross-modal Long Document Classification](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10105v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10105v1)

## 摘要

本文针对长文档分类（LDC）中的多模态数据（如文本和图像）未被有效利用的问题，提出了一种新颖的分层多模态Transformer（HMT）方法。HMT通过在分层结构中进行多模态特征交互和融合，有效地处理了长文档中图像和文本的复杂关系。此外，引入了一种动态掩码转移模块，以增强不同层次Transformer之间的信息交互。实验结果表明，HMT在多个多模态长文档数据集上的表现优于现有的单模态和多模态方法。<!--more-->

## 原理

HMT的核心在于其分层结构，通过两个多模态Transformer分别处理段落级和句子级的文本与图像特征。动态多尺度多模态Transformer（DMMT）通过不同大小的窗口掩码来捕捉句子与图像之间的多尺度关系。动态掩码转移模块则确保了段落级与句子级Transformer之间的信息流畅交互，从而提升了模型对长文档中复杂多模态关系的理解能力。

## 流程

HMT的工作流程首先通过预训练的文本和图像模型提取初始的文本和图像特征。接着，使用两个多模态Transformer来捕捉文本和图像特征在不同层次上的复杂关系。动态掩码转移模块随后被用来增强这些Transformer之间的信息交互。最后，通过融合模块整合不同层次的特征，实现长文档的分类。

## 应用

HMT模型在文档管理、分析和个性化推荐等多个场景中具有广泛的应用前景。随着多模态数据在长文档处理中的重要性日益增加，HMT能够提供更精确的分类和理解能力，从而推动相关技术的发展和应用。