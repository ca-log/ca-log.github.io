---
author: 'TechScribe'
title: '揭秘XAI方法的可靠性与稳定性：eXirt方法的突破与应用前景'
date: '2024-07-03 13:47:41+00:00'
Lastmod: '2024-07-04 01:52:49.029992'
description: 'How Reliable and Stable are Explanations of XAI Methods?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![How Reliable and Stable are Explanations of XAI Methods?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03108v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03108v1)

## 摘要

本文探讨了可解释人工智能（XAI）方法的可靠性和稳定性问题。随着黑盒模型在日常生活中的广泛应用，XAI方法应运而生，旨在生成关于模型如何进行预测的额外解释。研究通过使用糖尿病数据集和四种不同的机器学习模型（LGBM、MLP、DT和KNN），创建了不同程度的测试数据扰动，并使用eXirt方法生成模型解释，以评估其稳定性。结果显示，eXirt能够识别最可靠的模型，并发现当前XAI方法对扰动敏感，除了一种特定方法外。<!--more-->

## 原理

本文的核心在于评估XAI方法的可靠性和稳定性。eXirt方法基于项目反应理论（IRT），通过特征相关性排序生成模型解释，允许人类个体对模型产生信心。IRT通过评估个体对特定项目的正确回答概率来估计潜在特质，这与传统评估方法不同，后者仅通过总正确答案数来衡量性能。eXirt利用IRT的特性，如难度、区分度和猜测，来评估模型的可靠性。

## 流程

研究首先选择糖尿病数据集，并将其标准化后分为训练和测试集。随后，构建了四种不同类型的机器学习模型，并对测试数据进行不同程度的扰动。接着，应用XAI技术（如Dalex、Eli5、eXirt、Lofo、Shap和Skater）生成模型解释。最后，通过特征相关性排序和项目特征曲线（ICC）分析模型的稳定性和可靠性。具体流程包括数据准备、模型构建、扰动应用、解释生成和结果分析。

## 应用

本文的研究结果表明，eXirt方法能够有效识别最可靠的模型，并且对扰动的稳定性较高。这表明eXirt在敏感领域的应用前景广阔，如医疗诊断和金融风险评估等。此外，研究还为XAI方法的稳定性提供了基准比较，有助于未来在更广泛的应用场景中推广和优化XAI技术。