---
author: 'TechScribe'
title: '探索OmniJARVIS：引领开放世界指令遵循代理的新时代'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'OmniJARVIS: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![OmniJARVIS: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00114v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00114v1)

## 摘要

本文介绍了一种名为OmniJARVIS的新型视觉-语言-动作（VLA）模型，该模型旨在使开放世界中的指令遵循代理能够进行推理和高效决策。OmniJARVIS通过统一的多模态交互数据令牌化，实现了对任务指令、记忆、思维、观察、文本响应和行为轨迹等长期多模态交互的建模。该模型在开放世界游戏Minecraft中展示了卓越的性能，能够处理原子级、程序级和开放式任务。论文还探讨了交互数据形成、统一令牌化和其扩展潜力的关键设计原则。<!--more-->

## 原理

OmniJARVIS的核心创新在于其行为令牌化（Behavior Tokenization）和自回归建模（Autoregressive Modeling）。首先，通过自监督学习方法，OmniJARVIS学习一个行为编码器，该编码器能够为行为轨迹生成离散令牌，并有一个模仿学习策略解码器基于这些令牌进行条件化。这些行为令牌随后被添加到预训练的多模态语言模型（MLM）的词汇表中。其次，OmniJARVIS将涉及任务指令、记忆、思维、观察、文本响应和行为轨迹的多模态交互数据打包成统一的令牌序列，并使用自回归变换器对其进行建模。这种设计使得OmniJARVIS能够通过产生思维链进行推理、规划、回答问题并通过产生行为令牌进行行动。

## 流程

OmniJARVIS的工作流程始于接收任务指令、初始记忆和观察。模型随后迭代地进行思维链推理，并产生行为令牌作为控制手段，这些令牌被发送到策略解码器以执行电机控制。每隔128步，OmniJARVIS会根据最新的观察重新进行推理并产生新的行为令牌。此外，OmniJARVIS还能够生成文本响应，例如回答问题。整个过程通过自监督学习和自回归建模实现，确保了模型在开放世界环境中的高效和智能决策。

## 应用

OmniJARVIS的应用前景广泛，特别是在需要复杂推理和高效决策的开放世界环境中，如虚拟现实、游戏和模拟训练系统。其统一的多模态令牌化方法不仅提高了模型的性能，还为未来的自主代理开发提供了新的研究方向和可能性。随着数据和模型规模的进一步扩展，OmniJARVIS有望在更多领域展现其强大的应用潜力。