---
author: 'Chengrui Huang,Zhengliang Shi,Yuntao Wen,Xiuying Chen,Peng Han,Shen Gao,Shuo Shang'
title: '探索工具学习框架的稳定性：大型语言模型与现实世界应用的交互挑战'
date: '2024-07-03'
Lastmod: '2024-07-05'
description: 'What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03007v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03007v1)

## 摘要

本文探讨了工具学习框架的稳定性问题，特别是在大型语言模型（LLMs）与现实世界应用交互时。文章指出，尽管现有研究通过微调LLMs或设计提示来使LLMs选择合适的工具并正确调用它们，但工具学习的表现因任务、数据集、训练设置和算法而异。这种不稳定性可能导致结果不一致、模型部署效率低下和工具利用不理想，最终阻碍LLMs在实际场景中的集成和扩展。为此，本文通过大量实验分析了影响工具学习框架性能的内外部因素，并提出了一些有价值的结论和未来研究方向。<!--more-->

## 原理

本文通过将多样化的因素分为内部和外部因素，系统地分析了它们对工具学习模型性能的影响。内部因素包括开发者在开发工具使用模型时的不确定性，如解码温度、最大推理步骤和不同基础LLMs的选择。外部因素涉及与已部署工具使用模型交互时的多样化提示工程，如不同风格的用户查询、定制的系统提示和用于解决查询的候选工具集。通过在常用的ToolBench数据集上进行广泛实验，文章采用多种常用指标从多个角度衡量性能，并得出了一系列有趣的发现，强调了现有工具使用流程对各种内外部因素的不稳定性，以及在内部因素中，适当的超参数设置可以提升LLMs生成多样化解的能力，但也可能导致不稳定性。

## 流程

文章详细描述了工具学习框架的工作流程，包括LLM如何通过迭代决定使用哪个工具（Thought）、执行选定的工具（Action），并将执行结果纳入上下文（Observation）以进行下一次迭代预测。例如，在默认的工具使用框架中，LLM被引导以自然语言生成工具使用计划，选择适当的工具并制定相应的参数，然后将工具的执行结果整合到当前上下文中。通过这种迭代过程，LLM最终解析执行结果以产生正确的响应。

## 应用

本文的研究为未来工具学习研究提供了新的视角，特别是在增强LLMs与现实世界应用的交互能力方面。文章指出，LLMs可以通过增加试验和探索来显著受益，这为开发更稳定和高效的工具学习框架提供了方向。此外，研究结果还表明，LLMs对候选工具集的顺序和规模敏感，这为设计更优化的工具选择模块提供了启示。未来工作可能包括扩展评估到由多模态LLMs赋能的工具使用代理，以及探索模型在更复杂环境中的稳定性，如与用户的动态交互。