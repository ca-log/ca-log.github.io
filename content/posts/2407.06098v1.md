---
author: 'TechScribe'
title: '"自动检测文本中的不公正：一种创新的人工智能框架"'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'Epistemological Bias As a Means for the Automated Detection of Injustices in Text'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Epistemological Bias As a Means for the Automated Detection of Injustices in Text](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06098v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06098v1)

## 摘要

本文由Kenya Andrews和Lamogha Chiazor共同撰写，探讨了如何利用细调的BERT模型结合其他模型和词典方法，自动检测文本中的不公正现象，特别是新闻媒体中的歧视性叙述。文章通过实证定性研究，展示了该框架在大量数据中检测不公正现象的有效性。<!--more-->

## 原理

本文提出的框架结合了三种模型：一个细调的BERT模型用于检测与认识论偏差相关的词汇，两个刻板印象检测模型CO-STAR和Social Bias Frames (SBF)用于生成与输入文本相关的潜在刻板印象及其概念，以及一个基于词典的方法。这些模型共同工作，通过识别文本中的认识论偏差词汇，进而关联到可能导致的刻板印象和不公正现象。

## 流程

该框架的工作流程包括以下步骤：首先，使用细调的BERT模型对输入文本进行分析，标记出可能含有认识论偏差的词汇；接着，将这些标记词汇输入到CO-STAR和SBF模型中，生成相关的刻板印象及其概念；最后，通过语义相似度分析，确定与原文最相关的刻板印象和概念。例如，在分析新闻标题时，框架能够识别出含有偏见的词汇，并指出这些词汇可能关联的刻板印象，从而帮助编辑和记者识别和避免文本中的不公正现象。

## 应用

该框架的应用前景广泛，特别适用于新闻媒体行业，帮助编辑和记者自动检测和避免文本中的不公正现象，如证词不公、性格不公和框架不公。此外，该技术也可扩展到其他领域，如政治、市场营销和医疗等，以提高文本内容的公正性和客观性。