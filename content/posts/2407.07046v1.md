---
author: 'TechScribe'
title: 'CorMulT：引领多模态情感分析的新纪元'
date: '2024-07-09'
Lastmod: '2024-07-10'
description: 'CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07046v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07046v1)

## 摘要

本文介绍了一种名为Correlation-aware Multimodal Transformer (CorMulT)的半监督多模态情感分析模型。该模型针对现有方法在处理弱相关多模态数据时性能不佳的问题，提出了一种两阶段的学习框架。在预训练阶段，通过模态相关对比学习模块有效地学习不同模态间的相关系数。在预测阶段，将学习到的相关系数与模态表示融合，以进行情感预测。实验结果表明，CorMulT在CMU-MOSEI数据集上显著超越了现有的多模态情感分析方法。<!--more-->

## 原理

CorMulT模型的核心在于其两阶段的学习框架。首先，在预训练阶段，模型通过模态相关对比学习模块（Modality Correlation Contrastive Learning Module）学习不同模态间的相关系数。该模块包括模态特定特征提取和模态相关评估两个子模块。特征提取模块负责从音频、图像和文本三种模态中提取单模态特征，而相关评估模块则分析这些模态间的相关性。通过对比学习，模型能够在共享的相关空间中量化不同模态间的距离，从而学习到模态间的相关系数。

在预测阶段，CorMulT模型将预训练阶段学习到的模态相关系数与模态表示融合，通过相关感知的多模态变换器模块（Correlation-aware Multimodal Transformer Module）进行情感分析。该模块接收来自音频、图像和文本模态的特征，并将这些特征与模态相关系数结合，通过多模态特征学习和模态相关增强的多模态融合，最终通过线性投影层和Softmax层输出情感预测结果。

## 流程

1. **预训练阶段**：
   - 输入音频、图像和文本数据。
   - 通过模态特定特征提取模块提取各模态的单模态特征。
   - 将提取的特征输入模态相关评估模块，通过对比学习计算模态间的相关系数。

2. **预测阶段**：
   - 接收新的音频、图像和文本数据。
   - 提取各模态的特征，并与预训练阶段学习到的模态相关系数结合。
   - 通过相关感知的多模态变换器模块进行特征融合和情感预测。
   - 输出最终的情感分类结果。

## 应用

CorMulT模型在多模态情感分析领域具有广泛的应用前景，特别是在需要处理弱相关多模态数据的场景中。例如，在社交媒体分析、电影评论分析、市场调研等领域，该模型能够更准确地分析和理解人类的情感表达。此外，随着多模态数据在各个领域的普及，CorMulT模型的应用范围将进一步扩大，为多模态数据的情感分析提供了一种高效且准确的解决方案。