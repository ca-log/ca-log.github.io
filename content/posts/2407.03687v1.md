---
author: 'TechScribe'
title: '探索STOC-TOT：一种革命性的多跳问答框架，提升大型语言模型的推理能力'
date: '2024-07-04'
Lastmod: '2024-07-10'
description: 'STOC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for Complex Reasoning in Multi-Hop Question Answering'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![STOC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for Complex Reasoning in Multi-Hop Question Answering](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03687v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03687v1)

## 摘要

本文介绍了一种名为STOC-TOT的新型多跳问答（MHQA）框架，该框架通过随机树状思维推理和约束解码技术，旨在提高大型语言模型在复杂推理场景下的性能。STOC-TOT通过将原始问题分解为多个子问题，形成不同的推理路径，并在每个推理步骤中为每条路径分配概率估计，从而构建一个树状推理结构。此外，该框架在回答阶段采用约束解码，确保模型生成基于证据的、准确的答案，减少幻觉现象。实验结果显示，STOC-TOT在多个MHQA数据集和大型语言模型上显著优于其他推理提示方法。<!--more-->

## 原理

STOC-TOT的核心在于其随机树状思维推理结构和约束解码技术。首先，模型被提示将复杂问题分解为多个子问题，每个子问题代表一个可能的推理路径。在推理过程中，模型不仅生成答案，还为每个推理路径提供概率估计，评估其合理性。最终，通过选择具有最高累积概率的路径来确定最佳答案。约束解码技术确保模型在生成答案时仅使用来自原始问题和证据列表的词汇，从而减少不基于证据的答案生成，提高答案的准确性和可靠性。

## 流程

STOC-TOT的工作流程包括以下几个关键步骤：
1. **子问题生成**：模型被提示生成与原始问题相关的多个子问题，每个子问题代表一个推理路径。
2. **概率估计**：在回答每个子问题时，模型同时评估该推理路径的合理性，并为其分配一个概率值。
3. **约束解码**：在生成最终答案时，模型仅使用来自原始问题和证据列表的词汇，确保答案的准确性和基于证据。
4. **选择最佳路径**：通过计算各推理路径的累积概率，选择概率最高的路径对应的答案作为最终答案。

例如，在处理一个两跳的MHQA问题时，STOC-TOT首先生成两个子问题，分别为每个子问题生成答案，并评估每个答案的合理性。最终，选择累积概率最高的答案作为最终答案。

## 应用

STOC-TOT框架在多跳问答任务中展现出显著的性能提升，尤其适用于需要复杂推理的开放领域问答系统。其应用前景广泛，包括但不限于教育辅助工具、智能客服、信息检索系统等，能够有效提升这些系统在处理复杂查询时的准确性和效率。