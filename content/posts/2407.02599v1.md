---
author: 'TechScribe'
title: 'Meta 3D Gen：革命性的文本到3D生成技术，开启高效内容创作新纪元'
date: '2024-07-02 18:37:52+00:00'
Lastmod: '2024-07-04 01:53:13.512228'
description: 'Meta 3D Gen'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Meta 3D Gen](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02599v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02599v1)

## 摘要

Meta 3D Gen（3DGen）是一项创新的高速文本到3D资产生成管道，能够在不到一分钟内创建具有高提示保真度和高质量3D形状及纹理的3D资产。该技术支持物理基础渲染（PBR），这对于现实世界应用中的3D资产重新照明至关重要。此外，3DGen还支持使用用户提供的额外文本输入对先前生成的（或艺术家创建的）3D形状进行生成性纹理重制。3DGen整合了Meta 3D AssetGen和Meta 3D TextureGen两个关键技术组件，通过结合它们的优势，3DGen在三维空间中同时以三种方式表示3D对象：视图空间、体积空间和UV（或纹理）空间。通过这种集成，3DGen在与单一阶段模型相比的评估中达到了68%的胜率，并且在复杂文本提示的提示保真度和视觉质量方面优于众多行业基线，同时显著加快了生成速度。<!--more-->

## 原理

Meta 3D Gen的工作原理基于两个主要阶段：AssetGen（阶段I）和TextureGen（阶段II）。在阶段I中，用户提供的文本提示被用于创建初始3D资产，使用Meta 3D AssetGen模型生成带有纹理和PBR材料映射的3D网格。阶段II则进一步优化这些资产的纹理和PBR映射，使用Meta 3D TextureGen模型。TextureGen通过训练网络生成对象的多个视图，然后将这些视图重新投影到相应的纹理图像上，最后通过另一个生成网络输出最终的纹理，从而提高纹理质量和分辨率，同时保持对初始提示的忠实度。这种两阶段的方法通过结合视图空间和UV空间的生成，实现了高质量的3D生成。

## 流程

Meta 3D Gen的工作流程从接收文本提示开始，执行文本到3D生成（阶段I），随后进行纹理细化（阶段II）。阶段II还可以用于使用用户提供的新文本提示对生成的或艺术家创建的网格进行纹理重制。具体流程包括：首先，根据提示运行网络生成初始网格和UV映射；然后，使用UV映射将新生成的视图图像重新投影到部分纹理上；接着，运行TextureGen网络以获得统一的UV纹理；最后，使用AssetGen网络获得最终的纹理，修复由于非人类UV映射导致的任何残留接缝。

## 应用

Meta 3D Gen的应用前景广泛，包括视频游戏设计、增强和虚拟现实应用、电影行业的特效制作等。由于其能够在短时间内生成高质量的3D内容，3DGen特别适合需要快速迭代和个性化内容创建的场景。此外，AI驱动的3D生成对于构建元宇宙中的无限大虚拟世界也至关重要。随着技术的进一步发展，3DGen有望在多个领域推动创新和效率的提升。