---
author: 'TechScribe'
title: 'LLaRA：将视觉语言模型转化为强大的机器人动作策略'
date: '2024-06-28'
Lastmod: '2024-07-05'
description: 'LLaRA: Supercharging Robot Learning Data for Vision-Language Policy'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![LLaRA: Supercharging Robot Learning Data for Vision-Language Policy](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.20095v1.pdf_0.jpg)](https://arxiv.org/abs/2406.20095v1)

## 摘要

本文提出了一种名为 LLaRA 的框架，将机器人动作策略公式化为对话，并在使用辅助数据进行训练时提供改进的响应。通过将行为克隆数据集转换为指令数据集，并利用视觉语言模型进行微调，该框架能够处理多样化的视觉运动控制挑战。实验结果表明，该框架在多个模拟和真实世界环境中表现出了最先进的性能。<!--more-->

## 原理

该框架的工作原理如下：
1. **问题定义**：将机器人操作任务定义为马尔可夫决策过程（MDP）中的行为克隆设置。
2. **指令调谐数据集**：从专家轨迹中生成视觉运动指令调谐数据集，将状态动作对转换为单轮对话。
3. **辅助数据集**：通过自我监督学习，从相同的专家演示中提取辅助指令调谐数据集，以增强机器人策略学习。
4. **模型训练**：使用预训练的视觉语言模型（VLM）在指令调谐数据集上进行微调，以学习机器人动作策略。
5. **推理过程**：在推理过程中，使用与训练相同的模板准备视觉语言模型（VLM）的提示。对于在 inBC 上训练的模型，每个对话轮次都包含当前的视觉观察、任务描述和文本中描述的先前动作。对于在 D-inBC 上训练的模型，该过程首先使用对象检测将任务描述中的任何额外图像转换为文本。然后，将任务描述（现在包括检测结果）与视觉观察和动作历史相结合，以完成指令。

## 流程

该框架的工作流程如下：
1. **数据准备**：
    - **构建 inBC 数据集**：将专家轨迹转换为单图像单轮对话设置，以模拟用户查询 VLM 并生成可直接转换为具体动作的响应的策略。
    - **构建 D-inBC 数据集**：利用对象检测将场景图像解析为对象列表及其相应的边界框，从而将参考图像描述为对象列表。
    - **构建辅助数据集**：使用模板生成辅助数据集，每个样本从 15 个模板中随机选择一个。
2. **训练**：使用预训练的 LLaVA-1.5-7B 模型，并微调所有参数，包括语言模型和投影层，但不包括视觉编码器。
3. **推理**：对于在 inBC 上训练的模型，在每个时间戳启动一个新的对话。对于在 D-inBC 上训练的模型，在查询 VLM 之前，首先对所有参考图像进行对象检测，并使用检测结果填充 D-inBC 的指令模板。

## 应用

该框架在机器人操作任务中具有广泛的应用前景，包括但不限于：
1. **工业自动化**：可以应用于工业生产线上的机器人操作，提高生产效率和质量。
2. **物流和仓储**：可以用于物流和仓储领域的机器人操作，如货物搬运和分拣。
3. **医疗保健**：可以应用于医疗保健领域的机器人操作，如手术机器人和康复机器人。
4. **家庭服务**：可以用于家庭服务领域的机器人操作，如清洁机器人和护理机器人。