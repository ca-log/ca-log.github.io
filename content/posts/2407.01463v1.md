---
author: 'TechScribe'
title: '探索多语言环境下的增强检索生成技术：构建高效的多语言RAG管道'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Retrieval-augmented generation in multilingual settings'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Retrieval-augmented generation in multilingual settings](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01463v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01463v1)

## 摘要

本文探讨了在多语言环境下增强检索生成（Retrieval-augmented Generation, RAG）的实现和评估。传统的RAG主要集中在英语环境中，而本文扩展了这一概念，考虑了用户查询和数据存储在13种不同语言中的情况。文章详细介绍了构建一个高效的多语言RAG（mRAG）管道所需的组件和调整，并强调了任务特定的提示工程在生成用户语言响应中的重要性。此外，文章还指出了当前评估指标在多语言设置中需要进行的调整，以适应命名实体拼写的变体。主要挑战包括非拉丁字母语言中的频繁代码切换、偶尔的流畅性错误、文档的错误解读或无关检索。文章最后发布了相应的代码库，以支持未来在零样本设置中对多语言RAG的研究。<!--more-->

## 原理

多语言RAG（mRAG）的工作原理涉及两个主要步骤：检索和生成。首先，系统使用多语言检索器从互联网或特定集合中检索与用户查询相关的上下文。这些检索器能够处理查询和文档在相同或不同语言中的情况，并且能够有效地从多语言数据存储中进行检索。其次，使用大型语言模型（LLM）基于用户查询和检索到的相关上下文生成响应。为了在所有语言中实现高性能，需要一个强大的多语言预训练和微调的LLM，并结合先进的提示技术，例如将提示翻译成用户语言并指示LLM在用户语言中生成响应。

## 流程

mRAG的工作流程如图1所示，包括以下步骤：
1. **检索**：用户查询首先通过一个可选的查询生成模型转换为搜索查询，然后使用多语言检索系统从Wikipedia或其他集合中检索相关上下文。
2. **生成**：基于用户查询和检索到的上下文，使用LLM生成响应。LLM遵循预训练和指令微调的范式，通过模板传递数据，模板包含用户查询、模型响应和系统提示的占位符。

## 应用

mRAG的应用前景广泛，特别是在需要跨语言信息访问和处理的领域。它可以用于多语言的开放域问答、事实核查等知识密集型任务，为非英语用户提供高质量的信息检索和生成服务。此外，mRAG的进一步研究和发展将有助于推动多语言环境下的人工智能应用，特别是在全球化和多语言社区中。