---
author: 'TechScribe'
title: 'AI代理评估的革新：优化准确性与成本的新框架'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'AI Agents That Matter'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![AI Agents That Matter](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01502v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01502v1)

## 摘要

本文探讨了AI代理（AI agents）的评估和基准测试实践中的多个关键问题。文章指出，当前的AI代理基准测试过于侧重于准确性而忽视了成本等其他重要指标，导致代理设计复杂且成本高昂。此外，模型开发者和下游开发者对基准测试的需求被混淆，许多基准测试缺乏适当的保留集，导致代理过度拟合基准。文章提出了一个原则性的框架来避免过度拟合，并强调了评估实践中的标准化和可重复性的重要性。最终，文章旨在推动开发出不仅在基准测试中准确，而且在现实世界中真正有用的AI代理。<!--more-->

## 原理

文章通过分析当前AI代理基准测试的不足，提出了几个关键的改进措施：
1. **成本控制评估**：强调在评估AI代理时必须考虑成本，避免仅追求高准确率而忽视成本的代理设计。
2. **联合优化准确性和成本**：通过可视化评估结果作为准确性和推理成本的帕累托曲线，开启了一个新的代理设计空间，即同时优化这两个指标。
3. **区分模型开发者和下游开发者的基准需求**：通过案例研究展示了模型评估基准在下游评估中的误导性，强调下游评估应考虑实际成本而非成本代理。
4. **避免基准测试中的捷径**：指出许多类型的过度拟合是可能的，并提出了基于所需通用性水平的不同类型的保留样本。
5. **评估的标准化和可重复性**：发现WebArena和HumanEval评估中普遍存在的可重复性问题，这些问题夸大了准确性估计，导致对代理能力的过度乐观。

## 流程

文章通过以下步骤详细说明了其工作流程：
1. **成本控制评估**：设计并实现了成本控制的优化方法，展示了在保持准确性的同时大幅降低成本的潜力。
2. **联合优化准确性和成本**：修改了DSPy框架以进行联合优化，降低了HotPotQA上的成本同时保持了准确性。
3. **区分基准需求**：通过NovelQA案例研究，展示了模型评估基准在下游评估中的误导性。
4. **避免基准测试中的捷径**：提出了一个原则性的框架来避免过度拟合，并通过WebArena基准的案例研究进行了说明。
5. **评估的标准化和可重复性**：提出了改进评估标准化的步骤，并希望这些步骤能促进AI代理评估的严谨性。

## 应用

文章提出的改进措施有望广泛应用于AI代理的开发和评估中，特别是在需要考虑成本效益和实际应用场景的领域。通过提高评估的准确性和效率，这些方法可以帮助开发出更符合现实世界需求的AI代理，从而推动AI技术的实际应用和商业化。