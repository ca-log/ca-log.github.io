# 探索音译在低资源非拉丁文字语言中的应用：提升大型语言模型的上下文学习能力

[![Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02320v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02320v1)

## 摘要

本文探讨了在非拉丁文字的低资源语言中，通过上下文学习（In-Context Learning, ICL）利用音译（Transliteration）提高解码器专用大型语言模型（LLMs）性能的有效性。论文针对低资源语言，特别是使用非拉丁文字的语言，提出了一种通过音译增强LLMs性能的方法。研究通过三种提示模板（使用原始文字、拉丁文字或两者结合），评估了音译在不同任务和模型大小上的效果，特别是在文本分类和序列标注任务上。研究发现，音译在序列标注任务中显著提升了模型性能，但在其他任务上的效果不一。

## 原理

论文的核心在于利用音译将非拉丁文字转换为拉丁文字，以此增强LLMs在低资源语言中的理解和处理能力。音译通过增加词汇重叠，帮助模型更好地进行跨语言知识转移。论文提出的三种提示模板（SCRIPT{Orig}、SCRIPT{Latn}、SCRIPT{Combined}）允许模型在处理非拉丁文字时，可以选择使用原始文字、拉丁文字或两者结合的方式，从而提高模型在特定任务上的表现。

## 流程

论文的工作流程包括以下几个步骤：
1. **音译转换**：使用Uroman工具将非拉丁文字转换为拉丁文字。
2. **提示模板设计**：设计三种提示模板，分别使用原始文字、拉丁文字和两者结合。
3. **模型应用**：将这些提示模板应用于多个LLMs，包括LLaMA、Mistral和BLOOM等，进行文本分类和序列标注等任务。
4. **性能评估**：通过命名实体识别（NER）、SIB200和Taxi1500等任务，评估不同提示模板在不同模型上的性能。

## 应用

论文的研究成果对于处理非拉丁文字的低资源语言具有重要意义。音译方法可以广泛应用于需要处理多种语言的领域，如多语言信息检索、跨语言自然语言处理等。随着更多低资源语言数据的积累和模型能力的提升，音译方法有望进一步提高LLMs在多语言环境下的性能。

