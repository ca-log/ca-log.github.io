---
author: 'TechScribe'
title: '转写能否提升低资源非拉丁文字语言的 LLM 性能？'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02320v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02320v1)

## 摘要

这篇论文探讨了转写在提升仅解码器大型语言模型（LLM）对低资源非拉丁文字语言的上下文学习（ICL）性能方面的有效性。作者提出了三种提示模板，并在不同任务和模型上进行了实验。结果表明，转写对序列标记任务特别有益，但对文本分类任务的效果不一致。此外，转写的效果还与模型类型和规模有关。<!--more-->

## 原理

论文的关键内容是研究转写在提升仅解码器 LLM 性能方面的工作原理。具体来说，作者提出了三种提示模板，分别使用原始脚本、拉丁脚本和两者结合的方式表示目标语言文本。通过实验，作者发现转写对序列标记任务有显著的提升效果，这是因为 NER 数据中存在许多跨语言共享的（专有）名词，转写能够帮助模型更好地利用这些共享词汇进行推理。此外，模型的性能还受到不同脚本的影响，对于在预训练数据中出现过的脚本，转写的效果更为明显。

## 流程

论文的工作流程如下：
1. 选择模型：作者实验了六种模型，包括 LLaMA2-7B、Mistral-7BInstruct 和 BLOOM 模型的不同变体。
2. 提出提示方法：作者提出了三种提示方法，分别是 SCRIPT{Orig}、SCRIPT{Latn}和 SCRIPT{Combined}。
3. 进行实验：作者在命名实体识别（NER）、SIB200 和 Taxi1500 等任务上进行了实验，并比较了不同提示方法的效果。
4. 分析结果：作者对实验结果进行了分析，发现转写对序列标记任务特别有益，但对文本分类任务的效果不一致。此外，转写的效果还与模型类型和规模有关。

## 应用

论文的关键内容在自然语言处理领域具有广阔的应用前景。转写可以帮助模型更好地处理低资源非拉丁文字语言，提高模型的泛化能力和性能。此外，转写还可以应用于跨语言信息检索、机器翻译等领域，为解决语言障碍提供新的思路和方法。