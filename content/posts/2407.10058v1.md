---
author: 'TechScribe'
title: '保护隐私的新前沿：大型语言模型的遗忘技术'
date: '2024-07-14'
Lastmod: '2024-07-16'
description: 'Learning to Refuse: Towards Mitigating Privacy Risks in LLMs'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Learning to Refuse: Towards Mitigating Privacy Risks in LLMs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10058v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10058v1)

## 摘要

本文由刘振华、朱彤、谭传元和陈文亮共同撰写，针对大型语言模型（LLMs）在处理和生成自然语言时可能无意中记忆私人信息，从而引发重大隐私风险的问题进行了研究。文章提出了一种无需完全重新训练即可保护特定个人隐私数据的方法。研究团队创建了RETURN数据集，包含2,492名来自维基百科的个人及其相关问答对，用于评估机器遗忘（MU）方法在现实场景中保护个人数据的效果。此外，文章还介绍了名称感知遗忘框架（NAUF），该框架使模型能够学习哪些个人的信息应受保护，同时不影响其回答与无关个人相关的问题的能力。实验结果表明，NAUF在遗忘评分上达到了最先进的平均水平，有效地保护了目标个人的隐私数据，同时保持了模型的通用能力。<!--more-->

## 原理

NAUF框架的核心在于两个关键组件：名称感知拒绝回答和对比数据增强。名称感知拒绝回答组件旨在帮助模型识别并保护特定个人的信息，通过在遗忘集中使用名称感知的拒绝回答模板，如“我恐怕不能帮助关于[NAME]的询问”，来训练模型。对比数据增强组件则通过扩充遗忘集和保留集的数据分布，增强方法的泛化能力。具体来说，对于遗忘集中的每个个体，随机抽取其他个体的问题并替换为目标个体的名称，然后使用名称感知的拒绝回答进行标记；对于保留集中的个体，同样进行随机抽取和名称替换，但使用原始模型的预测作为标记答案。

## 流程

1. 数据收集与准备：从维基百科收集大量名人的背景信息，并使用GPT-4生成每个个体的20个问答对。
2. 模型识别：通过模型回答RETURN数据集中的问题，并计算模型预测答案与标准答案的平均准确度，以识别模型深度记忆的个体。
3. 数据集划分：将深度记忆的个体分为遗忘集和保留集，目标是在保护遗忘集个体隐私的同时，保持保留集个体的正常回答能力。
4. 模型训练与评估：使用名称感知拒绝回答和对比数据增强方法训练模型，并通过遗忘评分、保留评分和下游任务准确度等指标评估模型的性能。

## 应用

NAUF框架的应用前景广泛，特别是在需要保护个人隐私的场景中，如社交媒体、在线客服和个性化推荐系统等。通过有效保护个人数据，该框架有助于遵守数据保护法规，如欧盟的通用数据保护条例（GDPR），并增强用户对技术的信任。此外，随着隐私保护意识的提升，NAUF框架在未来的智能系统中将扮演重要角色，推动隐私保护技术的进一步发展。