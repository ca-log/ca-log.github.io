---
author: 'TechScribe'
title: '探索未来：Mobile-Bench——引领LLM移动代理评估的新基准'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00993v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00993v1)

## 摘要

本文介绍了一种名为Mobile-Bench的新型基准测试工具，用于评估基于大型语言模型（LLM）的移动代理的能力。随着LLM的显著进步，基于LLM的代理已成为人机交互领域的研究热点。然而，目前缺乏针对这些移动代理的基准测试工具。Mobile-Bench通过整合103个收集的API来提高任务完成的效率，并通过结合真实用户查询和LLM增强数据来收集评估数据。该基准测试工具包含832个数据条目，其中超过200个任务专门设计用于评估多应用程序协作场景。此外，Mobile-Bench引入了一种名为CheckPoint的新评估指标，用于评估LLM移动代理在规划和推理步骤中是否达到关键点。<!--more-->

## 原理

Mobile-Bench的核心工作原理是通过模拟真实用户与移动设备的交互，评估LLM代理在执行任务时的效率和准确性。该基准测试工具通过以下几个关键步骤实现其功能：
1. **API集成**：通过集成103个API，Mobile-Bench能够加速任务完成过程，因为单个API调用可以替代多个UI操作步骤。
2. **数据收集**：结合真实用户查询和LLM生成的增强数据，Mobile-Bench构建了一个包含832个数据条目的评估数据集。
3. **任务分类**：数据集中的任务被分为三个不同的复杂度级别：SAST（单应用单任务）、SAMT（单应用多任务）和MAMT（多应用多任务）。
4. **评估指标**：引入CheckPoint指标，用于评估代理在执行任务时是否达到了关键的规划和推理步骤。

## 流程

Mobile-Bench的工作流程如下：
1. **任务启动**：用户通过自然语言指令启动任务，例如“设置一个早上7:30的闹钟”。
2. **API调用或UI操作**：LLM代理根据任务需求选择合适的API调用或UI操作来执行任务。例如，通过API调用可以直接设置闹钟，而通过UI操作则需要多个步骤（如打开时钟应用、选择新建闹钟、设置时间等）。
3. **任务执行**：代理执行选定的API调用或UI操作，并记录执行历史。
4. **任务评估**：通过CheckPoint指标评估任务执行的准确性和效率。例如，检查是否正确设置了闹钟时间。
5. **结果反馈**：根据评估结果，系统反馈任务是否成功完成。

## 应用

Mobile-Bench的应用前景广泛，主要体现在以下几个方面：
1. **人机交互研究**：为研究人员提供了一个标准化的测试平台，用于评估和改进基于LLM的移动代理的性能。
2. **智能助手开发**：帮助开发者设计和优化智能助手，使其能够更高效地执行复杂任务。
3. **用户体验优化**：通过模拟真实用户交互，帮助开发者理解用户需求，从而优化应用程序的用户体验。
4. **自动化测试**：为移动应用程序的自动化测试提供了一个强大的工具，特别是在多应用协作场景中。