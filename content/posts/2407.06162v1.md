---
author: 'TechScribe'
title: '融合CNNs和ViTs的人类动作识别新模型'
date: '2024-06-02'
Lastmod: '2024-07-10'
description: 'RNNs, CNNs and Transformers in Human Action Recognition: A Survey and A Hybrid Model'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![RNNs, CNNs and Transformers in Human Action Recognition: A Survey and A Hybrid Model](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06162v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06162v1)

## 摘要

本文是一篇关于人类动作识别（HAR）的综述，主要介绍了卷积神经网络（CNNs）、循环神经网络（RNNs）和视觉转换器（ViTs）在该领域的应用和发展。文章还提出了一种新的混合模型，将CNNs和ViTs的优势相结合，以提高HAR系统的性能。<!--more-->

## 原理

本文的关键内容是提出了一种新的混合模型，将CNNs和ViTs的优势相结合，以提高HAR系统的性能。该模型的工作原理如下：
1. **空间组件（TimeDistributed CNN）**：使用CNN骨干网络（如Mobilenet）处理每个视频帧，输出空间特征向量。
2. **时间组件（ViT）**：将空间特征向量输入到ViT模型中，通过多头自注意力机制和前馈神经网络对序列进行处理，最终输出动作分类结果。

## 流程

该模型的工作流程如下：
1. 输入视频序列，将其分解为多个视频帧。
2. 使用CNN骨干网络对每个视频帧进行处理，输出空间特征向量。
3. 将空间特征向量输入到ViT模型中，通过多头自注意力机制和前馈神经网络对序列进行处理。
4. 最终输出动作分类结果。

## 应用

该模型的应用前景非常广泛，可以应用于医疗、教育、娱乐、视觉监控、视频检索等领域，帮助人们更好地理解和分析人类动作。