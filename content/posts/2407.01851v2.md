---
author: 'TechScribe'
title: 'Meerkat：音频-视觉大语言模型的新突破'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Meerkat: Audio-Visual Large Language Model for Grounding in Space and Time'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Meerkat: Audio-Visual Large Language Model for Grounding in Space and Time](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01851v2.pdf_0.jpg)](https://arxiv.org/abs/2407.01851v2)

## 摘要

本文介绍了一种名为 Meerkat 的音频-视觉大语言模型，它可以在图像和音频中进行时空定位。该模型具有两个关键模块，即模态对齐模块和交叉注意力模块，能够学习更好的联合音频-视觉表示，从而增强下游任务。此外，作者还引入了 MeerkatBench，它统一了五个不同的音频-视觉任务，并创建了一个新的大型指令调整数据集 AVFIT，以支持这些任务的训练。实验结果表明，该模型在所有这些下游任务上都取得了最先进的性能，相对改进高达 37.12%。<!--more-->

## 原理

Meerkat 是一种基于最优传输和交叉注意力机制的音频-视觉大语言模型，其工作原理如下：
1. **多模态特征提取**：使用预训练的 CLIP-ViT-B/16 编码器提取图像特征，使用 CLAP 音频变压器骨干提取音频特征，使用开源的 Llama 2-Chat（7B）作为大型语言模型骨干。
2. **音频-视觉特征对齐**：通过模态对齐模块（AVOpT）和音频-视觉一致性强化模块（AVACE）实现音频和视觉模态的对齐。AVOpT 基于最优传输算法，通过最小化补丁级 Wasserstein 距离来学习图像和音频补丁之间的跨模态对齐。AVACE 通过限制交叉模态注意力图在感兴趣对象周围，最小化与背景的关联，来最大化区域级对齐。
3. **训练目标**：使用交叉熵损失、弱 AV 对齐损失和注意力一致性损失的加权线性组合作为训练目标。
4. **数值表示**：使用数值表示框位置和时间片段，将其嵌入到自然语言序列中。

## 流程

Meerkat 的工作流程如下：
1. 输入图像和音频对，以及文本指令。
2. 使用多模态特征提取模块提取图像和音频特征。
3. 使用音频-视觉特征对齐模块进行音频和视觉模态的对齐。
4. 使用训练好的大型语言模型进行推理和预测。
5. 输出预测结果，如音频-视觉事实检查的真假判断、图像引导的音频时间定位的时间区间等。

## 应用

Meerkat 可以应用于以下领域：
1. **多媒体内容分析**：通过对音频和视频的理解，实现对多媒体内容的自动分析和标注。
2. **多模态虚拟助手**：结合音频和视觉信息，提供更加自然和智能的交互体验。
3. **教育和培训**：利用音频和视频的优势，提供更加生动和有效的教育和培训内容。
4. **智能监控和安防**：通过对音频和视频的实时分析，实现对异常事件的及时发现和预警。