---
author: 'TechScribe'
title: 'LayTextLLM：革新文档理解的大型语言模型'
date: '2024-07-02 06:29:05+00:00'
Lastmod: '2024-07-04 01:17:40.706409'
description: 'A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01976v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01976v1)

## 摘要

本文介绍了一种名为LayTextLLM的新型大型语言模型（LLM），用于文档理解任务。该模型通过将每个边界框投影为一个单一的嵌入，并与文本交错，有效地避免了长序列问题，同时充分利用了LLM的自回归特性。LayTextLLM不仅简化了布局和文本数据的交互，还在关键信息提取（KIE）和视觉问答（VQA）任务中显示出增强的性能。综合基准评估显示，与先前的最先进文档理解MLLMs相比，LayTextLLM在KIE任务上提高了27.0%，在VQA任务上提高了24.1%，在基于OCR的LLMs上提高了15.5%。<!--more-->

## 原理

LayTextLLM的核心创新在于其空间布局投影器（SLP），它将每个边界框的四个坐标转换为一个单一的嵌入。这种转换使得模型能够同时处理空间布局和文本输入。此外，LayTextLLM采用了部分低秩适应（P-LoRA）模块，这是一种最小侵入性方法，用于在保留LLM固有知识的同时引入额外模态。通过这些技术，LayTextLLM能够有效地将布局信息与文本信息整合，充分利用LLM的自回归特性进行增强的文档理解。

## 流程

LayTextLLM的工作流程包括两个主要阶段：预训练和监督微调。在预训练阶段，模型通过布局感知下一词预测（LNTP）任务进行训练，这是一个完全自监督的任务，旨在增强布局和文本模态之间的对齐。在监督微调阶段，模型通过随机OCR监督微调（SSFT）任务进行训练，该任务随机打乱OCR提取文本的顺序，以增强模型对输入令牌顺序变化的鲁棒性。例如，在处理收据布局时，模型能够通过整合空间布局和文本数据，减少对输入序列顺序的依赖，从而更准确地识别相关信息。

## 应用

LayTextLLM在文档理解领域具有广泛的应用前景，特别是在需要精确提取和理解文档中关键信息的场景，如金融文档分析、法律文档处理和医疗记录解读等。此外，LayTextLLM的技术也可以扩展到其他需要结合视觉和文本信息的领域，如多模态问答系统和交互式文档分析工具。