---
author: 'TechScribe'
title: '革命性进展：利用Grounding DINO和SAM实现自动化图像数据标注'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19057v2.pdf_0.jpg)](https://arxiv.org/abs/2406.19057v2)

## 摘要

本文探讨了在零样本对象检测和图像分割领域中，Grounding DINO和Segment Anything Model（SAM）的结合应用。特别是在医学图像分割等专业领域，由于目标对象（如器官、组织和肿瘤）可能不在现有类别名称中，传统的基于类别名称的检测方法面临挑战。论文提出利用Grounding DINO的指代表达理解（REC）能力，通过语言描述来检测任意目标，并将其作为SAM的输入，以实现自动化的图像数据标注。研究通过在多个公开数据集上的实验，揭示了错误预测的模式，并提出了一种通过过滤预测边界框相对面积来减少错误的方法，显著提高了分割质量和标注效率。<!--more-->

## 原理

Segment Anything Model（SAM）是一个先进的生成神经网络，预训练于大量标记的图像分割数据上。其架构包括三个关键组件：图像编码器（采用Vision Transformer）、提示编码器（从文本、边界框或点等额外输入中提取嵌入）和掩码解码器（利用图像和提示嵌入生成输出掩码）。Grounding DINO通过结合多尺度图像和文本特征提取以及跨模态解码器，扩展了DINO模型，实现了零样本对象检测。两者结合使用时，Grounding DINO通过文本输入预测目标对象的边界框，SAM则利用这些边界框生成精确的分割掩码。

## 流程

1. 使用Grounding DINO通过文本描述预测目标对象的边界框。
2. 将这些边界框作为提示输入到SAM中。
3. SAM根据这些提示生成图像的分割掩码。
4. 通过分析预测边界框的相对面积，过滤掉可能的错误预测。
5. 最终得到高质量的图像分割结果和标注数据。

## 应用

该研究提出的方法在医学图像分割、植物病害检测、塑料检测等多个领域具有广泛的应用前景。通过自动化图像数据标注，可以大幅减少人工标注的时间和成本，加速机器学习模型的开发和部署，特别是在需要大量高质量标注数据的场景中。