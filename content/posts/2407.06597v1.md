---
author: 'TechScribe'
title: '探索视频时刻检索的新前沿：基于不精确查询的排序技术'
date: '2024-07-09'
Lastmod: '2024-07-10'
description: 'TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![TVR-Ranking: A Dataset for Ranked Video Moment Retrieval with Imprecise Queries](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06597v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06597v1)

## 摘要

本文提出了一项名为“Ranked Video Moment Retrieval (RVMR)”的新任务，旨在通过自然语言查询从视频集合中定位并排序匹配的时刻。尽管计算机视觉、自然语言处理和信息检索社区已经提出了一些相关任务，但RVMR任务最能反映实际的时刻搜索场景。为了促进RVMR的研究，本文基于TVR数据集的原始视频和现有时刻注释，开发了TVR-Ranking数据集。本文的主要贡献是手动注释了94,442个查询-时刻对的相关性级别，并开发了NDCG@K, IoU ≥ µ评估指标来评估这一新任务。实验表明，新的RVMR任务为现有模型带来了新的挑战，并相信这一新数据集有助于多模态搜索的研究。<!--more-->

## 原理

RVMR任务的核心在于从视频集合中检索与自然语言查询相关的时刻，并对其进行排序。这一任务的关键在于理解查询的语义并将其与视频中的时刻进行匹配。为了实现这一目标，本文采用了以下方法：
1. **数据集构建**：基于TVR数据集，通过替换原始时刻描述中的角色名称，生成不精确的查询。这一过程通过精心设计的提示与ChatGPT进行交互，并进行了质量控制。
2. **相关性注释**：通过23名注释者对3,281个查询的候选时刻进行手动注释，每个查询注释20或40个候选时刻，涵盖从无关（0）到完美匹配（4）的五个相关性级别。
3. **评估指标**：提出了NDCG@K, IoU ≥ µ评估指标，该指标结合了NDCG（用于排序任务）和IoU（用于时刻检索），以处理检索时刻与真实时刻之间的部分匹配问题。
4. **模型适应**：将三个最初为VCMR任务设计的基线模型（XML、CONQUER和ReLoCLNet）适应到RVMR任务，并通过实验评估它们在TVR-Ranking数据集上的性能。

## 流程

1. **查询生成**：从TVR数据集的原始时刻描述中生成不精确的查询，通过ChatGPT替换角色名称，并进行语义一致性和命名实体识别的质量检查。
2. **候选时刻选择**：对于每个查询，基于查询与时刻描述的相似性，选择前K个候选时刻进行注释。
3. **手动注释**：两名注释者独立对每个查询-时刻对进行相关性评分，如果评分差异在1或0以内，则取平均值作为最终评分；否则，由另外两名注释者进行评分，并采用修剪平均法确定最终评分。
4. **评估模型**：使用NDCG@K, IoU ≥ µ指标评估模型性能，其中K表示排名前K的时刻，µ表示IoU的阈值。
5. **模型训练与测试**：在TVR-Ranking数据集上训练和测试适应后的基线模型，评估其在RVMR任务上的表现。

## 应用

RVMR任务的应用前景广泛，包括但不限于：
- **视频搜索**：用户可以通过自然语言查询快速找到视频中的特定时刻。
- **内容推荐**：系统可以根据用户的查询推荐相关的视频片段。
- **教育资源**：在教育视频中，学生可以通过查询找到特定的教学内容。
- **视频编辑**：视频编辑者可以利用RVMR技术快速定位和剪辑视频片段。
随着技术的进步，RVMR有望在多媒体内容检索和处理领域发挥更大的作用。