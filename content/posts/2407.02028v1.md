---
author: 'TechScribe'
title: '探索大型语言模型在情境学习中的挑战与机遇：开放与封闭问题的深度解析'
date: '2024-07-02 07:52:30+00:00'
Lastmod: '2024-07-04 01:17:37.855124'
description: 'Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02028v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02028v1)

## 摘要

本文探讨了大型语言模型（LLMs）在情境学习（in-context learning）中对开放和封闭问题的表现，特别是在问题的新颖性和难度方面的影响。研究通过创建一个包含科学难题的新基准，展示了情境相关性对模型性能的影响，并发现情境与主题的匹配度并不总是提高性能，尤其是在开放问题和高难度或新颖问题中。这一发现揭示了LLMs处理不同类型问题的基本差异，并提出了如何为LLMs选择最佳情境的新问题，特别是在检索增强生成（RAG）系统中。研究结果表明，情境选择可能高度依赖于应用，并受问题格式、难度级别和信息新颖性等因素的影响。<!--more-->

## 原理

情境学习是一种允许LLMs通过有限的示例在不更新模型参数的情况下解决给定问题的方法。在情境学习中，问题-解决方案对被包含在输入提示中，使LLMs能够检测这些示例的逻辑和模式，从而提高输出准确性。这种技术显著降低了提高LLMs性能的复杂性，相比于微调等传统方法。本文通过实验展示了情境相关性对模型性能的影响，特别是在开放问题和高难度或新颖问题中的意外行为，即更相关的情境并不总是提高性能。

## 流程

研究团队创建了一个包含160个独特问题-响应对的基准数据集，涵盖物理学和计算机科学领域，难度各异。每个问题伴随四种不同类型的情境（包括无情境作为对照组），并由GPT-4生成答案。评估过程中，每个问题由六名独立评分者使用预定义的评分表进行评估，确保评估的准确性和可靠性。通过这种多评分者的方法，研究团队能够减少个体偏见，获得更全面和可靠的评估结果。

## 应用

本文的研究结果对检索增强生成（RAG）系统的性能改进具有重要意义。鉴于情境相关性与模型性能在开放和封闭问题中的不同关系，未来的研究应考虑问题类型的特性来优化情境选择策略。此外，研究还提出了对情境学习评估的新方法，特别是在涉及开放式和情境敏感查询的复杂性方面。这些发现为LLMs在更广泛的应用场景中的优化和评估提供了新的视角和方法。