---
author: 'TechScribe'
title: '探索大型语言模型在情境学习中的挑战与机遇：开放与封闭问题的不同影响'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02028v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02028v1)

## 摘要

本文探讨了大型语言模型（LLMs）在情境学习（in-context learning）中对开放和封闭问题的表现，特别是在问题的新颖性和难度方面的影响。研究通过创建一个包含科学难题的新基准数据集，发现情境的相关性并不总是有助于提高模型性能，尤其是在开放问题和高难度或新颖问题中。这一发现揭示了LLMs处理不同类型问题的方式的差异，并强调了在不同类型问题中评估情境学习的必要性。此外，研究还提出了在检索增强生成（RAG）系统中如何最优选择情境的新问题。<!--more-->

## 原理

情境学习是一种允许LLMs通过有限的示例学习解决新问题的方法，无需更新模型参数。在情境学习中，问题-解决方案对被包含在输入提示中，使LLMs能够检测这些示例的逻辑和模式，从而提高输出准确性。这种技术显著降低了提高LLMs性能的复杂性，特别是在与微调等传统方法相比时。研究特别关注了情境对模型性能的影响，发现情境的相关性在处理不同类型的问题时表现不同，尤其是在开放问题和高难度问题中，情境的相关性甚至可能降低模型性能。

## 流程

研究首先创建了一个包含160个独特问题-响应对的基准数据集，涵盖物理学和计算机科学领域，每个问题伴随四种不同相关性的情境（包括无情境作为对照组）。然后，使用GPT-4模型生成每个问题-情境对的响应，并由六名独立的评分者使用预定义的评分表进行评估。评分标准包括完整性和相关性、逻辑和推理以及真实性（缺乏幻觉）。研究结果显示，情境的相关性在不同类型的问题中表现不同，尤其是在开放问题和高难度问题中，情境的相关性甚至可能降低模型性能。

## 应用

这项研究的结果对于改进检索增强生成（RAG）系统的性能具有重要意义。当前的RAG研究主要集中在模型推理期间提供情境，但研究显示情境的相关性与模型性能之间的关系因问题类型（开放或封闭）而异。因此，选择情境的策略应根据问题的属性进行调整，这可能包括问题的格式、感知难度级别以及信息的新颖性或流行度。未来的研究可以探索如何根据这些因素优化情境选择，以提高LLMs在处理复杂和开放问题时的性能。