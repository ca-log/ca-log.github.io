---
author: 'TechScribe'
title: '探索大型语言模型在情境学习中的挑战与机遇'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02028v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02028v1)

## 摘要

本文探讨了大型语言模型（LLMs）在情境学习（in-context learning）中对开放和封闭问题的表现，特别是情境相关性对模型性能的影响。研究通过创建一个包含物理学和计算机科学领域难题的新基准数据集，发现情境与问题的相关性并不总是提高模型性能，尤其是在处理开放问题和高度困难或新颖的问题时。这一发现揭示了LLMs处理不同类型问题的基本差异，并提出了如何为大型语言模型最优选择情境的新问题，特别是在检索增强生成（RAG）系统的背景下。<!--more-->

## 原理

情境学习是一种允许LLMs通过有限的示例在推理时学习新知识的技术，无需更新模型参数。在这种学习模式中，模型通过输入中的问题-解决方案对来识别逻辑和模式，从而提高输出准确性。本文通过实验展示了GPT-4在不同情境相关性下的表现，特别是在开放和封闭问题上的差异，表明模型对情境的利用方式因问题类型而异。

## 流程

研究团队创建了一个包含160个独特问题-响应对的基准数据集，每个问题伴随四种不同相关性的情境（包括无情境作为对照组），并由GPT-4生成答案。每个问题由六名独立的评分者使用预定义的评分表进行评估，以确保评估的准确性和可靠性。实验结果显示，GPT-4在处理开放问题时，情境的相关性与模型性能呈负相关，而在封闭问题上则呈正相关。

## 应用

本文的研究结果对检索增强生成（RAG）系统的优化具有重要意义，特别是在如何选择情境以提高LLMs在开放问题上的推理性能方面。未来的研究可以探索更多情境选择策略，以适应不同类型的应用需求，并进一步提高LLMs的性能和可靠性。