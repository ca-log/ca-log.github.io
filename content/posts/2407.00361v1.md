---
author: 'TechScribe'
title: '"RICHES：革命性的检索与生成集成方法，开启AI新纪元"'
date: '2024-06-29'
Lastmod: '2024-07-05'
description: 'From RAG to RICHES: Retrieval Interlaced with Sequence Generation'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![From RAG to RICHES: Retrieval Interlaced with Sequence Generation](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.00361v1.pdf_0.jpg)](https://arxiv.org/abs/2407.00361v1)

## 摘要

本文介绍了RICHES，一种新颖的方法，它将检索与序列生成任务交织在一起。RICHES提供了一种替代传统RAG系统的方案，通过直接解码文档内容并受限于语料库，消除了对独立检索器和生成器的需求。这种方法通过单一的LLM解码过程，实现了检索与生成的统一，使得系统能够通过简单的提示适应多样的新任务。RICHES在开放域问答（ODQA）任务中展示了强大的性能，包括带有归属和多跳问答的能力。<!--more-->

## 原理

RICHES的核心在于将检索和生成任务无缝集成在一个单一的LLM解码过程中。它通过直接解码文档内容或相关的自然语言检索键来检索文档，这些检索键指向文档本身。这种方法的关键先进性在于，它允许LLM在生成文本的同时进行检索，从而实现了一种动态的、上下文感知的生成过程。此外，RICHES支持多跳检索，即模型可以在生成过程中多次检索信息，每次检索都基于前一次的结果，从而实现更深层次的推理和信息整合。

## 流程

RICHES的工作流程包括以下几个步骤：
1. **输入问题**：用户输入一个问题。
2. **初始检索**：LLM开始解码过程，并根据问题生成初始的检索键。
3. **检索文档**：LLM使用生成的检索键从语料库中检索相关文档。
4. **生成答案**：LLM根据检索到的文档内容生成答案，并在必要时进行多跳检索以获取更多信息。
5. **输出答案**：LLM输出最终的答案，并提供归属证据。

例如，在处理一个多跳问题时，RICHES首先生成一个关于需要检索内容的“思考”，然后生成一个基于语料库的支持性陈述，并与原始支持文本相关联。这个过程在一个单一的解码过程中完成，如图1所示。

## 应用

RICHES的应用前景广泛，特别适用于需要复杂推理和多源信息整合的任务，如开放域问答、知识密集型NLP任务等。由于其能够通过简单的提示适应新任务，RICHES在未来的AI系统中可能成为一种灵活且强大的工具，尤其是在需要快速响应和适应新信息的环境中。