---
author: 'TechScribe'
title: 'fairBERTs：通过语义和公平意识扰动擦除敏感信息，构建更公平的预训练语言模型'
date: '2024-07-11'
Lastmod: '2024-07-12'
description: 'fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.08189v1.pdf_0.jpg)](https://arxiv.org/abs/2407.08189v1)

## 摘要

本文介绍了一种名为fairBERTs的创新框架，旨在解决预训练语言模型（PLMs）中存在的性别和种族歧视等刻板偏见问题。通过使用生成对抗网络（GANs）生成语义和公平意识扰动，fairBERTs能够擦除模型中的敏感信息，从而减少不公平性。研究通过在两个真实世界任务上的广泛实验，证明了fairBERTs在保持模型效用的同时，显著提高了模型的公平性。此外，研究还验证了fairBERTs中生成的扰动可以转移到其他BERT类模型中，以实现公平性改进。<!--more-->

## 原理

fairBERTs框架的核心在于利用生成对抗网络（GANs）生成语义和公平意识扰动，这些扰动被叠加到BERT系列模型的隐藏表示中，以擦除编码的敏感信息。具体来说，框架包括三个主要组件：BERT系列模型（BPLMs）、对抗去偏组件和任务特定分类器。生成器负责生成扰动，而判别器则尝试从扰动后的隐藏表示中区分出敏感属性。通过这种对抗训练，模型能够在不牺牲分类效用的情况下，减少对敏感属性的依赖。

## 流程

fairBERTs的工作流程包括以下步骤：首先，使用BPLMs提取文本输入的序列表示；然后，生成器基于这些序列表示生成语义和公平意识扰动；接着，将这些扰动叠加到原始的隐藏表示中，形成公平的分类表示；最后，使用任务特定分类器基于这些公平表示进行预测。整个过程通过对抗训练进行优化，确保生成的扰动既能有效擦除敏感信息，又不破坏原始表示的分类效用。

## 应用

fairBERTs框架的应用前景广泛，特别是在需要高度公平性的领域，如法律判决、招聘筛选和社交媒体监控等。通过减少模型中的偏见，fairBERTs有助于构建更加公正和可信的人工智能系统。此外，该框架的可转移性意味着它可以被应用于各种BERT类模型，进一步扩大了其应用范围。