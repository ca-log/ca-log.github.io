---
author: 'TechScribe'
title: '"保护企业级LLM应用：一种基于角色安全和北约级别的创新架构"'
date: '2024-07-09'
Lastmod: '2024-07-10'
description: 'A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.06718v1.pdf_0.jpg)](https://arxiv.org/abs/2407.06718v1)

## 摘要

本文提出了一种基于角色安全和企业大型语言模型应用的简单架构，该架构利用基于角色的安全和北约安全级别，结合检索增强生成（RAG）和专家混合模型（MoE）。该研究旨在解决当前大型语言模型（LLMs）在处理安全和信息访问方面的局限性。通过使用用户角色和安全级别，过滤RAG中的文档和MoE中的专家，从而防止信息泄露。<!--more-->

## 原理

该架构的核心在于通过角色和安全级别来控制对LLM应用的访问。在RAG中，用户的角色决定了其可以访问的文档；在MoE中，用户的角色决定了其可以咨询的专家。这种过滤机制确保了只有符合用户角色和安全级别的文档和专家被激活，从而有效防止了信息泄露。此外，该架构支持仅使用RAG、仅使用MoE或两者结合使用，提供了灵活的应用场景。

## 流程

1. **用户角色和安全级别映射**：首先，将用户映射到一个或多个角色，并将这些映射存储在目录服务或ERP数据库中。
2. **文档和专家过滤**：在RAG中，根据用户的角色和安全级别过滤文档；在MoE中，根据用户的角色和安全级别过滤专家。
3. **推理过程**：使用RAG时，系统仅返回用户角色有权访问的文档；使用MoE时，系统仅激活用户角色有权访问的专家。
4. **结合RAG和MoE**：在某些情况下，可以同时使用RAG和MoE，以提供更全面的解决方案。

## 应用

该架构适用于需要高度安全控制的LLM应用，特别是在军事、政府和企业环境中。通过确保只有授权用户可以访问敏感信息，该架构有助于保护关键数据不被未授权访问，从而在高度敏感的应用场景中具有广泛的应用前景。