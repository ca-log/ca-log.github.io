---
author: 'TechScribe'
title: '解锁文本与视觉智慧：开放词汇3D物体检测的新纪元'
date: '2024-07-07'
Lastmod: '2024-07-10'
description: 'Unlocking Textual and Visual Wisdom: Open-Vocabulary 3D Object Detection Enhanced by Comprehensive Guidance from Text and Image'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Unlocking Textual and Visual Wisdom: Open-Vocabulary 3D Object Detection Enhanced by Comprehensive Guidance from Text and Image](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05256v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05256v1)

## 摘要

本文探讨了开放词汇3D物体检测（OV-3DDet）的问题，旨在在任何新的3D场景中定位和识别已见和未见过的物体类别。由于训练数据的有限性，这一任务面临重大挑战。尽管视觉-语言模型（VLM）和大型语言模型（LLM）在处理各种开放词汇任务上取得了成功，但这些基础模型的全部潜力尚未在OV-3DDet中得到充分开发。本文通过利用语言和视觉基础模型，解锁了文本和视觉智慧，以解决开放词汇3D检测任务。具体来说，本文利用视觉基础模型为发现3D场景中的新类别提供图像级指导，并通过分层对齐方法，将3D特征空间与视觉-语言特征空间在实例、类别和场景级别上对齐。实验结果显示，本文的方法在准确性和泛化性上取得了显著改进，强调了基础模型在推进开放词汇3D物体检测在实际场景中的潜力。<!--more-->

## 原理

本文提出的方法通过两个关键组件来实现开放词汇3D物体检测：图像引导的新类别发现（IGND）和分层特征空间对齐（Hierarchical Feature Space Alignment）。IGND利用视觉基础模型在图像中进行零样本物体发现，作为初始种子和过滤指导，以识别新的3D物体。分层对齐方法则通过预训练的视觉-语言模型（VLM）在实例、类别和场景级别上对齐3D特征空间和视觉-语言特征空间。这种分层对齐不仅考虑了单个物体的特征，还考虑了物体在场景中的关系，从而更全面地理解和识别3D场景中的物体。

## 流程

本文的方法工作流程分为三个主要阶段：首先，利用视觉基础模型在图像中检测物体，生成2D边界框作为初始种子；其次，将这些2D边界框的中心提升到3D空间，作为补充查询种子，用于生成更多的3D物体提案；最后，利用2D边界框来选择可靠的新3D边界框，并通过分层对齐方法，将3D特征空间与视觉-语言特征空间在不同级别上对齐。这一流程不仅提高了新类别发现的召回率，还增强了3D检测器的类别无关检测能力。

## 应用

本文的方法在开放词汇3D物体检测领域具有广泛的应用前景，特别是在自动驾驶、机器人交互和增强现实等需要精确3D物体识别和定位的应用中。通过利用视觉和语言基础模型的强大能力，本文的方法能够有效地处理和识别复杂的3D场景，为未来的智能系统提供了强大的技术支持。