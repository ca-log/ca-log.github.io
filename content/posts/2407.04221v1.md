---
author: 'TechScribe'
title: '探索Autoverse：一种革命性的可进化游戏语言，推动开放式学习的前沿'
date: '2024-07-05'
Lastmod: '2024-07-10'
description: 'Autoverse: An Evolvable Game Langugage for Learning Robust Embodied Agents'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Autoverse: An Evolvable Game Langugage for Learning Robust Embodied Agents](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.04221v1.pdf_0.jpg)](https://arxiv.org/abs/2407.04221v1)

## 摘要

本文介绍了一种名为Autoverse的可进化游戏语言，旨在为单人2D网格游戏创建一个可扩展的训练平台，用于开放式学习（OEL）算法。Autoverse通过类似细胞自动机的重写规则来描述游戏机制，能够表达多种游戏环境，如迷宫、地牢和推箱子谜题，这些都是强化学习（RL）代理的流行测试平台。论文提出了一种通过模仿学习从搜索中启动开放式学习的方法，通过进化Autoverse环境来最大化贪婪树搜索发现新最佳解决方案所需的迭代次数，从而生成一个由越来越复杂的环境和游戏轨迹组成的课程。然后，通过模仿学习将这些专家游戏轨迹提炼成基于神经网络的策略，并使用学习到的策略作为开放式RL的起点。<!--more-->

## 原理

Autoverse的核心在于其能够通过简单的卷积操作来实现环境的重写规则，这使得环境能够在GPU上并行化，从而大幅加速RL训练。重写规则定义为一系列局部瓷砖图案的变化，这些变化可以通过卷积核来识别和应用。通过这种方式，Autoverse不仅能够快速生成复杂的游戏环境，还能够通过模仿学习从搜索中提取专家轨迹，进而通过强化学习进一步优化代理策略。这种结合了环境进化、模仿学习和强化学习的方法，显著提高了代理的性能和通用性。

## 流程

论文首先通过进化算法生成一系列复杂的游戏环境，每个环境都通过贪婪树搜索来评估其难度。随后，通过模仿学习将这些环境的解决方案提炼成神经网络策略。最后，使用这些预训练的策略作为起点，进行开放式强化学习，不断进化新的训练环境以最大化RL代理的价值函数误差。整个流程包括环境生成、模仿学习提炼和开放式强化学习三个主要阶段，通过这种方式，代理能够在不断变化和复杂化的环境中学习和适应。

## 应用

Autoverse的应用前景广泛，尤其在需要高度适应性和通用性的AI系统中，如游戏AI、机器人学习和复杂环境下的决策支持系统。通过不断进化的环境和策略，Autoverse能够为AI代理提供一个持续学习和适应的平台，从而在各种实际应用中展现出更高的性能和灵活性。