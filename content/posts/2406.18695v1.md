---
author: 'TechScribe'
title: '"COBB：黑箱LLM推理能力提升的新方法"'
date: '2024-06-26'
Lastmod: '2024-07-05'
description: 'Learning to Correct for QA Reasoning with Black-box LLMs'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Learning to Correct for QA Reasoning with Black-box LLMs](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.18695v1.pdf_0.jpg)](https://arxiv.org/abs/2406.18695v1)

## 摘要

本文针对大型语言模型（LLM）在黑箱设置下的推理能力改进问题，提出了一种名为COBB的新方法。COBB通过训练一个较小的适应模型，将原始黑箱LLM的推理映射到正确的推理上。该方法不依赖于输出标记概率等详细信息，而是通过遗传算法优化数据集构建，并在训练过程中对比正确与错误推理的概率，从而显著提高了各种问答基准的推理准确性。<!--more-->

## 原理

COBB的核心在于通过一个训练有素的适应模型，将黑箱LLM的原始推理转换为改进的推理。具体来说，适应模型首先由一个较小的开源LLM初始化，并在一组子采样的训练对上进行调整。为了选择具有代表性的正确与错误推理对，研究者将数据集构建问题形式化为一个优化问题，通过遗传算法解决，以最小化采样子集与整个集合之间的统计偏差。接着，适应模型通过对比正确与错误推理的概率来进行训练。这一过程确保了模型能够有效地识别并修正错误的推理路径，同时保留并强化正确的推理逻辑。

## 流程

COBB的工作流程包括以下几个关键步骤：首先，从黑箱LLM中采样多个推理链，并使用人类标注的地面真实标签来标记其正确性。然后，从所有可能的正确与错误推理对中，子采样出一些能够保持整个集合特征的代表性对。接下来，通过遗传算法解决优化问题，以找到这样的子集。最后，使用这个优化子集，训练适应模型，同时增加正确推理的概率并降低错误推理的概率。整个过程通过算法1和图2进行了详细描述。

## 应用

COBB方法在多个问答任务中展示了其有效性，表明它能够广泛应用于需要黑箱LLM适应性的实际场景。由于其高效的训练和推理成本，COBB特别适合于资源受限的环境。此外，该方法的泛化能力意味着训练好的适应模型可以应用于其他LLM，包括基于API的黑箱模型和开源模型，这为实际部署提供了极大的灵活性和效率。