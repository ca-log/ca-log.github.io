---
author: 'TechScribe'
title: '探索量子神经网络的表达能力和归纳偏差'
date: '2024-07-05'
Lastmod: '2024-07-10'
description: 'Exploiting the equivalence between quantum neural networks and perceptrons'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Exploiting the equivalence between quantum neural networks and perceptrons](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.04371v1.pdf_0.jpg)](https://arxiv.org/abs/2407.04371v1)

## 摘要

这篇论文探讨了量子神经网络（QNNs）的表达能力和归纳偏差。通过将 QNNs 映射到经典感知机，研究了它们在布尔函数上的局限性和障碍。论文还提出了两种方法来克服这些限制，即使用 QNN 生成经典 DNN 启发的内核，以及构建具有更丰富归纳偏差的分层非线性 QNN。最后，论文讨论了 QNN 文献中可能模糊其在经典数据上实现量子优势难度的特征。<!--more-->

## 原理

论文通过将 QNNs 映射到经典感知机，证明了任何 QNN 都可以唯一地映射到一个张量积感知机（TPP）上。TPP 是一种作用在输入数据张量积上的经典感知机，其权重是实数。通过这种映射，简化了 QNNs 的训练，允许系统地研究其他更具表现力的嵌入对布尔数据的归纳偏差。

## 流程

首先，将 QNNs 作用在输入数据的张量积上，得到一个张量积感知机（TPP）。然后，通过训练 TPP 来研究 QNNs 的表达能力和归纳偏差。具体来说，通过在布尔数据集上进行实验，比较不同编码方法和算法的性能，来评估 QNNs 的表达能力和归纳偏差。

## 应用

QNNs 在量子计算和人工智能领域具有广泛的应用前景。它们可以用于量子机器学习、量子优化、量子密码学等领域。此外，QNNs 还可以与经典神经网络结合，形成混合量子-经典模型，提高模型的性能和效率。