---
author: 'TechScribe'
title: '提升低收入数据表现：视觉-语言模型的社会经济视角转换策略'
date: '2024-07-02 19:27:00+00:00'
Lastmod: '2024-07-04 01:53:13.277720'
description: 'Uplifting Lower-Income Data: Strategies for Socioeconomic Perspective Shifts in Vision-Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Uplifting Lower-Income Data: Strategies for Socioeconomic Perspective Shifts in Vision-Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02623v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02623v1)

## 摘要

本文由Joan Nwatu、Oana Ignat、Rada Mihalcea等研究者共同撰写，旨在解决视觉-语言模型（VL模型）在不同国家和收入群体中表现不均的问题。研究团队通过设计包含非英语、地理和经济社会属性的综合提示，评估这些提示对VL模型在不同国家及收入群体数据上的表现影响。研究发现，地理和经济社会属性的综合提示能显著提升VL模型在低收入数据上的表现，并有助于检索到更多低收入家庭常见的主题内容。研究还确定了这些策略最有效的应用场景，并公开了相关模型分析代码，以便于其他VL模型和数据集的性能评估。<!--more-->

## 原理

研究团队采用三种提示技术来提升VL模型在低收入数据上的表现：1) 将提示翻译成各国的非英语主要语言；2) 在提示中加入国家名称；3) 在提示中加入经济社会属性（如“贫穷国家”、“富裕地区”）。通过使用NLLB-CLIP-SigLIP这一先进的跨语言视觉-语言模型，研究者计算了图像嵌入与文本嵌入之间的余弦相似度，以此评估不同提示策略的效果。研究发现，尽管非英语提示在某些情况下表现不佳，但包含地理和经济社会属性的提示能显著提高模型对低收入数据的识别准确性。

## 流程

研究团队首先选择了包含38,479张图像的Dollar Street数据集，该数据集涵盖了多个国家和不同收入水平的家庭物品图像。接着，他们设计了三种类型的提示：默认英语提示、翻译成各国非英语主要语言的提示、以及包含国家名称或经济社会属性的提示。使用NLLB-CLIP-SigLIP模型对这些提示进行处理，计算图像与提示之间的相似度，并根据相似度得分来评估提示的有效性。实验结果显示，包含国家名称和经济社会属性的提示能有效提升模型对低收入数据的识别能力，尤其是在检索那些在低收入家庭中常见的物品图像时表现突出。

## 应用

该研究提出的提示策略不仅有助于提升VL模型在低收入数据上的表现，还能促进AI模型在更广泛的社会经济和文化背景下的应用。这些策略可以应用于数据标注、内容推荐系统、以及跨文化交流平台等多个领域，有助于构建更加公平和包容的AI系统。此外，公开的模型分析代码也为其他研究者和开发者提供了宝贵的资源，以进一步优化和扩展VL模型的应用范围。