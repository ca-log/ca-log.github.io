---
author: 'TechScribe'
title: '"Skywork-Math：突破大型语言模型在数学推理上的极限"'
date: '2024-07-11'
Lastmod: '2024-07-12'
description: 'Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.08348v1.pdf_0.jpg)](https://arxiv.org/abs/2407.08348v1)

## 摘要

本文探讨了如何通过数据扩展法增强大型语言模型（LLMs）在数学推理能力上的表现。研究团队引入了Skywork-Math模型系列，这些模型在常见的7B参数LLMs上进行了监督微调（SFT），使用了他们提出的250万实例的Skywork-MathQA数据集。Skywork-Math 7B模型在MATH和GSM8K基准测试中取得了显著的准确率，分别达到了51.2%和83.9%，超越了早期版本的GPT-4。这一成果得益于他们创新的两阶段数据合成和模型SFT流程，该流程包括三种不同的增强方法和一个多样化的种子问题集，确保了Skywork-MathQA数据集在不同难度级别上的数量和质量。此外，研究还提供了实用的见解，以增强LLMs在数学推理方面的能力，适用于研究和工业应用。<!--more-->

## 原理

Skywork-Math模型系列的核心在于其两阶段的数据合成和模型SFT流程。在第一阶段，模型通过处理由GPT-4生成的正常合成问题来增强对数学问题的普遍理解。为了保持数据选择的多样性，采用了核心集方法对扩大的种子问题进行处理。然而，随着数据量的增加，性能与数据量之间的关系开始趋于平稳。因此，在第二阶段，通过引入一定比例的增强难题来进一步多样化数据集，从而使模型暴露于更具挑战性的数学问题中。这一过程不需要在大规模数学语料库上进行持续的预训练，而是通过在仅包含7B参数的常见预训练LLMs上进行监督微调来实现显著的性能提升。

## 流程

1. **数据合成阶段1**：使用GPT-4生成210万个高质量、多样化的SFT数据，旨在让模型获得对数学问题的全面理解。
2. **数据合成阶段2**：在第一阶段的基础上，生成40万个难题，增加数据集的难度和多样性。
3. **模型SFT阶段**：在常见的7B预训练LLM模型上进行监督微调，使用合成的Skywork-MathQA数据集。
4. **评估阶段**：在GSM8K和MATH基准测试上评估模型的数学推理能力，确保不使用外部工具和投票技术，采用零样本思维链评估框架。

## 应用

Skywork-Math模型的应用前景广泛，特别是在需要复杂数学推理的教育、金融分析、科学研究等领域。这些模型能够处理和解决高级数学问题，为自动化复杂计算和分析提供了可能。随着模型的进一步优化和数据集的扩展，其在实际应用中的性能和可靠性将得到进一步提升。