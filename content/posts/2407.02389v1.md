# "SafaRi：引领弱监督引用表达分割的新纪元"

[![SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring Expression Segmentation](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02389v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02389v1)

## 摘要

本文介绍了一种名为SafaRi的自适应序列转换器，用于弱监督的引用表达分割（Referring Expression Segmentation, RES）任务。该方法通过引入新的算法创新，解决了现有方法需要大量掩码标注且在未见/零样本场景中泛化能力差的问题。SafaRi是首个仅使用部分掩码和边界框标注进行训练的方法，通过跨模态融合与注意力一致性模块（X-FACt）和伪标签有效性过滤程序（MVF），显著提高了图像与文本区域级对齐和目标对象的空间定位能力。实验表明，在仅使用30%标注数据的情况下，SafaRi在RefCOCO+@testA和RefCOCO+testB数据集上的表现优于完全监督的SOTA方法SeqTR，并展示了强大的泛化能力。

## 原理

SafaRi的核心在于其跨模态融合与注意力一致性模块（X-FACt），该模块通过融合特征提取器和注意力掩码一致性正则化（AMCR）来增强跨模态对齐质量。X-FACt模块利用Swin Transformer和RoBERTa作为图像和文本特征提取器，通过归一化门控交叉注意力机制学习高质量的语言感知视觉表示。AMCR组件通过正则化技术确保交叉注意力热图与图像中的目标对象一致，从而在有限标注场景下提高视觉定位能力。此外，SafaRi还通过伪标签有效性过滤（MVF）和空间感知零样本提案评分方法（SpARC）进行自动伪标签生成和验证，进一步提升了模型的自标注能力。

## 流程

SafaRi的工作流程包括初始训练阶段、伪标签生成和模型重新训练三个主要步骤。在初始训练阶段，模型使用部分标注的掩码数据进行训练。随后，在伪标签生成阶段，模型对未标注数据进行推理并生成掩码，这些掩码通过MVF进行有效性验证。最后，在模型重新训练阶段，模型使用包含伪标签的更新数据集进行迭代训练，通过γ调度策略动态调整伪标签损失权重，以平衡真实掩码和伪标签的训练。这一流程通过迭代优化，不断提升模型在弱监督环境下的分割性能。

## 应用

SafaRi在弱监督引用表达分割任务中展现了卓越的性能，其方法不仅适用于静态图像分割，还具有向多图像和视频场景扩展的潜力。随着技术的进一步发展和优化，SafaRi有望在视频对象分割、交互式图像分割等更广泛的视觉任务中发挥重要作用，特别是在需要处理复杂场景和动态对象的应用中。

