---
author: 'Hayder Elesedy,Pedro M. Esperança,Silviu Vlad Oprea,Mete Ozay'
title: 'LoRA-Guard：开创资源受限设备上的高效内容审核新时代'
date: '2024-07-03'
Lastmod: '2024-07-05'
description: 'LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02987v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02987v1)

## 摘要

本文介绍了一种名为LoRA-Guard的新型内容审核方法，专门针对资源受限的计算设备如移动电话上的大型语言模型（LLMs）应用。LoRA-Guard通过在LLMs和防护模型之间共享知识，利用低秩适配器（LoRA）提取语言特征并进行内容审核任务的适配。该方法通过双路径设计，防止了生成任务性能的下降，并在保持准确性的同时，将参数开销降低了100-1000倍，使得在设备上进行内容审核成为可能。<!--more-->

## 原理

LoRA-Guard的核心在于其参数高效的防护适配方法，该方法依赖于LLMs和防护模型之间的知识共享。具体来说，LoRA-Guard从LLMs中提取语言特征，并使用低秩适配器（LoRA）进行内容审核任务的适配。LoRA适配器是一种参数高效的微调方法，通过在预训练模型的权重上添加可训练的低秩矩阵，实现对模型的微调，而不会影响原始模型的参数。此外，LoRA-Guard采用双路径设计，即生成路径和防护路径，分别用于生成响应和进行内容审核，这种设计避免了传统微调方法中常见的性能下降问题（即灾难性遗忘）。

## 流程

LoRA-Guard的工作流程包括以下几个步骤：
1. 从LLMs中提取语言特征。
2. 使用LoRA适配器对提取的特征进行内容审核任务的适配。
3. 通过双路径设计，分别进行生成任务和防护任务。
4. 在生成路径中，使用原始的语言模型头进行响应生成。
5. 在防护路径中，使用防护模型头进行内容审核，并生成危害性评分。
6. 系统可以根据用户提示、模型响应或它们的组合进行防护。

例如，在ToxicChat数据集上的实验显示，LoRA-Guard在几乎所有情况下都优于基线方法，同时使用的参数数量仅为基线方法的1/1000。

## 应用

LoRA-Guard的应用前景广泛，特别适用于需要在资源受限设备上运行LLMs应用的场景，如移动电话上的聊天机器人。由于其参数高效和性能优越，LoRA-Guard有望成为未来内容审核技术的重要组成部分，推动LLMs在更广泛领域的安全应用。