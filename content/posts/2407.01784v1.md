---
author: 'TechScribe'
title: '探索表情包中的说服技巧：语言模型与释义增强的融合'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language Models with Paraphrase Enrichment'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language Models with Paraphrase Enrichment](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01784v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01784v1)

## 摘要

本文由Kota Shamanth Ramanath Nayak和Leila Kosseim撰写，来自加拿大蒙特利尔康考迪亚大学的计算语言学实验室（CLaC）。论文主要探讨了在表情包文本中检测说服技巧的多标签分类问题。研究采用了细调的语言模型（如BERT、XLM-RoBERTa和mBERT），并通过ChatGPT生成的释义数据进行数据增强，以提高模型性能。研究结果显示，使用释义训练可以提升模型性能，但平衡的训练集比不平衡的大集更有优势。此外，论文还指出了从不同分布中无差别地引入释义可能带来的噪声问题。<!--more-->

## 原理

论文的核心在于利用细调的语言模型和数据增强技术来识别和分类表情包文本中的多种说服技巧。具体来说，研究团队首先对BERT、XLM-RoBERTa和mBERT这三个语言模型进行细调，然后通过平均聚合的方式构建了一个集成模型。为了增强模型的泛化能力，研究中采用了ChatGPT生成的释义数据进行数据增强。此外，研究还调整了每个说服技巧的分类阈值，以优化模型在验证集上的表现。这种结合了细调语言模型和数据增强的方法，不仅提高了模型的准确性，还增强了模型对不同语言的适应能力。

## 流程

研究的工作流程包括以下几个关键步骤：首先，对BERT、XLM-RoBERTa和mBERT进行细调；其次，使用ChatGPT生成释义数据进行数据增强；然后，通过平均聚合的方式构建集成模型；最后，调整分类阈值以优化模型性能。在实际应用中，模型首先对输入的文本进行预处理和标记化，然后通过细调的模型输出概率分布，再通过集成模型进行最终的分类决策。例如，对于一个包含特定说服技巧的表情包文本，模型能够准确识别并分类出这些技巧。

## 应用

该研究的应用前景广泛，特别是在社交媒体分析、广告效果评估和政治宣传监控等领域。通过有效识别和分类表情包中的说服技巧，可以帮助研究人员和决策者更好地理解和管理网络环境中的信息传播。此外，该技术还可以用于教育领域，帮助学生识别和分析不同类型的说服技巧，提高他们的批判性思维能力。