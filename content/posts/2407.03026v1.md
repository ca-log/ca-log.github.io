---
author: 'Jinming Chen,Jingyi Fang,Yuanzhong Zheng,Yaoxuan Wang,Haojun Fei'
title: '探索Qifusion-Net：引领多口音语音识别的新前沿'
date: '2024-07-03'
Lastmod: '2024-07-05'
description: 'Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03026v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03026v1)

## 摘要

本文介绍了一种名为Qifusion-Net的端到端多口音语音识别模型，该模型通过层适应融合（LAF）策略，无需预先了解目标口音信息即可有效识别多口音语音。基于动态块策略，Qifusion-Net支持流式和非流式解码模式，并能在帧级别提取声学特征，实现细粒度信息融合。实验结果显示，Qifusion-Net在KeSpeech和MagicData-RMAC数据集上的字符错误率（CER）分别降低了22.1%和17.2%，显著优于基线模型。<!--more-->

## 原理

Qifusion-Net的核心在于其层适应融合模块（LAF），该模块通过在共享声学编码器中提取细粒度口音信息，结合交叉注意力模块，有效消除了口音对声学模型的影响。LAF模块通过选择不同层次的声学编码器输出，利用可学习的适应权重进行融合，从而在无需额外口音类别信息的情况下，提高了多口音系统的识别准确性。交叉注意力模块则通过将声学特征作为键，口音嵌入作为查询，进行信息融合，进一步提升了识别性能。

## 流程

Qifusion-Net的工作流程包括以下几个关键步骤：首先，通过基于Conformer的声学编码器提取帧级别的声学特征；其次，利用LAF模块从声学编码器的不同层次提取口音信息；然后，通过交叉注意力模块将声学特征和口音信息进行融合；最后，通过多任务训练和动态块策略实现流式和非流式解码。例如，在训练阶段，模型会随机选择一个块大小，将输入分割成多个块，并对每个块进行双向块级别注意力，以适应不同的解码模式。

## 应用

Qifusion-Net的应用前景广泛，特别适用于需要处理多口音语音识别的商业语音识别产品。由于其无需预先口音信息即可高效识别多口音语音的能力，该模型在实际应用中具有很高的实用价值和参考意义，尤其是在实时流式场景和多任务学习中。