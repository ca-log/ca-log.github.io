---
author: 'TechScribe'
title: '探索Qifusion-Net：引领多口音语音识别的新前沿'
date: '2024-07-03 11:35:52+00:00'
Lastmod: '2024-07-04 01:52:53.247771'
description: 'Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03026v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03026v1)

## 摘要

本文介绍了一种名为Qifusion-Net的端到端多口音语音识别模型，该模型通过层适应融合（LAF）模块，实现了无需预先了解目标口音的流/非流解码模式。Qifusion-Net在多个口音测试数据集上显著降低了字符错误率（CER），显示出其在多口音语音识别领域的先进性和实用性。<!--more-->

## 原理

Qifusion-Net的核心在于其层适应融合（LAF）模块，该模块通过动态块策略实现流和非流解码模式的统一。LAF模块能够从共享的声学编码器中提取细粒度的口音信息，并通过交叉注意力模块有效地融合这些信息，从而消除口音对声学模型的影响。此外，模型采用了基于卷积增强的Transformer（Conformer）的声学编码器，通过逐步子采样操作减少输入序列的维度，降低了计算复杂度，同时增强了局部信号序列的建模能力。

## 流程

Qifusion-Net的工作流程包括以下几个关键步骤：
1. **声学编码器**：使用Conformer模型提取多口音语音的帧级声学特征。
2. **层适应模块**：从声学编码器的不同层提取细粒度的口音信息，并通过学习可适应的权重进行融合。
3. **交叉注意力模块**：将声学特征和口音嵌入进行交叉信息融合，以消除口音导致的声学特征扭曲。
4. **多任务训练和流/非流解码**：结合CTC损失、解码器注意力损失和口音识别交叉熵损失进行多任务训练，并使用动态块掩蔽策略支持流和非流解码模式。

## 应用

Qifusion-Net在多口音语音识别领域具有广泛的应用前景，特别是在需要处理多种口音的实时语音识别系统中。其高效的流/非流解码能力和细粒度的口音信息融合，使其在商业语音识别产品中具有重要的应用价值。