---
author: 'TechScribe'
title: '"SmurfCat团队在PAN 2024多语言文本去毒化任务中的创新解决方案"'
date: '2024-07-07'
Lastmod: '2024-07-10'
description: 'SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05449v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05449v1)

## 摘要

本文由SmurfCat团队在PAN 2024文本去毒化任务中提出，旨在解决多语言文本去毒化的挑战。文章介绍了通过机器翻译进行数据增强和特殊过滤程序，构建了一个额外的多语言平行数据集。利用这些数据，团队对多个多语言序列到序列模型（如mT0和Aya）进行了微调，并应用了ORPO对齐技术。最终模型仅包含37亿参数，实现了乌克兰语的最新技术成果和其他语言的接近最新技术成果。在竞赛中，团队在自动评估中以0.52分获得第一名，在最终的人工评估中以0.74分获得第二名。<!--more-->

## 原理

本文的核心工作原理基于多语言序列到序列模型的微调与优化。首先，通过机器翻译从英语数据自动翻译到其他语言，进行数据增强。随后，使用LaBSE模型评估翻译前后语义相似度，并利用XLM-R毒性分类器检查翻译后的毒性变化。通过这些步骤，构建了一个多语言平行数据集。接着，对mT0系列模型进行微调，采用多样性束搜索算法进行假设过滤，最后应用ORPO对齐技术进一步优化模型性能。这一系列步骤确保了模型在多语言环境下的高效去毒化能力。

## 流程

1. **数据增强**：使用GoogleTranslator模型将英语数据自动翻译成其他9种语言，增加数据多样性。
2. **数据过滤**：通过LaBSE模型和XLM-R毒性分类器对翻译后的数据进行语义相似度和毒性检查，确保数据质量。
3. **模型微调**：对mT0系列模型进行微调，针对每种语言优化模型参数。
4. **假设生成与选择**：使用多样性束搜索生成多个假设，并根据相关性评分选择最佳候选。
5. **ORPO对齐**：应用ORPO对齐技术，进一步优化模型在未见数据上的表现。

## 应用

该研究为多语言文本去毒化提供了有效的解决方案，特别适用于低资源语言。未来，该技术可广泛应用于社交媒体监控、在线内容审核等领域，有助于构建更加健康和安全的网络环境。此外，该方法还可扩展到其他文本风格转换任务，具有广泛的应用前景。