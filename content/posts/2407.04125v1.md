---
author: 'TechScribe'
title: 'QGSumm：革命性的护理笔记摘要技术，提升临床工作效率'
date: '2024-07-04'
Lastmod: '2024-07-10'
description: 'Query-Guided Self-Supervised Summarization of Nursing Notes'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Query-Guided Self-Supervised Summarization of Nursing Notes](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.04125v1.pdf_0.jpg)](https://arxiv.org/abs/2407.04125v1)

## 摘要

本文介绍了一种名为QGSumm的查询引导自监督领域适应框架，用于护理笔记的摘要生成。护理笔记是电子健康记录（EHRs）的重要组成部分，追踪患者在护理过程中的健康状况变化。现有的摘要方法往往忽视了护理笔记，并且需要创建参考摘要作为监督信号，这既耗时又费力。QGSumm利用与患者相关的临床查询作为指导，生成高质量、以患者为中心的摘要，无需依赖参考摘要进行训练。通过自动和专家临床医生的手动评估，证明了该方法相对于最先进的大型语言模型（LLMs）在零样本和少样本设置中的优势。该方法为条件文本摘要提供了一个新的视角，特别适用于临床人员的特定兴趣。<!--more-->

## 原理

QGSumm的核心原理是利用患者相关的临床查询来引导摘要生成过程。该框架假设一个好的临床笔记摘要是以患者的状况为中心的，因此，当查询关于患者的状况时，从摘要中得到的答案应与从原始笔记中得到的答案相似。例如，查询可以涉及患者状况在不久的将来改善的可能性。模型被训练来使用当前的护理笔记或其摘要作为输入来回答这个查询，如果摘要准确，这两个答案应该是相似的。因此，学习目标是最小化从摘要或源笔记对给定查询的响应之间的差异。为了进一步鼓励模型优先考虑患者的当前医疗状况，摘要工作流程中还集成了患者的元数据以及患者在同一入院期间记录的先前笔记的信息。

## 流程

QGSumm的工作流程包括以下几个关键步骤：
1. **基础模型**：使用一个预训练的基于Transformer的语言模型作为基础模型，该模型已经针对文本摘要任务进行了微调。
2. **训练目标**：由于没有可用的真实摘要，传统的监督微调方法不可行。因此，采用自监督策略来强制模型生成高质量、以患者为中心的摘要，这些摘要能够有效地响应患者相关的查询。
3. **增强块**：为了提高性能，引入了两个增强块：时间信息融合（TIF）和患者信息增强（PIA）。TIF通过加权平均池化从前面的笔记中提取信息，而PIA通过交叉注意机制将患者级别的元数据集成到模型中。
4. **实验设置**：使用MIMIC-III数据库进行实验，该数据库是一个广泛使用的真实世界EHRs数据库。实验包括自动评估和临床医生的手动评估，以全面评估摘要的质量。

## 应用

QGSumm的应用前景广泛，特别是在临床环境中，它可以帮助临床人员更有效地理解患者的状况，从而提高工作效率和护理质量。此外，该方法还可以扩展到其他类型的医疗文档摘要，如出院总结、放射学报告等。随着技术的进一步发展和优化，QGSumm有望成为医疗信息处理领域的一个重要工具。