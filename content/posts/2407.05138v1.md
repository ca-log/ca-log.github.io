---
author: 'TechScribe'
title: '探索RAG增强型LLM在软件集成中的挑战与前景'
date: '2024-07-06'
Lastmod: '2024-07-10'
description: 'Vortex under Ripplet: An Empirical Study of RAG-enabled Applications'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Vortex under Ripplet: An Empirical Study of RAG-enabled Applications](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05138v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05138v1)

## 摘要

本文通过深入研究100个开源应用程序及其问题报告，揭示了在将增强检索生成（RAG）的大型语言模型（LLM）集成到软件系统中时，开发者面临的挑战。研究发现，超过98%的应用程序存在多种集成缺陷，这些缺陷影响了软件的功能性、效率和安全性。文章总结了19种缺陷模式，并提出了相应的解决指南，旨在辅助LLM驱动的软件开发，并激发未来的研究。<!--more-->

## 原理

RAG-enhanced LLMs通过从外部数据源提供相关信息来增强其在具体应用场景中的能力。这些模型在存储阶段将文本从源文件中提取并分割成多个块，每个知识条目通过LLM的嵌入模块被嵌入为一个语义向量，存储在向量数据库中。在查询阶段，RAG算法使用相同的嵌入模块将查询问题嵌入，并通过语义向量之间的距离检索相关知识条目，构建LLM上下文，从而简化原本知识密集型任务为理解任务。

## 流程

LLM-enabled软件的典型工作流程包括初始化向量数据库、收集和转换用户输入、提取关键短语构建查询问题、从向量数据库检索相关知识、LLM代理构建提示并管理执行历史、软件组件处理LLM响应并回答用户。例如，一个角色模拟应用程序支持语音对话，利用向量数据库存储角色设置，并通过第三方库进行语音和文本的转换。当用户询问角色信息时，应用程序从向量数据库中检索相关信息以构建提示，使LLM代理能够扮演任何角色并正确回答问题。

## 应用

RAG-enhanced LLMs在多种应用场景中提供了有效的解决方案，包括对话、文档理解、问答等。随着技术的成熟和框架的完善，预计将有更多软件系统集成这些模型以实现智能功能。未来的研究可以进一步探索这些模型在不同领域的应用潜力，以及如何优化集成过程以提高软件质量和用户体验。