---
author: 'TechScribe'
title: '"SaMoye：革命性的零样本歌唱声音转换技术"'
date: '2024-07-10'
Lastmod: '2024-07-12'
description: 'SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07728v2.pdf_0.jpg)](https://arxiv.org/abs/2407.07728v2)

## 摘要

本文介绍了一种名为SaMoye的端到端特征解耦模型，用于实现零样本多对多歌唱声音转换（SVC）。SaMoye模型通过将歌唱声音的特征分解为内容、音色和音调特征，实现了在不依赖大量训练样本的情况下，将一首歌的演唱者声音转换为另一个演唱者的声音，同时保持音乐内容如节奏和旋律的一致性。此外，本文还建立了一个大规模的无标签歌唱声音数据集，包含150万个纯净的歌唱声音片段，涵盖至少10,000名歌手，以支持零样本性能。<!--more-->

## 原理

SaMoye模型的核心在于其特征解耦和合成机制。首先，模型通过Hubert模型提取音频内容特征，并通过残差向量量化（RVQ）将这些特征量化为Hubert令牌。接着，利用基于GPT的模型增强内容特征，通过与歌词音素的交叉预测，提高内容信息的准确性并减少原音色信息。音色特征则从Mel频谱图中提取，并通过RMVPE模型获取音调特征。在合成阶段，模型通过替换目标歌手的音色特征，生成转换后的音频。这一过程通过对抗学习策略进行优化，确保生成的音频在特征和数据尺度上与原始音频难以区分。

## 流程

SaMoye模型的工作流程分为训练和推理两个阶段。在训练阶段，模型首先从音频片段中提取内容、音色和音调特征，并通过对抗学习策略训练生成器和判别器。生成器负责合成转换后的音频，而判别器则评估生成音频与原始音频的相似度。在推理阶段，模型通过替换目标歌手的音色特征，直接生成转换后的音频。例如，输入一段原唱音频和目标歌手的音色特征，模型将输出一段由目标歌手演唱的音频。

## 应用

SaMoye模型的应用前景广泛，特别是在音乐制作、娱乐和虚拟现实领域。例如，音乐制作人可以利用该模型快速生成不同歌手风格的音乐作品，而无需每个歌手实际录制。此外，该模型还可用于虚拟现实中的角色配音，为游戏和虚拟角色提供多样化的声音选项。随着技术的进一步发展和优化，SaMoye模型有望在更多领域展现其价值。