# Meta 3D TextureGen：革命性的3D纹理生成技术，开启快速高质量创作新纪元

[![Meta 3D TextureGen: Fast and Consistent Texture Generation for 3D Objects](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02430v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02430v1)

## 摘要

本文介绍了一种名为Meta 3D TextureGen的新型前馈方法，旨在为任意复杂度的3D几何体生成高质量且全局一致的纹理。该方法利用文本到图像模型的适应性，通过在2D空间中对3D语义进行条件化，并将它们融合成完整的、高分辨率的UV纹理图，从而在不到20秒的时间内实现纹理生成。此外，还引入了一个纹理增强网络，能够将任意纹理上采样至4K像素分辨率。该方法在质量和速度上均达到了最先进的结果，为3D对象的纹理生成提供了快速且一致的解决方案，具有广泛的应用前景。

## 原理

Meta 3D TextureGen的工作原理基于两个连续的网络：第一个网络是一个几何感知文本到图像模型，它生成多视角的纹理图像，这些图像在2D空间中被条件化为3D形状特征。第二个网络是一个图像到图像的网络，它在UV空间中操作，通过将第一个网络的输出反投影并融合，生成一个完整的UV纹理图。这种方法的关键创新在于利用3D形状特征的2D渲染来指导纹理生成，确保了纹理的全局一致性和对文本提示的忠实度。

## 流程

Meta 3D TextureGen的工作流程分为两个主要阶段：
1. **图像空间生成阶段**：使用一个经过微调的扩散型神经网络，根据文本描述和3D形状特征的渲染，生成多视角的纹理图像。
2. **UV空间生成阶段**：将第一阶段的输出通过加权反投影操作融合到UV空间中，然后使用一个UV空间内的修复网络填补缺失区域并提高纹理的整体质量。
此外，还可以选择性地使用纹理增强网络来进一步提高纹理的分辨率和质量。

## 应用

Meta 3D TextureGen的应用前景广泛，包括但不限于游戏、动画和虚拟/混合现实等领域的3D内容创作。其快速、高质量且多样化的纹理生成能力，使得艺术家和普通用户都能够轻松地为3D资产创建丰富的纹理，极大地提升了3D内容的视觉表现和创作效率。

