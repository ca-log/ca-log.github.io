---
author: 'TechScribe'
title: '探索多分辨率Tokenization：革新时间序列预测的Transformer架构'
date: '2024-07-03 15:07:16+00:00'
Lastmod: '2024-07-04 01:52:42.681934'
description: 'Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03185v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03185v1)

## 摘要

本文提出了一种针对时间序列预测的transformer架构，特别关注时间序列的tokenization，并将其应用于定价领域的实际预测问题。该架构旨在同时学习所有可用数据在多个尺度上的有效表示。模型包含多个创新模块：一种采用多分辨率的时间序列分块方法，一个用于处理时间变化已知变量的多分辨率模块，一个基于混合器的模块用于捕捉跨序列信息，以及一个具有有利缩放特性的新颖输出头，以应对增加的token数量。本文展示了该模型在一家大型零售商的降价团队面临的实际预测问题中的应用，实验表明该模型优于内部模型和选定的现有深度学习架构。<!--more-->

## 原理

该模型的核心在于多分辨率tokenization（MRT）策略，它允许模型在同一注意力机制中使用来自多个分辨率的token，从而在多个数据类型之间进行显式的成对建模。此外，模型还提供了一种方案，用于在多个分辨率上对未来时间步长的时间变化已知数据进行tokenize。这种多分辨率tokenization策略使得模型能够学习复杂的成对关系，并通过将辅助变量作为tokenization策略的一部分，增强了模型的解释性。

## 流程

模型的工作流程包括以下几个关键步骤：
1. **多分辨率分块（MRP）**：将时间序列分成多个分辨率的块，每个分辨率使用共享的线性变换映射到嵌入空间。
2. **处理辅助信息**：对辅助数据进行单独的tokenization，以减少过拟合并提高解释性。
3. **跨序列信息**：使用混合器架构提取跨序列token（CST），这些token与所有其他token一起输入到transformer模块中。
4. **输出头**：提出了一种新颖的反向分块输出头，具有有利的缩放特性，能够处理增加的token数量。

## 应用

该模型在定价领域的应用前景广阔，特别是在需要复杂时间序列分析和辅助变量建模的场景中。由于其能够处理多分辨率和跨序列信息，该模型有望在零售、金融和其他需要精细时间序列预测的行业中得到广泛应用。