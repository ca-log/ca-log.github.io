---
author: 'TechScribe'
title: '"革新草图识别：结合大型基础模型与人类草图理解的新方法"'
date: '2024-07-04'
Lastmod: '2024-07-10'
description: 'Do Generalised Classifiers really work on Human Drawn Sketches?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Do Generalised Classifiers really work on Human Drawn Sketches?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.03893v1.pdf_0.jpg)](https://arxiv.org/abs/2407.03893v1)

## 摘要

本文探讨了通用分类器在人类绘制草图上的应用效果，特别是在不同抽象层次上的表现。论文提出了一种结合大型基础模型与人类草图理解的新方法，通过学习特定于草图的提示和抽象层次的代码本，使CLIP模型能够更好地适应草图分类。该方法不仅在零样本和少样本设置下超越了现有算法，而且在不同抽象边界的场景中也表现出色。论文的核心贡献在于首次将人类草图与基础模型结合，解决了数据稀缺和抽象层次多样性两大挑战，展示了在草图分类领域的广泛应用前景。<!--more-->

## 原理

论文的核心在于通过条件化CLIP模型，使其能够理解和分类人类绘制的草图。首先，通过学习草图特定的提示（prompts），使CLIP模型“草图意识”增强。这些提示是通过一个新颖的辅助头，即光栅到矢量草图转换，来实现的。其次，为了处理草图的抽象层次差异，论文引入了抽象层次特定的提示偏差代码本，通过加权组合这些代码本，模型能够表示跨越不同抽象层次的草图。这种方法使得CLIP模型不仅能够识别草图，还能理解其抽象程度，从而在草图分类任务中实现更高的准确性和泛化能力。

## 流程

论文提出的方法首先使用CLIP视觉变换器（ViT）作为视觉编码器，通过学习草图提示（visual prompts）来编码输入草图，生成视觉特征。接着，这些视觉特征被同时输入到两个模块中：一个轻量级的元网络（Meta-Net）用于预测实例特定的上下文，以及一个代码本分类器用于计算抽象提示。最后，结合文本提示、实例特定上下文和抽象提示，生成文本特征，并通过CLIP文本编码器进行分类。整个流程通过训练和推理阶段实现，确保模型在不同抽象层次的草图上都能有效工作。

## 应用

论文提出的方法不仅在草图分类上取得了显著的进步，而且为未来的草图理解和处理提供了新的方向。该技术可以应用于教育、设计、艺术创作等多个领域，帮助用户更好地理解和利用草图信息。随着技术的进一步发展和优化，预计将在更多领域展现出其潜在价值。