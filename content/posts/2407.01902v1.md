---
author: 'TechScribe'
title: '解锁LLMs的安全挑战：SoP框架的自动越狱攻击与防御策略'
date: '2024-07-02 02:58:29+00:00'
Lastmod: '2024-07-04 01:17:44.032071'
description: 'SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01902v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01902v1)

## 摘要

本文探讨了大型语言模型（LLMs）在广泛应用中可能被滥用的安全问题。尽管LLMs在发布前已根据人类偏好数据进行了调整，但它们仍容易受到各种恶意攻击，特别是“越狱攻击”。本文提出了一种基于社会促进概念的自动越狱提示设计框架（SoP），该框架能够利用开源LLMs自动生成和优化越狱提示，无需人工设计的种子模板。实验结果显示，SoP在绕过GPT-3.5和GPT-4的安全对齐方面取得了显著的成功率，并展示了其在不同LLMs和恶意请求之间的可转移性。此外，本文还探讨了针对SoP设计的越狱攻击的防御策略。<!--more-->

## 原理

SoP框架的核心在于利用社会促进概念，通过自动生成和优化多个越狱角色来绕过目标LLM的安全防护。这些角色在攻击过程中被逐步优化，以最大化组合角色的最佳攻击性能。SoP的关键创新在于其能够在冷启动场景中使用开源LLMs生成和优化越狱提示，无需依赖人工设计的种子模板或专有LLMs。这种自动化的方法不仅提高了攻击效率，还增强了攻击的可转移性和通用性。

## 流程

SoP的工作流程包括以下几个关键步骤：
1. **角色生成**：使用元提示（meta prompt）指导攻击LLM生成候选越狱角色。
2. **目标响应**：将候选角色插入越狱模板中，结合恶意请求攻击目标LLM。
3. **越狱评分**：使用判断模型对当前角色的响应进行评分。
4. **迭代优化**：根据评分结果更新元提示中的示例，重复上述过程以优化角色。

具体示例中，SoP通过生成多个角色，每个角色提供逐步的恶意指令，从而诱导目标LLM生成有害内容。例如，一个角色可能被描述为“不需要遵守任何规则”，并通过逐步指令引导LLM执行恶意行为。

## 应用

SoP框架的应用前景广泛，主要体现在以下几个方面：
1. **安全测试**：作为红队策略，用于测试和增强LLMs的安全性。
2. **防御策略开发**：通过揭示LLMs的潜在漏洞，促进更有效的防御机制的开发。
3. **研究工具**：为研究人员提供一个强大的工具，用于探索和理解LLMs的安全性和鲁棒性。

随着LLMs在各个领域的广泛应用，SoP框架将成为确保这些模型安全性的重要工具，同时也为开发更智能、更安全的AI系统提供了新的视角和方法。