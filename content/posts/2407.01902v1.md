---
author: 'TechScribe'
title: '解锁社会促进的力量：自动越狱攻击大型语言模型的先进框架'
date: '2024-07-02'
Lastmod: '2024-07-05'
description: 'SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01902v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01902v1)

## 摘要

本文探讨了大型语言模型（LLMs）在广泛应用中可能被滥用的安全问题。尽管LLMs在发布前已根据人类偏好数据进行了调整，但它们仍然容易受到各种恶意攻击，特别是“越狱攻击”。为此，本文提出了一种基于社会促进概念的自动越狱提示设计框架（SoP），该框架能够利用开源LLMs生成和优化越狱提示，无需任何种子越狱模板。实验结果显示，SoP在绕过GPT-3.5和GPT-4的安全对齐方面取得了显著的成功率，并展示了其在不同LLMs和恶意请求间的可转移性。此外，本文还探讨了针对SoP设计的越狱攻击的防御策略。<!--more-->

## 原理

SoP框架的核心在于利用社会促进理论，通过自动生成和优化多个越狱角色来绕过目标LLM的安全防护。这些角色在攻击过程中被逐步优化，以最大化攻击效果。SoP不依赖于人工设计的种子模板，而是通过开源LLM自动生成和优化越狱提示。这种基于社会促进的策略使得SoP能够在冷启动场景下有效攻击强大的专有LLMs，如GPT-4。

## 流程

SoP的工作流程包括以下几个关键步骤：
1. **角色生成**：使用元提示（meta prompt）指导攻击LLM生成候选越狱角色。
2. **目标响应**：将候选角色插入到越狱模板中，结合恶意请求攻击目标LLM。
3. **越狱评分**：通过判断模型评估当前角色的攻击效果。
4. **迭代细化**：根据评分结果更新元提示中的示例，重复上述过程以优化角色。

例如，在实验中，SoP使用LLaMA-2作为攻击LLM，成功绕过了LLaMA-2、GPT-3.5和GPT-4的安全防护，实现了高攻击成功率。

## 应用

SoP框架不仅展示了在不同LLMs间的高转移性，还表明了其在处理未见恶意请求时的有效性。这使得SoP成为开发可信赖LLMs的有价值红队测试工具。未来，SoP的应用可能扩展到更广泛的LLM安全测试和防御策略研究中，有助于提升LLMs的安全性和可靠性。