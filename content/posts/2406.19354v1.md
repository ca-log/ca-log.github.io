---
author: 'TechScribe'
title: '探索大型语言模型中的信念修正：挑战与解决方案'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19354v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19354v1)

## 摘要

本文探讨了大型语言模型（LLMs）中模型编辑的核心问题，即如何随着时间的推移学习新的事实并控制模型中的知识。文章指出，尽管模型编辑的实证研究受到广泛关注，但其概念基础仍然不稳固，因为模型编辑本质上是一个哲学上长期存在的问题——信念修正。文章批评了模型编辑问题的标准表述，并提出了一个正式的测试平台来研究模型编辑。文章首先描述了模型编辑的12个开放问题，这些问题基于（1）定义问题，（2）开发基准，以及（3）假设LLMs具有可编辑的信念。文章接着介绍了一个基于Wikidata的半合成数据集，用于评估模型编辑，并鼓励进一步研究探索可以与理想化贝叶斯代理进行比较的设置。<!--more-->

## 原理

文章提出的模型编辑测试平台通过以下步骤实现：首先，开发一个半合成预训练语料库并从头开始训练语言模型，以便可以精确控制预训练数据中的“知识”。然后，创建带有精确贝叶斯后验概率标签的评估数据，以评估模型编辑，从而评估模型编辑方法与“黄金标准”信念修正过程的接近程度。该测试平台使用从Wikidata派生的数据，能够将编辑后的语言模型的概率与精确的贝叶斯后验概率进行比较，提供了一个更精细的模型编辑方法评估。

## 流程

1. **预训练数据创建**：从Wikidata创建一个知识图谱，定义一个生成模型，并创建预训练数据。
2. **编辑基准创建**：拟合一个贝叶斯模型到预训练数据，创建测试案例。
3. **语言模型预训练**：在一个基于Wikidata的半合成语料库上训练一个8300万参数的自回归Transformer模型。
4. **模型编辑方法**：使用LoRA微调应用于MLP下投影矩阵，进行模型编辑。
5. **实验结果**：评估模型编辑性能，包括生成准确性、概率一致性和逻辑一致性。

## 应用

文章提出的模型编辑测试平台为未来研究提供了方向，包括如何更精确地定义模型编辑问题、开发可靠的模型编辑基准、确定哪些类型的LLMs应该被视为可编辑的，以及如何使用正式基准开发更好的模型编辑方法。这些研究将有助于开发更安全、更适应的AI系统，特别是在需要对LLMs中的信念进行精细调整以指导其行为并适应世界变化状态的部署环境中。