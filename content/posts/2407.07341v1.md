---
author: 'TechScribe'
title: '探索MixSumm：一种创新的数据增强框架在低资源抽取式文本摘要中的应用'
date: '2024-07-10'
Lastmod: '2024-07-11'
description: 'MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.07341v1.pdf_0.jpg)](https://arxiv.org/abs/2407.07341v1)

## 摘要

本文介绍了一种名为MixSumm的新型数据增强框架，专门用于低资源环境下的抽取式文本摘要任务。MixSumm利用开源大型语言模型LLaMA-3-70b生成包含多个主题信息的文档，并在此基础上训练摘要模型。通过在多个挑战性文本摘要基准数据集上的广泛实验，证明了MixSumm在低资源抽取式摘要任务中优于近期的基于提示的方法。此外，研究还展示了从LLaMA-3-70b到小型BERT基抽取式摘要器的有效知识蒸馏。<!--more-->

## 原理

MixSumm的工作原理基于两个主要步骤：首先，通过提示LLaMA-3-70b模型生成包含多个主题信息的新文档，这些文档混合了来自不同主题的示例信息；其次，利用这些新生成的文档训练一个抽取式摘要模型。这种方法通过混合不同主题的内容，增强了数据集的多样性和丰富性，从而提高了摘要模型的性能。此外，使用ROUGE分数和基于LLaMA-3的参考无关评估方法L-Eval来衡量生成摘要的质量，确保了评估的准确性和公正性。

## 流程

MixSumm的工作流程包括以下几个步骤：
1. 使用k-means算法将文档分组为T个集群。
2. 构建提示，包含来自不同集群的文档，并指示LLaMA-3-70b模型混合多个主题信息生成新文档。
3. 训练一个PreSumm抽取式摘要器在结合了种子数据和合成数据集上。
例如，在处理ArXiv/PubMed数据集时，由于文档较长，采用了分块和迭代摘要的子程序来处理长文档。

## 应用

MixSumm框架在低资源环境下的抽取式文本摘要任务中展现出巨大的潜力，特别是在数据稀缺的场景中。其应用前景广泛，包括但不限于新闻摘要、科学论文摘要、客户服务对话摘要等领域。随着技术的进一步发展和优化，MixSumm有望成为文本摘要领域的一个重要工具。