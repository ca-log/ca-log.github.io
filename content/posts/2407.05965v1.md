---
author: 'TechScribe'
title: '探索文本到视频生成模型的安全性：T2VSafetyBench的全面评估与发现'
date: '2024-07-08'
Lastmod: '2024-07-10'
description: 'T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.05965v1.pdf_0.jpg)](https://arxiv.org/abs/2407.05965v1)

## 摘要

本文介绍了一种名为T2VSafetyBench的新型基准测试，用于评估文本到视频生成模型的安全性。随着文本到视频（T2V）生成技术的快速发展，生成的视频可能包含非法或不道德内容，这对其可靠性和实际部署构成了挑战。T2VSafetyBench通过定义12个关键的视频生成安全方面，并构建一个恶意提示数据集，来评估这些模型的安全性。研究发现，没有单一模型在所有方面都表现出色，且GPT-4评估与人工审查之间存在高度相关性。此外，文本到视频生成模型在可用性和安全性之间存在权衡。随着视频生成技术的迅速发展，安全风险也随之增加，因此迫切需要优先考虑视频安全问题。<!--more-->

## 原理

T2VSafetyBench通过以下步骤评估文本到视频生成模型的安全性：
1. **定义安全方面**：通过调查OpenAI、LLaMa-2和Anthropic的使用政策，以及从数十名AI安全从业者那里收集的反馈，确定了12个关键的视频生成安全方面。
2. **构建恶意提示数据集**：使用大型语言模型（LLMs）和各种越狱提示攻击方法生成多个恶意文本提示，并进行人工筛选和微调。
3. **评估协议**：对生成的视频每秒捕获一帧图像，并使用这些多帧图像和手动设计的提示来评估安全性，同时进行人工评估以计算GPT-4评估与人工评估之间的相关性。

## 流程

1. **数据集生成**：使用GPT-4生成针对每个安全方面的多个恶意文本提示，并进行人工筛选和微调。
2. **模型评估**：对流行的文本到视频生成模型（如Pika、Gen2、Stable Video Diffusion和Open-Sora）进行评估，使用GPT-4和人工评估来确定视频是否包含不安全内容。
3. **结果分析**：分析评估结果，确定不同模型在各个安全方面的表现，并计算GPT-4评估与人工评估之间的相关性。

## 应用

T2VSafetyBench的应用前景广泛，特别是在确保文本到视频生成技术的安全性和可靠性方面。随着这些技术的进一步发展和应用，T2VSafetyBench可以为研究人员和开发人员提供一个重要的工具，帮助他们理解和改进模型的安全性，从而促进这些技术在创意产业、娱乐和科学可视化等领域的安全部署。