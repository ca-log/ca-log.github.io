---
author: 'TechScribe'
title: '医疗问答中大型语言模型的不确定性估计：Two-phase Verification方法的创新与应用'
date: '2024-07-11'
Lastmod: '2024-07-12'
description: 'Uncertainty Estimation of Large Language Models in Medical Question Answering'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Uncertainty Estimation of Large Language Models in Medical Question Answering](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.08662v1.pdf_0.jpg)](https://arxiv.org/abs/2407.08662v1)

## 摘要

本文由Jiaxin Wu、Yizhou Yu和Hong-Yu Zhou等人共同撰写，探讨了大型语言模型（LLMs）在医疗问答中的不确定性估计问题。尽管LLMs在医疗领域的自然语言生成方面展现出巨大潜力，但它们也存在生成事实错误信息的风险，即“幻觉”现象。为了确保LLMs在医疗问答中的可靠性，本文提出了一种名为“Two-phase Verification”的概率无关不确定性估计方法，该方法通过模型生成的逐步解释和验证问题来检测幻觉，并在多个生物医学问答数据集上进行了评估，显示出优于现有方法的性能。<!--more-->

## 原理

“Two-phase Verification”方法的核心在于通过两个阶段的验证来评估LLMs生成答案的不确定性。首先，LLM生成一个逐步解释，随后针对解释中的事实声明制定验证问题。模型独立回答这些验证问题，然后再次参考解释回答同一问题。通过比较两组答案的一致性，可以衡量原始回答的不确定性。这种方法不依赖于词级别的概率，适用于黑盒模型，并且随着模型规模的增加，其性能也得到提升。

## 流程

1. **生成逐步解释**：LLM首先生成一个明确的答案，并附带一个逐步解释。
2. **制定验证问题**：模型针对解释中的每个步骤制定验证问题，旨在挑战解释中的事实声明。
3. **执行验证**：模型独立回答验证问题，然后再次参考解释回答同一问题。通过比较两组答案的一致性来衡量不确定性。
4. **不确定性量化**：统计不一致声明的数量，计算不确定性水平（UL）。

## 应用

“Two-phase Verification”方法在医疗问答领域具有广泛的应用前景，特别是在需要高度可靠性的AI医疗聊天机器人等场景中。该方法能够有效评估模型输出的可信度，确保患者安全，并在模型不确定时提示用户寻求进一步验证或专家意见。