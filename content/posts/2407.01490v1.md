---
author: 'TechScribe'
title: '"LLM See, LLM Do: 利用合成数据引导大型语言模型向理想属性进化"'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01490v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01490v1)

## 摘要

本文探讨了合成数据对大型语言模型（LLMs）的影响，特别是如何通过精炼数据影响其他LLMs。研究系统地分析了合成数据集成对模型内部偏见、校准和生成文本属性的影响。研究发现，即使合成数据提示看似“中性”，模型对某些属性也异常敏感，这引发了关于是否可以利用数据生成过程在测试时明确引导模型向所需属性的问题。文章提出了“主动继承”这一概念，描述了如何有意地根据非可微目标约束合成数据，以引导模型生成具有高词汇多样性或低毒性的文本。<!--more-->

## 原理

论文的关键内容在于“主动继承”方法，这是一种通过精心选择合成数据来优化非可微目标的技术。具体来说，该方法涉及为每个提示生成多个样本，然后选择最能体现所需属性的样本进行微调。这种方法不依赖于复杂的强化学习或贝叶斯优化，而是通过简单地引导生成过程中的数据选择来实现，这种方法因其基于可观察的数据特征而具有可解释性。

## 流程

论文详细描述了“主动继承”的工作流程，包括如何从单个或多个模型中生成多个样本，然后根据特定的非可微目标（如增加文本长度和词汇多样性，减少毒性）选择最佳样本进行模型微调。例如，通过比较不同模型的生成样本，选择词汇多样性最高的样本进行后续训练，从而逐步优化模型的生成行为。

## 应用

该研究为合成数据在LLMs中的应用提供了新的视角，特别是在如何通过数据生成过程来引导模型行为方面。这种方法不仅适用于提高文本的多样性和降低毒性，还可以扩展到其他需要优化非可微目标的应用场景，如情感分析、内容过滤等。随着合成数据质量的提高和模型设计的进步，这种方法有望在多个领域推动LLMs的应用和发展。