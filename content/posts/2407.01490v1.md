---
author: 'TechScribe'
title: '"主动继承：利用合成数据引导大型语言模型生成理想文本"'
date: '2024-07-01'
Lastmod: '2024-07-05'
description: 'LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.01490v1.pdf_0.jpg)](https://arxiv.org/abs/2407.01490v1)

## 摘要

本文探讨了合成数据对大型语言模型（LLMs）的影响，特别是如何通过精炼数据影响其他LLMs。研究系统地分析了合成数据源如何塑造模型的内部偏见、校准和生成文本的属性及偏好。研究发现，即使合成数据提示看似“中性”，模型对某些属性仍异常敏感，这引发了一个问题：是否可以利用数据生成过程在测试时明确引导模型向我们想要的属性发展？本文提出了“主动继承”这一概念，描述了如何根据非可微目标有意限制合成数据，以引导模型生成具有高词汇多样性或低毒性的文本。<!--more-->

## 原理

本文的核心在于通过“主动继承”策略，即在合成数据生成过程中有目的地选择和优化数据，以引导模型生成特定属性的文本。具体来说，研究者通过选择具有特定理想属性的代理标签来生成多个样本，然后从中选择最符合目标属性的样本来进行模型微调。这种方法不依赖于复杂的强化学习或贝叶斯优化，而是通过简单地指导生成过程来实现，这种方法的可解释性在于它直接关联到可观察的数据特征。

## 流程

研究首先通过“被动继承”分析，即不加选择地使用教师模型生成的合成数据来训练学生模型，以评估模型属性的变化。随后，引入“主动继承”方法，通过目标采样策略，即从多个模型或单个模型生成多个样本，然后选择最符合预定属性的样本来进行模型微调。这种方法通过增强理想属性（如长度和词汇多样性）和减少负面属性（如毒性）来引导模型行为。

## 应用

本文提出的“主动继承”策略为合成数据的生成和使用提供了新的方向，特别是在需要控制模型生成文本属性（如多样性和毒性）的场景中。这种方法的应用前景广泛，包括但不限于内容生成、自动审核系统以及需要高度定制化文本输出的应用领域。