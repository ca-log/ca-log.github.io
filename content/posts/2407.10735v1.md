---
author: 'TechScribe'
title: '探索大型语言模型的本质与未来：ChatGPT的深度解析与应用前景'
date: '2024-07-15'
Lastmod: '2024-07-16'
description: 'Transforming Agency. On the mode of existence of Large Language Models'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Transforming Agency. On the mode of existence of Large Language Models](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.10735v1.pdf_0.jpg)](https://arxiv.org/abs/2407.10735v1)

## 摘要

本文探讨了大型语言模型（LLMs）如ChatGPT的本质存在模式，特别关注其作为代理的状态。文章在通货膨胀和通货紧缩的叙述之间，特别关注LLMs作为代理人的地位。这需要详细解释LLMs的架构、处理和训练程序，以及将LLMs转变为类似代理系统的扩展。经过系统分析，我们得出结论，根据具身心灵理论，LLM未能满足自主代理的必要和充分条件：个体性条件（它不是自身活动的产品，甚至不受其直接影响），规范性条件（它不产生自己的规范或目标），以及部分交互不对称条件（它不是其与环境交互的源头和持续源泉）。如果不是代理人，那么LLMs是什么？我们主张ChatGPT应被描述为对话者或语言自动机，一个会说话的图书馆，缺乏（自主）代理，但能够在非目的性但目的结构化和目的有限性的任务中进行表演性参与。当与人类互动时，人类-机器交互中的“幽灵”成分使得与LLMs进行真正的对话体验成为可能。尽管缺乏感官运动和生物体，LLMs的文本体（训练语料库）和资源密集型计算体，显著改变了现有的人类代理形式。除了辅助和扩展的代理外，LLM-人类耦合可以产生中介形式的代理，更接近于有意代理的生产而非任何先前技术的扩展工具性。<!--more-->

## 原理

大型语言模型（LLMs）如ChatGPT的工作原理基于其复杂的架构和处理流程。首先，输入的文本被切分为标记（tokens），每个标记大约是英语中四分之三个单词的长度。这些标记随后被编码为数值形式。接下来，这些数值被映射到一个高维关系空间中，这个过程称为嵌入（embedding）。嵌入不仅涉及简单的存储统计关系或条件概率，而是构成了一个压缩和结构化的引擎，能够以非线性、高度相互关联和复杂的形式处理和转换文本输入。

在嵌入之后，每个词/标记嵌入还会被转换以包含位置信息，这是通过添加一个独特的正弦和余弦函数输出来实现的。这个过程产生了巨大的矩阵，其中包含了所有输入标记的嵌入及其位置。这个矩阵随后通过一系列处理块进行处理，每个块包括主要的三种操作：注意力机制、加法和归一化，以及前馈神经网络处理。GPT-3通过96个这样的块来转换输入矩阵。

注意力机制是LLMs革命中最具创新性的步骤，它允许模型并行处理学习过程中的处理，并能够探索输入数据上的广泛相关性依赖，以高度可扩展的方式改进其他架构，如循环神经网络或长短期记忆网络。前馈网络涉及通过三层传递矩阵：输入层是矩阵本身，隐藏层扩展其维度，输出层将其缩减回原始大小。所有第一层的节点都连接到所有第二层，所有第二层连接到第三层（但不相互连接或向后连接，因此称为前馈）。连接是加权的，因此不同关系之间的值投影可以有不同的权重，并放大或减少进入下一层的每个信号的值。然后，下一层的节点通过非线性函数处理。原则上，FFNN可以计算任何函数。在这个案例中，它们可以被看作是一个计算机内的计算机（它们可以模拟任何图灵机），其好处是可以在无监督的方式下编程。

最后，经过处理的矩阵需要转换为单个下一个标记的输出。回想一下，原始嵌入将50257个单词（标记）投影到一个12228维空间中。一个50257x12228的投影矩阵（这是嵌入的转置）现在将处理过的矩阵转换为词汇表中每个标记的分数。最高分的k个标记被分离出来，一个softmax算法简单地将每个标记的分数转换为归一化的概率，该概率与其分数成比例。然后根据这些概率选择最终的标记。

这个序列的操作被一遍又一遍地重复，每次在字符串的末尾添加一个新的标记（例如，一个新的单词到句子中），直到达到允许标记的最大数量，或者最常见的是，GPT产生一个序列结束标记（一种“停止”标记，被解释为停止）。可以通过重新引入输入并添加一些更多文本（例如，当我们向对话中添加响应时）来继续该过程。尽管GPT的“智能”经常在它停止时显示出来，但自回归最相关的方面是它为系统提供的“外部化”反馈形式。这是其功能的一个基本部分。请注意，在架构的任何步骤中，ChatGPT都没有存储任何信息，没有“内部”状态，没有记忆。从某种意义上说，它是一个纯粹的反应系统。正是通过自回归，它才弥补了这一点，以一种将成为非常重要讨论的方式。

术语transformer最初被选中是为了描绘输入矩阵到输出的转换，翻译任务是一个关键组成部分。它后来被应用于其他任务（如总结），并最终发现一个足够大的transformer可以很好地跨任务执行。而且，它可以通过直接指令学习做什么，只需很少或没有示例（Brown等人，2020；Radford等人，2019）。这就是提示概念变得重要的地方。LLM变换器的通用性和非特定性使其开放，可以在不同的方向上展开：总结、翻译、纠正、解释、对话、扩展关键思想、发展大纲策略等。“魔术”可以说，支撑这些能力的是系统的参数，即操作输入矩阵的嵌入、注意力和FFNN矩阵（图1中紫色部分）。

## 流程

大型语言模型（LLMs）如GPT的配置通常在各个阶段进行。首先是所谓的“预训练”，但构成了主要的训练（理解为改进或获取新能力的

过程）。在这个过程中，每个处理转换的参数逐渐改变，直到达到一定的准确性水平，预训练结束，它们保持固定，直到新的训练程序开始。然后是微调，有两个基本阶段：任务特定的拟合和人类强化学习。最后，经常使用提示学习，这是一种指导系统的教学形式。

**预训练**
解释整个架构的工作方式，正如我们刚才所做的，对于理解训练至关重要。与其他方法相反，每个处理块不是孤立地训练以执行特定任务（例如，首先语法地组织输入，然后构建一个一般的抽象表示，接下来进行推理并做出输出决策），而是整个系统一起训练，通过反向传播（Rumelhart等人，1986）。

基本机制很简单：系统用随机参数初始化。然后从训练数据集中选择一个输入块（例如，句子的开头）。然后，如上所述进行处理。这称为前向传递。这个传递在系统提供结果数组时结束：指示所有单词成为下一个单词的概率的数组（选择最终输出的步骤之前）。结果在开始时将是无意义的。例如，对于输入“Elephants don’t play”，结果数组的高概率可能是“purple”，其次是“Fodor”，“misuse”，“chain”，“cat”等。现在，这将与正确的结果进行比较：一个数组，除了“chess”之外，所有单词的概率都为0。但“chess”可能在分配的概率中非常低。然而，现在可以计算一个错误（或损失）：结果数组分配的概率与目标数组之间的差异。

接下来，这个损失将通过网络反向传播（反向传递）。通过优化算法，在整个网络中朝着最小化这个错误的方向进行小的改变：算法计算“我应该对这个参数做什么改变，以便结果输出减少错误？”并相应地进行改变，对于每个块上的每个参数，向后进行。

这个过程一次又一次地迭代，直到前向过程产生无错误或很少错误。LLMs的所有三个主要组件都以这种方式训练：嵌入、注意力机制和前馈网络。尽管整个过程在局部相对简单，但微小变化的量是巨大的，效果是我们今天可以见证的性能能力。训练GPT-3的计算成本是3.14×10^23次浮点运算（Brown等人，2020附录D）。

到目前为止，该系统被认为是一个原始的基础模型：它可以一般地处理文本，并且可以已经用于许多任务，或者可以进一步训练以提高特定类型任务的性能。到目前为止的训练过程被认为是无监督的，除了下一个单词预测之外，没有使用任何东西来训练模型。

**微调**
额外的训练程序用于为特定任务微调变换器，如总结、翻译或对话。这次提供了指令（例如，总结）和任务输入（例如，整个维基百科文章），并且系统通过反向传播训练以匹配模型输出（例如，维基百科对该文章的总结条目），而不是仅仅下一个标记。这是监督学习，没有人干预，但任务不仅仅是“猜测”下一个单词，而是匹配特定的目标目标，需要完成这个训练的输入和目标输出对。

变换器通常进一步训练以包括人类反馈的强化学习或RFHF（Ziegler等人，2020）。预训练和微调的LLM被允许与人类互动。然后，根据人类如何积极或消极地评估模型的输出，它被训练以产生更有可能被积极评价或不太可能被消极评价的输出；根据人类交互者过去所做的修正。这是系统经常在道德或道德价值观上训练的地方，以及其他许多质量检查。

最后，我们有一键或几键学习程序，基本上在提示级别操作，提供示例或特定指令，LLMs将其作为输入来产生新的示例或遵循提供的指令（Brown等人，2020）。

## 应用

大型语言模型（LLMs）如ChatGPT的应用前景广泛，涵盖了从辅助工具到创新平台的多个领域。以下是一些关键的应用前景：

1. **辅助工具**：LLMs可以作为辅助工具，帮助用户完成各种文本相关的任务，如写作、编辑、翻译和总结。这些模型能够提供即时的反馈和建议，极大地提高了工作效率和质量。

2. **教育平台**：在教育领域，LLMs可以作为智能教学助手，提供个性化的学习材料和反馈。它们能够根据学生的学习进度和理解能力，调整教学内容和难度，实现真正的个性化教育。

3. **内容创作**：对于内容创作者，LLMs可以作为一个强大的创作伙伴，帮助生成创意文本、故事、诗歌等。这些模型能够提供多样化的内容建议，激发创作者的灵感。

4. **智能客服**：在客户服务领域，LLMs可以作为智能客服系统，提供24/7的客户支持。它们能够理解客户的问题，并提供准确及时的解答，提升客户满意度。

5. **研究和开发**：在科研领域，LLMs可以帮助研究人员处理和分析大量的文本数据，加速研究进程。它们还能够协助生成研究报告和论文摘要，提高科研效率。

6. **娱乐和游戏**：在娱乐和游戏行业，LLMs可以用于开发智能对话系统和角色，提供更加丰富和互动的游戏体验。它们能够创造出具有深度和个性的虚拟角色，增强游戏的沉浸感。

7. **企业应用**：在企业环境中，LLMs可以用于自动化文档处理、数据分析和决策支持。它们能够帮助企业提高运营效率，降低成本，并做出更加明智的决策。

总之，LLMs的应用前景非常广泛，它们有潜力在多个领域带来革命性的变化。随着技术的不断进步和应用场景的进一步探索，LLMs将在未来发挥更加重要的作用。