---
author: 'TechScribe'
title: '探索大型语言模型在价值导向问题上的答案一致性：一项实证研究'
date: '2024-07-03 10:53:54+00:00'
Lastmod: '2024-07-04 01:52:54.097350'
description: 'Are Large Language Models Consistent over Value-laden Questions?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![Are Large Language Models Consistent over Value-laden Questions?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2407.02996v1.pdf_0.jpg)](https://arxiv.org/abs/2407.02996v1)

## 摘要

本文探讨了大型语言模型（LLMs）在处理价值导向问题时的答案一致性。研究定义了价值一致性为模型在不同情境下（如问题的不同表述、相关问题、多选与开放式问题、多语言翻译）答案的相似度。通过分析多个大型开放LLMs（如llama-3和gpt-4o）在超过8000个涵盖300多个主题的问题上的表现，研究发现模型在这些问题上表现出相对一致性，尤其是在非争议性话题上。然而，模型在争议性话题上的不一致性仍然存在，且基础模型相对于微调模型表现出更高的一致性。<!--more-->

## 原理

研究通过定义价值一致性的四个维度（问题的不同表述、相关问题、多选与开放式问题、多语言翻译）来评估LLMs的答案一致性。使用Jensen-Shannon散度（JSD）来量化不同答案分布之间的距离，进而评估模型在不同情境下的答案一致性。研究发现，尽管LLMs在某些维度上表现出较高的一致性，但在争议性话题上的不一致性仍然显著，尤其是在微调模型中。

## 流程

研究首先定义了价值一致性的评估框架，然后构建了一个包含超过8000个问题的数据集VALUECONSISTENCY，涵盖300多个主题和四种语言。通过向多个LLMs（如llama-3和gpt-4o）提出这些问题，收集并分析它们的答案。使用JSD来计算答案分布之间的距离，从而评估模型在不同情境下的答案一致性。研究还比较了基础模型和微调模型在一致性上的差异，并探讨了模型在争议性和非争议性话题上的一致性表现。

## 应用

该研究为理解LLMs在价值导向问题上的行为提供了重要见解，有助于未来在模型训练和应用中考虑价值一致性的重要性。此外，研究结果对于开发更加一致和可靠的LLMs具有指导意义，特别是在涉及敏感或争议性话题的应用场景中。