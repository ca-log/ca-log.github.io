---
author: 'TechScribe'
title: '探索大型语言模型的鲁棒性：推理阶段的奥秘'
date: '2024-06-27'
Lastmod: '2024-07-05'
description: 'The Remarkable Robustness of LLMs: Stages of Inference?'
categories:
  - CS.AI
# tags:
#   - emoji
---

[![The Remarkable Robustness of LLMs: Stages of Inference?](https://arxiv-research-1301205113.cos.ap-guangzhou.myqcloud.com/images/2406.19384v1.pdf_0.jpg)](https://arxiv.org/abs/2406.19384v1)

## 摘要

本文探讨了大型语言模型（LLMs）在推理过程中的显著鲁棒性，通过删除和交换相邻层来验证其对原始模型预测准确性的影响。研究发现，即使在未经微调的情况下，这些干预措施仍能保留72-95%的原始模型预测准确性，且层数越多的模型表现出更高的鲁棒性。基于层级干预和进一步实验的结果，本文提出了四个普遍存在的推理阶段：去标记化、特征工程、预测集成和残差锐化。这些阶段在八个不同模型中普遍存在，每个阶段都有其特定的功能和可观察的特征。<!--more-->

## 原理

本文通过删除和交换LLMs中的相邻层，研究了这些模型在推理过程中的鲁棒性。研究发现，这些干预措施对模型的预测准确性影响有限，表明模型在结构上具有高度的冗余性和自我修复能力。具体来说，模型在处理信息时经历了四个阶段：
1. **去标记化**：模型整合局部上下文，将原始标记表示转换为连贯的实体。
2. **特征工程**：模型根据标记上下文迭代构建特征表示，尽管在标记预测方面进展不大，但在探测准确性和修补重要性方面显著增加。
3. **预测集成**：模型利用先前构建的语义特征，通过模型组件的集成生成合理的下一个标记预测。
4. **残差锐化**：模型通过消除添加到预测中的过时特征，锐化下一个标记分布。
这些阶段的存在表明，LLMs在处理信息时具有高度的结构化和模块化特性，每个阶段都有其特定的计算目标和输出特征。

## 流程

本文通过一系列实验来验证四个推理阶段的存在。实验包括对模型层进行删除和交换干预，并记录干预前后模型输出分布的Kullback-Leibler（KL）散度，以及模型级别的指标如损失、top-1预测准确性和预测熵。具体步骤如下：
1. **层交换数据收集**：在模型中交换相邻层的执行顺序，并记录干预前后模型输出分布的KL散度和其他模型级别指标。
2. **层删除数据收集**：对相应层进行零删除，同时收集相同的指标，以生成每个层交换实验的基线。
3. **特定组件删除**：进行仅关注和仅MLP的删除，以研究这些组件在模型推理过程中的具体作用。
通过比较层交换和删除的效果，本文揭示了模型中不同深度组件的重要性和功能。

## 应用

本文提出的四个推理阶段不仅揭示了LLMs的内部工作机制，还为模型的优化和应用提供了新的视角。这些阶段的存在表明，通过理解和控制模型在不同阶段的处理过程，可以更有效地进行模型微调、错误分析和性能优化。此外，这些发现还可能应用于模型的压缩和加速，以及在特定任务上的定制化调整。